{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b7df87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec85185",
   "metadata": {},
   "source": [
    "# Logistic Regression (L1) - Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c2bf400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('CleanedData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a67ef534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count of Rows</th>\n",
       "      <th>#YYY/MM/DD</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>DEPTH</th>\n",
       "      <th>Q</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAG</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>164905</td>\n",
       "      <td>164905</td>\n",
       "      <td>164905</td>\n",
       "      <td>164905</td>\n",
       "      <td>164905</td>\n",
       "      <td>164905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>187056</td>\n",
       "      <td>187056</td>\n",
       "      <td>187056</td>\n",
       "      <td>187056</td>\n",
       "      <td>187056</td>\n",
       "      <td>187056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52225</td>\n",
       "      <td>52225</td>\n",
       "      <td>52225</td>\n",
       "      <td>52225</td>\n",
       "      <td>52225</td>\n",
       "      <td>52225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10119</td>\n",
       "      <td>10119</td>\n",
       "      <td>10119</td>\n",
       "      <td>10119</td>\n",
       "      <td>10119</td>\n",
       "      <td>10119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>845</td>\n",
       "      <td>845</td>\n",
       "      <td>845</td>\n",
       "      <td>845</td>\n",
       "      <td>845</td>\n",
       "      <td>845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Count of Rows  #YYY/MM/DD     LAT     LON   DEPTH       Q\n",
       "MAG                                                           \n",
       "0           164905      164905  164905  164905  164905  164905\n",
       "1           187056      187056  187056  187056  187056  187056\n",
       "2            52225       52225   52225   52225   52225   52225\n",
       "3            10119       10119   10119   10119   10119   10119\n",
       "4              845         845     845     845     845     845\n",
       "5               55          55      55      55      55      55\n",
       "6                1           1       1       1       1       1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove classes with only 1 example (MAG=6)\n",
    "df['MAG'] = df['MAG'].astype(int)\n",
    "df.groupby(by='MAG').count().rename(columns={'Unnamed: 0': 'Count of Rows'})#['Count of Rows']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "218bbc97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>#YYY/MM/DD</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>DEPTH</th>\n",
       "      <th>Q</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAG</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>164905</td>\n",
       "      <td>164905</td>\n",
       "      <td>164905</td>\n",
       "      <td>164905</td>\n",
       "      <td>164905</td>\n",
       "      <td>164905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>187056</td>\n",
       "      <td>187056</td>\n",
       "      <td>187056</td>\n",
       "      <td>187056</td>\n",
       "      <td>187056</td>\n",
       "      <td>187056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52225</td>\n",
       "      <td>52225</td>\n",
       "      <td>52225</td>\n",
       "      <td>52225</td>\n",
       "      <td>52225</td>\n",
       "      <td>52225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10119</td>\n",
       "      <td>10119</td>\n",
       "      <td>10119</td>\n",
       "      <td>10119</td>\n",
       "      <td>10119</td>\n",
       "      <td>10119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>845</td>\n",
       "      <td>845</td>\n",
       "      <td>845</td>\n",
       "      <td>845</td>\n",
       "      <td>845</td>\n",
       "      <td>845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  #YYY/MM/DD     LAT     LON   DEPTH       Q\n",
       "MAG                                                        \n",
       "0        164905      164905  164905  164905  164905  164905\n",
       "1        187056      187056  187056  187056  187056  187056\n",
       "2         52225       52225   52225   52225   52225   52225\n",
       "3         10119       10119   10119   10119   10119   10119\n",
       "4           845         845     845     845     845     845\n",
       "5            55          55      55      55      55      55"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['MAG'] != 6]\n",
    "df.groupby(by='MAG').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ec37d684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q_A</th>\n",
       "      <th>Q_B</th>\n",
       "      <th>Q_C</th>\n",
       "      <th>Q_D</th>\n",
       "      <th>Q_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q_A  Q_B  Q_C  Q_D  Q_Z\n",
       "0  0.0  0.0  1.0  0.0  0.0\n",
       "1  0.0  0.0  0.0  1.0  0.0\n",
       "2  1.0  0.0  0.0  0.0  0.0\n",
       "3  1.0  0.0  0.0  0.0  0.0\n",
       "4  1.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encode quality \"Q\"\n",
    "cols = ['Q']\n",
    "one_hot_cols = df[cols] #.reshape(-1, 1)\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(one_hot_cols)\n",
    "encoded_cols = pd.DataFrame(enc.transform(one_hot_cols).toarray()\n",
    "                            , columns=enc.get_feature_names_out())\n",
    "encoded_cols.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a81f45c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>#YYY/MM/DD</th>\n",
       "      <th>MAG</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>DEPTH</th>\n",
       "      <th>Q_A</th>\n",
       "      <th>Q_B</th>\n",
       "      <th>Q_C</th>\n",
       "      <th>Q_D</th>\n",
       "      <th>Q_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>1980-01-02</td>\n",
       "      <td>2</td>\n",
       "      <td>32.445</td>\n",
       "      <td>-115.162</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>1980-01-02</td>\n",
       "      <td>3</td>\n",
       "      <td>34.449</td>\n",
       "      <td>-119.680</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>1980-01-02</td>\n",
       "      <td>2</td>\n",
       "      <td>33.040</td>\n",
       "      <td>-115.499</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>1980-01-03</td>\n",
       "      <td>2</td>\n",
       "      <td>32.967</td>\n",
       "      <td>-115.542</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48</td>\n",
       "      <td>1980-01-03</td>\n",
       "      <td>2</td>\n",
       "      <td>33.943</td>\n",
       "      <td>-116.304</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  #YYY/MM/DD  MAG     LAT      LON  DEPTH  Q_A  Q_B  Q_C  Q_D  \\\n",
       "0          21  1980-01-02    2  32.445 -115.162    4.8  0.0  0.0  1.0  0.0   \n",
       "1          30  1980-01-02    3  34.449 -119.680   15.6  0.0  0.0  0.0  1.0   \n",
       "2          33  1980-01-02    2  33.040 -115.499    5.1  1.0  0.0  0.0  0.0   \n",
       "3          38  1980-01-03    2  32.967 -115.542   14.5  1.0  0.0  0.0  0.0   \n",
       "4          48  1980-01-03    2  33.943 -116.304    0.7  1.0  0.0  0.0  0.0   \n",
       "\n",
       "   Q_Z  \n",
       "0  0.0  \n",
       "1  0.0  \n",
       "2  0.0  \n",
       "3  0.0  \n",
       "4  0.0  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the newly encoded columns to the data and drop the original columns\n",
    "df2 = df.join(encoded_cols).drop(cols,axis=1)\n",
    "df2 = df2.fillna(0)\n",
    "df2.head()\n",
    "#for c in df2.columns:\n",
    "#    print(c, df2[c].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fc74a9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = df2[['LAT', 'LON', 'DEPTH', 'Q_A', 'Q_B', 'Q_C', 'Q_D', 'Q_Z']]\n",
    "y = df2['MAG']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1,stratify=y)\n",
    "logistic = LogisticRegression(solver='liblinear',penalty='l1',C=1.0, random_state=1)\n",
    "logistic.fit(X_train, y_train)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "49f434b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 8)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients = logistic.coef_\n",
    "coefficients.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c3bde349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2941458385007907 \t LAT\n",
      "-0.016513208018584684 \t LON\n",
      "-0.07348082207674606 \t DEPTH\n",
      "3.1993663741376857 \t Q_A\n",
      "3.6580773757278635 \t Q_B\n",
      "3.786477004503291 \t Q_C\n",
      "4.324821932018484 \t Q_D\n",
      "0.0 \t Q_Z\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for c in X.columns:\n",
    "  print(coefficients[2][i], '\\t', c)\n",
    "  i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f720c5",
   "metadata": {},
   "source": [
    "# Extra Transformations for Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "573399c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Unnamed: 0            MAG            LAT            LON  \\\n",
      "count  415206.000000  415206.000000  415206.000000  415206.000000   \n",
      "mean   586645.494675       1.283736      34.261559    -116.973450   \n",
      "std    146368.176445       0.712565       1.209252       0.925457   \n",
      "min        21.000000       0.000000      32.000000    -122.000000   \n",
      "25%    483388.250000       0.770000      33.422000    -117.665000   \n",
      "50%    597916.500000       1.160000      33.933000    -116.802000   \n",
      "75%    706109.750000       1.660000      35.669000    -116.401000   \n",
      "max    812791.000000       6.070000      37.000000    -114.233000   \n",
      "\n",
      "               DEPTH  \n",
      "count  415206.000000  \n",
      "mean        7.632999  \n",
      "std         4.688657  \n",
      "min        -2.300000  \n",
      "25%         3.900000  \n",
      "50%         7.000000  \n",
      "75%        10.900000  \n",
      "max        58.100000  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 415206 entries, 0 to 415205\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   Unnamed: 0  415206 non-null  int64  \n",
      " 1   #YYY/MM/DD  415206 non-null  object \n",
      " 2   MAG         415206 non-null  float64\n",
      " 3   LAT         415206 non-null  float64\n",
      " 4   LON         415206 non-null  float64\n",
      " 5   DEPTH       415206 non-null  float64\n",
      " 6   Q           415206 non-null  object \n",
      "dtypes: float64(4), int64(1), object(2)\n",
      "memory usage: 22.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('CleanedData.csv')\n",
    "df.head()\n",
    "\n",
    "print(df.describe())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185f45a9",
   "metadata": {},
   "source": [
    "## Group data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c00c379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#YYY/MM/DD</th>\n",
       "      <th>MAG</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>DEPTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980-01-02</td>\n",
       "      <td>2.35</td>\n",
       "      <td>32.445</td>\n",
       "      <td>-115.162</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980-01-02</td>\n",
       "      <td>3.15</td>\n",
       "      <td>34.449</td>\n",
       "      <td>-119.680</td>\n",
       "      <td>15.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1980-01-02</td>\n",
       "      <td>2.83</td>\n",
       "      <td>33.040</td>\n",
       "      <td>-115.499</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1980-01-03</td>\n",
       "      <td>2.49</td>\n",
       "      <td>32.967</td>\n",
       "      <td>-115.542</td>\n",
       "      <td>14.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1980-01-03</td>\n",
       "      <td>2.52</td>\n",
       "      <td>33.943</td>\n",
       "      <td>-116.304</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #YYY/MM/DD   MAG     LAT      LON  DEPTH\n",
       "0  1980-01-02  2.35  32.445 -115.162    4.8\n",
       "1  1980-01-02  3.15  34.449 -119.680   15.6\n",
       "2  1980-01-02  2.83  33.040 -115.499    5.1\n",
       "3  1980-01-03  2.49  32.967 -115.542   14.5\n",
       "4  1980-01-03  2.52  33.943 -116.304    0.7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "df.drop('Q',axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ecfe460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rolling mean MAG\n",
    "def get_rolling_agg(df, method, days, col):\n",
    "    if method == 'max':\n",
    "        df2 = df.groupby(['#YYY/MM/DD'])[col].max()\n",
    "        rolling = df2.rolling(days,min_periods=0)\n",
    "        df2 = rolling.max()\n",
    "    elif method == 'sum':\n",
    "        df2 = df.groupby(['#YYY/MM/DD'])[col].sum()\n",
    "        rolling = df2.rolling(days,min_periods=0)\n",
    "        df2 = rolling.sum()\n",
    "    elif method == 'std':\n",
    "        df2 = df.groupby(['#YYY/MM/DD'])[col]\n",
    "        rolling = df2.rolling(days,min_periods=0)\n",
    "        df2 = rolling.std()\n",
    "    df2 = df2.reset_index()\n",
    "    df2['#YYY/MM/DD'] = pd.to_datetime(df2['#YYY/MM/DD']).dt.normalize()\n",
    "    df2['Year'] = df2['#YYY/MM/DD'].dt.strftime(\"%Y\")\n",
    "    df2.drop('#YYY/MM/DD',axis=1,inplace=True)\n",
    "    df2 = df2.groupby(['Year']).max()\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21998acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>#YYY/MM/DD</th>\n",
       "      <th>MAG</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>DEPTH</th>\n",
       "      <th>Count_L</th>\n",
       "      <th>Count_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1980-01-02</td>\n",
       "      <td>2.35</td>\n",
       "      <td>32.445</td>\n",
       "      <td>-115.162</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1980-01-02</td>\n",
       "      <td>3.15</td>\n",
       "      <td>34.449</td>\n",
       "      <td>-119.680</td>\n",
       "      <td>15.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1980-01-02</td>\n",
       "      <td>2.83</td>\n",
       "      <td>33.040</td>\n",
       "      <td>-115.499</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1980-01-03</td>\n",
       "      <td>2.49</td>\n",
       "      <td>32.967</td>\n",
       "      <td>-115.542</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1980-01-03</td>\n",
       "      <td>2.52</td>\n",
       "      <td>33.943</td>\n",
       "      <td>-116.304</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415201</th>\n",
       "      <td>415201</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>2.32</td>\n",
       "      <td>33.293</td>\n",
       "      <td>-117.823</td>\n",
       "      <td>58.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415202</th>\n",
       "      <td>415202</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>0.87</td>\n",
       "      <td>32.463</td>\n",
       "      <td>-116.804</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415203</th>\n",
       "      <td>415203</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>0.86</td>\n",
       "      <td>33.395</td>\n",
       "      <td>-116.896</td>\n",
       "      <td>13.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415204</th>\n",
       "      <td>415204</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>1.24</td>\n",
       "      <td>32.398</td>\n",
       "      <td>-116.239</td>\n",
       "      <td>20.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415205</th>\n",
       "      <td>415205</td>\n",
       "      <td>2023-04-15</td>\n",
       "      <td>0.74</td>\n",
       "      <td>33.481</td>\n",
       "      <td>-116.452</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>415206 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  #YYY/MM/DD   MAG     LAT      LON  DEPTH  Count_L  Count_S\n",
       "0            0  1980-01-02  2.35  32.445 -115.162    4.8      0.0      1.0\n",
       "1            1  1980-01-02  3.15  34.449 -119.680   15.6      0.0      1.0\n",
       "2            2  1980-01-02  2.83  33.040 -115.499    5.1      0.0      1.0\n",
       "3            3  1980-01-03  2.49  32.967 -115.542   14.5      0.0      1.0\n",
       "4            4  1980-01-03  2.52  33.943 -116.304    0.7      0.0      1.0\n",
       "...        ...         ...   ...     ...      ...    ...      ...      ...\n",
       "415201  415201  2023-04-15  2.32  33.293 -117.823   58.1      0.0      1.0\n",
       "415202  415202  2023-04-15  0.87  32.463 -116.804    1.2      0.0      1.0\n",
       "415203  415203  2023-04-15  0.86  33.395 -116.896   13.9      0.0      1.0\n",
       "415204  415204  2023-04-15  1.24  32.398 -116.239   20.1      0.0      1.0\n",
       "415205  415205  2023-04-15  0.74  33.481 -116.452   13.4      0.0      1.0\n",
       "\n",
       "[415206 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.copy()\n",
    "df2.loc[df2['MAG'] >= 5.5,'Count_L'] = 1\n",
    "df2.loc[df2['MAG'] < 5.5,'Count_S'] = 1\n",
    "df2[['Count_L','Count_S']] = df2[['Count_L','Count_S']].fillna(0)\n",
    "df2.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "500174a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count_S</th>\n",
       "      <th>Count_L</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>626.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>892.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>822.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>965.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>983.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Count_S  Count_L\n",
       "Year                  \n",
       "1980    626.0      0.0\n",
       "1981    892.0      1.0\n",
       "1982    822.0      2.0\n",
       "1983    965.0      4.0\n",
       "1984    983.0      4.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1yrctL = get_rolling_agg(df2, 'sum', 365, 'Count_L')\n",
    "df_1yrctS = get_rolling_agg(df2, 'sum', 365, 'Count_S')\n",
    "df_combined = df_1yrctS.join(df_1yrctL,rsuffix=\"L\")\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dba205c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>5.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>5.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>5.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>6.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>6.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MAG\n",
       "Year      \n",
       "1980  5.34\n",
       "1981  5.75\n",
       "1982  5.75\n",
       "1983  6.07\n",
       "1984  6.07"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1yrmax = get_rolling_agg(df, 'max', 365, 'MAG')\n",
    "df_5yrmax = get_rolling_agg(df, 'max', 365*5, 'MAG')\n",
    "df_10yrmax = get_rolling_agg(df, 'max', 365*10, 'MAG')\n",
    "df_5yrmax.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cb9d95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count_S</th>\n",
       "      <th>Count_L</th>\n",
       "      <th>MAG</th>\n",
       "      <th>MAG5yr</th>\n",
       "      <th>MAG10yr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>626.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.34</td>\n",
       "      <td>5.34</td>\n",
       "      <td>5.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>892.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>822.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>965.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.07</td>\n",
       "      <td>6.07</td>\n",
       "      <td>6.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>983.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.07</td>\n",
       "      <td>6.07</td>\n",
       "      <td>6.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Count_S  Count_L   MAG  MAG5yr  MAG10yr\n",
       "Year                                         \n",
       "1980    626.0      0.0  5.34    5.34     5.34\n",
       "1981    892.0      1.0  5.75    5.75     5.75\n",
       "1982    822.0      2.0  5.75    5.75     5.75\n",
       "1983    965.0      4.0  6.07    6.07     6.07\n",
       "1984    983.0      4.0  6.07    6.07     6.07"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined = df_combined.join(df_1yrmax,rsuffix=\"1yr\")\n",
    "df_combined = df_combined.join(df_5yrmax,rsuffix=\"5yr\")\n",
    "df_combined = df_combined.join(df_10yrmax,rsuffix=\"10yr\")\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c860bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.DataFrame(df_combined[['MAG','MAG5yr','MAG10yr']])\n",
    "ax = data.plot(style=['-', '--', ':'])\n",
    "ax.lines[0].set_alpha(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eec6e01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax2 = df_combined[['Count_L','Count_S']].plot(style=['-', '--', ':'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12ee94ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data headings:\n",
      "['MAG', 'MAG5yr', 'MAG10yr', 'Count_L', 'Count_S']\n",
      "\n",
      "Normalized data headings:\n",
      "['MAG', 'MAG5yr', 'MAG10yr', 'Count_L', 'Count_S']\n",
      "\n",
      "Normalized data:\n",
      "           MAG    MAG5yr   MAG10yr  Count_L   Count_S\n",
      "Year                                                 \n",
      "1980  0.660465  0.546584  0.496552      0.0  0.000000\n",
      "1981  0.851163  0.801242  0.779310      0.2  0.003733\n",
      "1982  0.851163  0.801242  0.779310      0.4  0.002750\n",
      "1983  1.000000  1.000000  1.000000      0.8  0.004757\n",
      "1984  1.000000  1.000000  1.000000      0.8  0.005010\n",
      "1985  0.813953  1.000000  1.000000      0.2  0.002400\n",
      "1986  0.809302  1.000000  1.000000      0.2  0.003522\n",
      "1987  0.809302  1.000000  1.000000      0.2  0.004982\n",
      "1988  0.711628  1.000000  1.000000      0.0  0.005052\n",
      "1989  0.679070  1.000000  1.000000      0.0  0.002091\n",
      "1990  0.739535  1.000000  1.000000      0.2  0.000912\n",
      "1991  0.739535  1.000000  1.000000      0.2  0.000870\n",
      "1992  0.860465  1.000000  1.000000      1.0  0.020474\n",
      "1993  0.860465  0.813665  1.000000      1.0  0.021161\n",
      "1994  0.916279  0.888199  1.000000      0.4  0.017457\n",
      "1995  0.916279  0.888199  1.000000      0.4  0.017232\n",
      "1996  0.851163  0.888199  1.000000      0.2  0.005557\n",
      "1997  0.851163  0.888199  1.000000      0.2  0.004112\n",
      "1998  0.623256  0.888199  1.000000      0.0  0.011437\n",
      "1999  0.860465  0.888199  1.000000      0.2  0.073335\n",
      "2000  0.860465  0.888199  0.875862      0.2  0.101681\n",
      "2001  0.451163  0.813665  0.875862      0.0  0.091690\n",
      "2002  0.451163  0.813665  0.875862      0.0  0.146965\n",
      "2003  0.427907  0.813665  0.875862      0.0  0.123811\n",
      "2004  0.460465  0.813665  0.875862      0.0  0.104474\n",
      "2005  0.497674  0.329193  0.875862      0.0  0.137156\n",
      "2006  0.497674  0.329193  0.793103      0.0  0.151539\n",
      "2007  0.376744  0.329193  0.793103      0.0  0.138643\n",
      "2008  0.493023  0.329193  0.793103      0.0  0.168940\n",
      "2009  0.493023  0.329193  0.793103      0.0  0.198788\n",
      "2010  0.623256  0.496894  0.441379      0.0  0.541046\n",
      "2011  0.623256  0.496894  0.441379      0.0  0.535601\n",
      "2012  0.251163  0.496894  0.441379      0.0  0.205425\n",
      "2013  0.251163  0.496894  0.441379      0.0  0.243398\n",
      "2014  0.172093  0.496894  0.441379      0.0  0.227078\n",
      "2015  0.148837  0.496894  0.441379      0.0  0.197637\n",
      "2016  0.055814  0.000000  0.441379      0.0  0.204134\n",
      "2017  0.032558  0.000000  0.441379      0.0  0.212638\n",
      "2018  0.325581  0.099379  0.441379      0.0  0.275154\n",
      "2019  0.325581  0.099379  0.441379      0.0  0.867138\n",
      "2020  0.139535  0.099379  0.441379      0.0  1.000000\n",
      "2021  0.172093  0.099379  0.000000      0.0  0.475148\n",
      "2022  0.172093  0.099379  0.000000      0.0  0.304075\n",
      "2023  0.000000  0.099379  0.000000      0.0  0.217437\n"
     ]
    }
   ],
   "source": [
    "# Define the columns to be normalized\n",
    "cols_to_norm = ['MAG','MAG5yr','MAG10yr','Count_L','Count_S']\n",
    "\n",
    "# Get the orignal data\n",
    "original_data = df_combined[cols_to_norm]\n",
    "\n",
    "# Get the normalized data\n",
    "normalized_data = (df_combined[cols_to_norm] - df_combined[cols_to_norm].min()) / (df_combined[cols_to_norm].max() - df_combined[cols_to_norm].min())\n",
    "\n",
    "print(\"Original data headings:\")\n",
    "print(original_data.columns.tolist())\n",
    "print(\"\\nNormalized data headings:\")\n",
    "print(normalized_data.columns.tolist())\n",
    "\n",
    "# Print the normalized data\n",
    "print(\"\\nNormalized data:\")\n",
    "print(normalized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d436231d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "normalized_data.to_csv('TransformedData.csv')\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dd8ebc",
   "metadata": {},
   "source": [
    "## Split Data for Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41669fbb",
   "metadata": {},
   "source": [
    "- Rolling windows: \n",
    "https://jakevdp.github.io/PythonDataScienceHandbook/03.11-working-with-time-series.html\n",
    "- On using a torch DataLoader:\n",
    "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "not that useful. https://visualstudiomagazine.com/articles/2020/09/10/pytorch-dataloader.aspx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a2c1ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "896eef92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Year</th>\n",
       "      <th>MAG</th>\n",
       "      <th>MAG5yr</th>\n",
       "      <th>MAG10yr</th>\n",
       "      <th>Count_L</th>\n",
       "      <th>Count_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1980</td>\n",
       "      <td>0.660465</td>\n",
       "      <td>0.546584</td>\n",
       "      <td>0.496552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1981</td>\n",
       "      <td>0.851163</td>\n",
       "      <td>0.801242</td>\n",
       "      <td>0.779310</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.003733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1982</td>\n",
       "      <td>0.851163</td>\n",
       "      <td>0.801242</td>\n",
       "      <td>0.779310</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.002750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1983</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.004757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.005010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Year       MAG    MAG5yr   MAG10yr  Count_L   Count_S\n",
       "0      0  1980  0.660465  0.546584  0.496552      0.0  0.000000\n",
       "1      1  1981  0.851163  0.801242  0.779310      0.2  0.003733\n",
       "2      2  1982  0.851163  0.801242  0.779310      0.4  0.002750\n",
       "3      3  1983  1.000000  1.000000  1.000000      0.8  0.004757\n",
       "4      4  1984  1.000000  1.000000  1.000000      0.8  0.005010"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined= pd.read_csv('TransformedData.csv')\n",
    "df_combined = df_combined.reset_index()\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "98783139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, labels, batch_size):\n",
    "    data.reset_index()\n",
    "    labels.reset_index()\n",
    "\n",
    "    x_train_val,x_test,y_train_val,y_test = train_test_split(data,labels,stratify=labels,test_size=0.20, random_state=42)\n",
    "    x_train,x_val,y_train,y_val = train_test_split(x_train_val,y_train_val,stratify=y_train_val,test_size=0.10, random_state=42)\n",
    "\n",
    "    num_classes = len(y_test.unique())\n",
    "    print(num_classes, y_test.unique())\n",
    "    \n",
    "    y_train = torch.tensor(y_train.values)\n",
    "    y_val = torch.tensor(y_val.values)\n",
    "    y_test = torch.tensor(y_test.values)\n",
    "\n",
    "    train_dataset = TensorDataset(torch.tensor(x_train.to_numpy()).to(torch.float32),y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "    val_dataset = TensorDataset(torch.tensor(x_val.to_numpy()).to(torch.float32),y_val)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    test_dataset = TensorDataset(torch.tensor(x_test.to_numpy()).to(torch.float32),y_test)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    \n",
    "    #print(type(x_train_val),type(x_test),type(y_test))\n",
    "    return test_loader, val_loader, train_loader, train_dataset, val_dataset, test_dataset, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07acdb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't encode target class...\n",
    "def encode_test(test):\n",
    "    num_classes = len(test.unique())\n",
    "    print(num_classes)\n",
    "\n",
    "    test = torch.nn.functional.one_hot(torch.LongTensor(test.values))\n",
    "    #y_test = (y_test - y_test.min())/(y_test.max() - y_test.min())\n",
    "\n",
    "    #print(test)\n",
    "\n",
    "    num_classes = test.shape[1]\n",
    "    print(test.shape, num_classes)\n",
    "    return test\n",
    "\n",
    "#y_train = encode_test(y_train)\n",
    "#y_val = encode_test(y_val)\n",
    "#print(y_test.shape)\n",
    "#y_test = encode_test(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4bf54214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dataset2(dataset, name):\n",
    "    print(name)\n",
    "    \n",
    "    x = pd.DataFrame(dataset.tensors[0])\n",
    "    y = pd.DataFrame(dataset.tensors[1])\n",
    "    \n",
    "    print(x)\n",
    "    print(y)\n",
    "\n",
    "def print_dataset(dataset, name):\n",
    "    print(name)\n",
    "    \n",
    "    x = dataset.tensors[0].numpy()\n",
    "    y = dataset.tensors[1].numpy()\n",
    "        \n",
    "    for i in range(0, len(dataset)):\n",
    "        row_x = '%s' % (x[i])\n",
    "        row_y = \"[%.04f]\" % (y[i])\n",
    "        \n",
    "        row = \"%s %s\" % (row_x, row_y)\n",
    "        print(row)\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e9dc46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "514299e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to plot final metrics\n",
    "# tr_results: Training metrics DataFrame\n",
    "# val_results: validation metrics DataFrame\n",
    "# tst_results: testing metrics DataFrame\n",
    "def plot_results(tr_results, val_results, tst_results):\n",
    "    # create a new index from epochs and iterations\n",
    "    \n",
    "    # denominator (max # iterations)\n",
    "    d = [tr_results[1].max() + 1\n",
    "         , val_results[1].max() + 1\n",
    "         , tst_results[1].max() + 1 ]\n",
    "    \n",
    "    i = 0\n",
    "    for v in [tr_results, val_results, tst_results]:\n",
    "        epoch = v[0]\n",
    "        iteration = v[1]\n",
    "        denominator = d[i]\n",
    "        percent = (iteration / denominator)\n",
    "        i = i + 1\n",
    "        v['index'] = epoch + percent\n",
    "        \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.suptitle('Training vs Validation')\n",
    "    ax1.set_title(\"Loss\")\n",
    "    ax1.plot(tr_results['index'],tr_results[2],'-',label=\"training\")\n",
    "    ax1.plot(val_results['index'],val_results[2],'-',label=\"validation\")\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.set_title(\"Accuracy\")\n",
    "    ax2.plot(tr_results['index'],tr_results[3],'-',label=\"training\")\n",
    "    ax2.plot(val_results['index'],val_results[3],'-',label=\"validation\")\n",
    "    ax2.legend()\n",
    "\n",
    "    print(\"test accuracy %.3f\" % max(tst_results[3]))\n",
    "\n",
    "# Helper function to run the model and return calculated accuracy & loss for the given data\n",
    "# Regardless of what data set it is (train, test, validation...)\n",
    "def run_model(device, model, inputs, labels, train=False):    \n",
    "    batch_size=inputs.size()[0]\n",
    "    \n",
    "    # send to GPU\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    \n",
    "    # Zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    logits = model(inputs)           #preds = model(inputs)\n",
    "    \n",
    "    # convert to formats accepted by CrossEntropyLoss\n",
    "    logits = logits.float()\n",
    "    labels = labels.long()\n",
    "    \n",
    "    # permute target to shape (batch_size, num_classes)\n",
    "    \n",
    "    #print(logits, labels)\n",
    "    \n",
    "    # calculate loss\n",
    "    loss = criterion(logits, labels) #loss = criterion(preds, labels)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    if train==True:\n",
    "        loss.backward()  # backward pass\n",
    "        optimizer.step() # update weights\n",
    "        \n",
    "    # Compute accuracy\n",
    "    probs = nn.functional.softmax(logits, dim=1)\n",
    "    _, preds = torch.max(probs, 1)\n",
    "    # predicted = torch.argmax(preds)  \n",
    "    \n",
    "    # Compute accuracy and loss\n",
    "    correct = torch.sum(preds == labels) # correct = torch.sum(predicted == labels)\n",
    "    acc = correct.double() / batch_size\n",
    "    loss += loss.item()\n",
    "    \n",
    "    return (loss / 100), acc\n",
    "\n",
    "# train, validdte, and test the model for X epochs in batches\n",
    "def train_test_model_epochs(model, num_epochs=5):\n",
    "    start_time = time.time()\n",
    "    print(\"Start \", start_time)\n",
    "\n",
    "    train_metrics = []\n",
    "    valid_metrics = []\n",
    "    test_metrics = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_acc = 0.0\n",
    "        valid_acc = 0.0\n",
    "        test_acc = 0.0\n",
    "\n",
    "        running_loss = 0.0\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        test_loss = 0.0\n",
    "\n",
    "        # Train model\n",
    "        j = 0\n",
    "        for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "            train_loss, train_acc = run_model(device, model, inputs, labels, train=True)\n",
    "            train_loss = train_loss.item()\n",
    "            train_acc  = train_acc.item()\n",
    "            train_metrics.append( (epoch, i, train_loss, train_acc))\n",
    "            j = i\n",
    "        print(epoch, j, train_loss, train_acc)\n",
    "\n",
    "        # change to evaluation mode\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # Validate model\n",
    "            for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "                valid_loss, valid_acc =  run_model(device, model, inputs, labels)\n",
    "                valid_metrics.append( (epoch, i, valid_loss.item(), valid_acc.item()) )\n",
    "            #print(epoch, 0, valid_loss, valid_acc)\n",
    "            \n",
    "            # Test model\n",
    "            for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "                test_loss, test_acc =  run_model(device, model, inputs, labels)\n",
    "            test_metrics.append( (epoch, 0, test_loss, test_acc) )\n",
    "            #print(epoch, test_loss, test_acc)\n",
    "            \n",
    "        # change back to training mode \n",
    "        model.train()\n",
    "\n",
    "        print('[%d] loss/acc for train: (%.3f, %.3f), valid: (%.3f, %.3f), test: (%.3f, %.3f)' %\n",
    "              (epoch + 1, train_loss, train_acc, \\\n",
    "               valid_loss, valid_acc, \\\n",
    "               test_loss, test_acc ))\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Done\", end_time - start_time)\n",
    "    \n",
    "    return train_metrics, valid_metrics, test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a1709425",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_variables, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.layer1 = nn.Linear(input_variables, 5)\n",
    "        self.layer2 = nn.Linear(5, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # check \n",
    "        #print(x.shape, x.dtype, self.layer1.weight.dtype)\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.layer2(x)\n",
    "        \n",
    "        # perform softmax outside\n",
    "        #x = self.softmax(self.layer1(x)) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c58c03d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 [0 1]\n",
      "2\n",
      "Start  1683924876.9559364\n",
      "0 0 0.014218372292816639 0.3870967741935484\n",
      "[1] loss/acc for train: (0.014, 0.387), valid: (0.014, 0.387), test: (0.014, 0.387)\n",
      "1 0 0.01420355960726738 0.3870967741935484\n",
      "[2] loss/acc for train: (0.014, 0.387), valid: (0.014, 0.387), test: (0.014, 0.387)\n",
      "2 0 0.014188796281814575 0.3870967741935484\n",
      "[3] loss/acc for train: (0.014, 0.387), valid: (0.014, 0.387), test: (0.014, 0.387)\n",
      "3 0 0.0141740832477808 0.3870967741935484\n",
      "[4] loss/acc for train: (0.014, 0.387), valid: (0.014, 0.387), test: (0.014, 0.387)\n",
      "4 0 0.014159422367811203 0.3870967741935484\n",
      "[5] loss/acc for train: (0.014, 0.387), valid: (0.014, 0.387), test: (0.014, 0.387)\n",
      "5 0 0.014144813641905785 0.3870967741935484\n",
      "[6] loss/acc for train: (0.014, 0.387), valid: (0.014, 0.387), test: (0.014, 0.387)\n",
      "6 0 0.014130258932709694 0.3870967741935484\n",
      "[7] loss/acc for train: (0.014, 0.387), valid: (0.014, 0.387), test: (0.014, 0.387)\n",
      "7 0 0.014115756377577782 0.3870967741935484\n",
      "[8] loss/acc for train: (0.014, 0.387), valid: (0.014, 0.387), test: (0.014, 0.387)\n",
      "8 0 0.014101310633122921 0.3870967741935484\n",
      "[9] loss/acc for train: (0.014, 0.387), valid: (0.014, 0.387), test: (0.014, 0.387)\n",
      "9 0 0.014086922630667686 0.3870967741935484\n",
      "[10] loss/acc for train: (0.014, 0.387), valid: (0.014, 0.387), test: (0.014, 0.387)\n",
      "10 0 0.014072587713599205 0.3870967741935484\n",
      "[11] loss/acc for train: (0.014, 0.387), valid: (0.014, 0.387), test: (0.014, 0.387)\n",
      "11 0 0.014058312401175499 0.3870967741935484\n",
      "[12] loss/acc for train: (0.014, 0.387), valid: (0.014, 0.387), test: (0.014, 0.387)\n",
      "12 0 0.014044094830751419 0.3870967741935484\n",
      "[13] loss/acc for train: (0.014, 0.387), valid: (0.014, 0.387), test: (0.014, 0.387)\n",
      "13 0 0.014029931277036667 0.3870967741935484\n",
      "[14] loss/acc for train: (0.014, 0.387), valid: (0.014, 0.387), test: (0.014, 0.387)\n",
      "14 0 0.014015828259289265 0.3870967741935484\n",
      "[15] loss/acc for train: (0.014, 0.387), valid: (0.014, 0.387), test: (0.014, 0.387)\n",
      "15 0 0.014001782052218914 0.3870967741935484\n",
      "[16] loss/acc for train: (0.014, 0.387), valid: (0.014, 0.387), test: (0.014, 0.387)\n",
      "16 0 0.013987796381115913 0.3870967741935484\n",
      "[17] loss/acc for train: (0.014, 0.387), valid: (0.014, 0.387), test: (0.014, 0.387)\n",
      "17 0 0.013973870314657688 0.3870967741935484\n",
      "[18] loss/acc for train: (0.014, 0.387), valid: (0.014, 0.387), test: (0.014, 0.387)\n",
      "18 0 0.013960002921521664 0.3870967741935484\n",
      "[19] loss/acc for train: (0.014, 0.387), valid: (0.014, 0.387), test: (0.014, 0.387)\n",
      "19 0 0.01394619420170784 0.3870967741935484\n",
      "[20] loss/acc for train: (0.014, 0.387), valid: (0.014, 0.387), test: (0.014, 0.387)\n",
      "20 0 0.013932444155216217 0.3870967741935484\n",
      "[21] loss/acc for train: (0.014, 0.387), valid: (0.014, 0.387), test: (0.014, 0.387)\n",
      "21 0 0.013918754644691944 0.3870967741935484\n",
      "[22] loss/acc for train: (0.014, 0.387), valid: (0.014, 0.387), test: (0.014, 0.387)\n",
      "22 0 0.013905121944844723 0.3870967741935484\n",
      "[23] loss/acc for train: (0.014, 0.387), valid: (0.014, 0.387), test: (0.014, 0.387)\n",
      "23 0 0.01389155164361 0.3870967741935484\n",
      "[24] loss/acc for train: (0.014, 0.387), valid: (0.014, 0.387), test: (0.014, 0.387)\n",
      "24 0 0.01387803815305233 0.3870967741935484\n",
      "[25] loss/acc for train: (0.014, 0.387), valid: (0.014, 0.387), test: (0.014, 0.387)\n",
      "25 0 0.013864587992429733 0.3870967741935484\n",
      "[26] loss/acc for train: (0.014, 0.387), valid: (0.014, 0.419), test: (0.014, 0.419)\n",
      "26 0 0.013851120136678219 0.41935483870967744\n",
      "[27] loss/acc for train: (0.014, 0.419), valid: (0.014, 0.419), test: (0.014, 0.419)\n",
      "27 0 0.01383768767118454 0.41935483870967744\n",
      "[28] loss/acc for train: (0.014, 0.419), valid: (0.014, 0.355), test: (0.014, 0.355)\n",
      "28 0 0.01382430549710989 0.3548387096774194\n",
      "[29] loss/acc for train: (0.014, 0.355), valid: (0.014, 0.387), test: (0.014, 0.387)\n",
      "29 0 0.01381097175180912 0.3870967741935484\n",
      "[30] loss/acc for train: (0.014, 0.387), valid: (0.014, 0.452), test: (0.014, 0.452)\n",
      "30 0 0.01379768829792738 0.45161290322580644\n",
      "[31] loss/acc for train: (0.014, 0.452), valid: (0.014, 0.484), test: (0.014, 0.484)\n",
      "31 0 0.013784454204142094 0.4838709677419355\n",
      "[32] loss/acc for train: (0.014, 0.484), valid: (0.014, 0.484), test: (0.014, 0.484)\n",
      "32 0 0.013771258294582367 0.4838709677419355\n",
      "[33] loss/acc for train: (0.014, 0.484), valid: (0.014, 0.516), test: (0.014, 0.516)\n",
      "33 0 0.01375800371170044 0.5161290322580645\n",
      "[34] loss/acc for train: (0.014, 0.516), valid: (0.014, 0.613), test: (0.014, 0.613)\n",
      "34 0 0.013744784519076347 0.6129032258064516\n",
      "[35] loss/acc for train: (0.014, 0.613), valid: (0.014, 0.710), test: (0.014, 0.710)\n",
      "35 0 0.013731607235968113 0.7096774193548387\n",
      "[36] loss/acc for train: (0.014, 0.710), valid: (0.014, 0.774), test: (0.014, 0.774)\n",
      "36 0 0.013718465343117714 0.7741935483870968\n",
      "[37] loss/acc for train: (0.014, 0.774), valid: (0.014, 0.774), test: (0.014, 0.774)\n",
      "37 0 0.013705364428460598 0.7741935483870968\n",
      "[38] loss/acc for train: (0.014, 0.774), valid: (0.014, 0.774), test: (0.014, 0.774)\n",
      "38 0 0.013692298904061317 0.7741935483870968\n",
      "[39] loss/acc for train: (0.014, 0.774), valid: (0.014, 0.774), test: (0.014, 0.774)\n",
      "39 0 0.013679273426532745 0.7741935483870968\n",
      "[40] loss/acc for train: (0.014, 0.774), valid: (0.014, 0.774), test: (0.014, 0.774)\n",
      "40 0 0.013666287995874882 0.7741935483870968\n",
      "[41] loss/acc for train: (0.014, 0.774), valid: (0.014, 0.742), test: (0.014, 0.742)\n",
      "41 0 0.013653300702571869 0.7419354838709677\n",
      "[42] loss/acc for train: (0.014, 0.742), valid: (0.014, 0.742), test: (0.014, 0.742)\n",
      "42 0 0.013640245422720909 0.7419354838709677\n",
      "[43] loss/acc for train: (0.014, 0.742), valid: (0.014, 0.774), test: (0.014, 0.774)\n",
      "43 0 0.013627213425934315 0.7741935483870968\n",
      "[44] loss/acc for train: (0.014, 0.774), valid: (0.014, 0.774), test: (0.014, 0.774)\n",
      "44 0 0.013614204712212086 0.7741935483870968\n",
      "[45] loss/acc for train: (0.014, 0.774), valid: (0.014, 0.677), test: (0.014, 0.677)\n",
      "45 0 0.01360122486948967 0.6774193548387096\n",
      "[46] loss/acc for train: (0.014, 0.677), valid: (0.014, 0.677), test: (0.014, 0.677)\n",
      "46 0 0.013588267378509045 0.6774193548387096\n",
      "[47] loss/acc for train: (0.014, 0.677), valid: (0.014, 0.677), test: (0.014, 0.677)\n",
      "47 0 0.01357533410191536 0.6774193548387096\n",
      "[48] loss/acc for train: (0.014, 0.677), valid: (0.014, 0.645), test: (0.014, 0.645)\n",
      "48 0 0.013562427833676338 0.6451612903225806\n",
      "[49] loss/acc for train: (0.014, 0.645), valid: (0.014, 0.645), test: (0.014, 0.645)\n",
      "49 0 0.013549545779824257 0.6451612903225806\n",
      "[50] loss/acc for train: (0.014, 0.645), valid: (0.014, 0.677), test: (0.014, 0.677)\n",
      "50 0 0.01353668887168169 0.6774193548387096\n",
      "[51] loss/acc for train: (0.014, 0.677), valid: (0.014, 0.677), test: (0.014, 0.677)\n",
      "51 0 0.013523858040571213 0.6774193548387096\n",
      "[52] loss/acc for train: (0.014, 0.677), valid: (0.014, 0.677), test: (0.014, 0.677)\n",
      "52 0 0.013511044904589653 0.6774193548387096\n",
      "[53] loss/acc for train: (0.014, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "53 0 0.013498259708285332 0.6774193548387096\n",
      "[54] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "54 0 0.013485496863722801 0.6774193548387096\n",
      "[55] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "55 0 0.013472753576934338 0.6774193548387096\n",
      "[56] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "56 0 0.01346001960337162 0.7096774193548387\n",
      "[57] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "57 0 0.013447296805679798 0.7096774193548387\n",
      "[58] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "58 0 0.013434589840471745 0.7096774193548387\n",
      "[59] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "59 0 0.013421901501715183 0.7096774193548387\n",
      "[60] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "60 0 0.013409231789410114 0.7096774193548387\n",
      "[61] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "61 0 0.013396581634879112 0.7096774193548387\n",
      "[62] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.742), test: (0.013, 0.742)\n",
      "62 0 0.013383949175477028 0.7419354838709677\n",
      "[63] loss/acc for train: (0.013, 0.742), valid: (0.013, 0.742), test: (0.013, 0.742)\n",
      "63 0 0.013371458277106285 0.7419354838709677\n",
      "[64] loss/acc for train: (0.013, 0.742), valid: (0.013, 0.742), test: (0.013, 0.742)\n",
      "64 0 0.013359053991734982 0.7419354838709677\n",
      "[65] loss/acc for train: (0.013, 0.742), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "65 0 0.013346683233976364 0.7096774193548387\n",
      "[66] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "66 0 0.013334345072507858 0.7096774193548387\n",
      "[67] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "67 0 0.013322034850716591 0.7096774193548387\n",
      "[68] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "68 0 0.013309755362570286 0.7096774193548387\n",
      "[69] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "69 0 0.013297505676746368 0.7096774193548387\n",
      "[70] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "70 0 0.01328528393059969 0.7096774193548387\n",
      "[71] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "71 0 0.01327308639883995 0.7096774193548387\n",
      "[72] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "72 0 0.013260914944112301 0.7096774193548387\n",
      "[73] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "73 0 0.013248768635094166 0.7096774193548387\n",
      "[74] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "74 0 0.013236694037914276 0.7096774193548387\n",
      "[75] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "75 0 0.013225095346570015 0.7096774193548387\n",
      "[76] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "76 0 0.01321346964687109 0.7096774193548387\n",
      "[77] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "77 0 0.013201744295656681 0.7096774193548387\n",
      "[78] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "78 0 0.013190052472054958 0.7096774193548387\n",
      "[79] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "79 0 0.013178394176065922 0.7096774193548387\n",
      "[80] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "80 0 0.013166767545044422 0.7096774193548387\n",
      "[81] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "81 0 0.013155171647667885 0.7096774193548387\n",
      "[82] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "82 0 0.01314360462129116 0.7096774193548387\n",
      "[83] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "83 0 0.013131819665431976 0.7096774193548387\n",
      "[84] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "84 0 0.013120008632540703 0.7096774193548387\n",
      "[85] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "85 0 0.01310819387435913 0.7096774193548387\n",
      "[86] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "86 0 0.013096380047500134 0.7096774193548387\n",
      "[87] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "87 0 0.013084568083286285 0.7096774193548387\n",
      "[88] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "88 0 0.013072751462459564 0.7096774193548387\n",
      "[89] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "89 0 0.013061012141406536 0.7096774193548387\n",
      "[90] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "90 0 0.013049558736383915 0.7096774193548387\n",
      "[91] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "91 0 0.013038136065006256 0.7096774193548387\n",
      "[92] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "92 0 0.013026741333305836 0.7096774193548387\n",
      "[93] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "93 0 0.01301537174731493 0.7096774193548387\n",
      "[94] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "94 0 0.013004027307033539 0.7096774193548387\n",
      "[95] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "95 0 0.01299270149320364 0.7096774193548387\n",
      "[96] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "96 0 0.012981398031115532 0.7096774193548387\n",
      "[97] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "97 0 0.012970108538866043 0.7096774193548387\n",
      "[98] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "98 0 0.012959578074514866 0.7096774193548387\n",
      "[99] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "99 0 0.012949674390256405 0.7096774193548387\n",
      "[100] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "100 0 0.012939822860062122 0.7096774193548387\n",
      "[101] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "101 0 0.012929991818964481 0.7096774193548387\n",
      "[102] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "102 0 0.012920188717544079 0.7096774193548387\n",
      "[103] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "103 0 0.01291041262447834 0.7096774193548387\n",
      "[104] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "104 0 0.012900659814476967 0.7096774193548387\n",
      "[105] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "105 0 0.012890932150185108 0.7096774193548387\n",
      "[106] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "106 0 0.012881235219538212 0.6774193548387096\n",
      "[107] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "107 0 0.012871555984020233 0.6774193548387096\n",
      "[108] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "108 0 0.012861904688179493 0.6774193548387096\n",
      "[109] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "109 0 0.012852272018790245 0.6774193548387096\n",
      "[110] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "110 0 0.01284265797585249 0.6774193548387096\n",
      "[111] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "111 0 0.012833061628043652 0.6774193548387096\n",
      "[112] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "112 0 0.012823423370718956 0.6774193548387096\n",
      "[113] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "113 0 0.012813795357942581 0.6774193548387096\n",
      "[114] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "114 0 0.012804176658391953 0.6774193548387096\n",
      "[115] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "115 0 0.01279456727206707 0.6774193548387096\n",
      "[116] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "116 0 0.012784963473677635 0.6774193548387096\n",
      "[117] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "117 0 0.012775365263223648 0.6774193548387096\n",
      "[118] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "118 0 0.012765772640705109 0.6774193548387096\n",
      "[119] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "119 0 0.01275618001818657 0.6774193548387096\n",
      "[120] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "120 0 0.012746588326990604 0.6774193548387096\n",
      "[121] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "121 0 0.012736993841826916 0.6774193548387096\n",
      "[122] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "122 0 0.012727398425340652 0.6774193548387096\n",
      "[123] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "123 0 0.012717796489596367 0.6774193548387096\n",
      "[124] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "124 0 0.012708191759884357 0.6774193548387096\n",
      "[125] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "125 0 0.012698574922978878 0.6774193548387096\n",
      "[126] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "126 0 0.012688950635492802 0.6774193548387096\n",
      "[127] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "127 0 0.012679314240813255 0.6774193548387096\n",
      "[128] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "128 0 0.01266966387629509 0.6774193548387096\n",
      "[129] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "129 0 0.012660038657486439 0.6774193548387096\n",
      "[130] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "130 0 0.0126504460349679 0.6774193548387096\n",
      "[131] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "131 0 0.012640825472772121 0.6774193548387096\n",
      "[132] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "132 0 0.012631180696189404 0.6774193548387096\n",
      "[133] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "133 0 0.012621507979929447 0.6774193548387096\n",
      "[134] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "134 0 0.012611809186637402 0.6774193548387096\n",
      "[135] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "135 0 0.01260207686573267 0.6774193548387096\n",
      "[136] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "136 0 0.012592312879860401 0.6774193548387096\n",
      "[137] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "137 0 0.01258252002298832 0.6774193548387096\n",
      "[138] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "138 0 0.012572691775858402 0.7096774193548387\n",
      "[139] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "139 0 0.012562825344502926 0.7096774193548387\n",
      "[140] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "140 0 0.01255292259156704 0.7096774193548387\n",
      "[141] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "141 0 0.012542984448373318 0.7096774193548387\n",
      "[142] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "142 0 0.012533001601696014 0.7096774193548387\n",
      "[143] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "143 0 0.012522978708148003 0.7096774193548387\n",
      "[144] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "144 0 0.012512910179793835 0.7096774193548387\n",
      "[145] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "145 0 0.012502798810601234 0.7096774193548387\n",
      "[146] loss/acc for train: (0.013, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "146 0 0.012492644600570202 0.7096774193548387\n",
      "[147] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "147 0 0.012482482939958572 0.7096774193548387\n",
      "[148] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "148 0 0.012472267262637615 0.7096774193548387\n",
      "[149] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "149 0 0.012461994774639606 0.7096774193548387\n",
      "[150] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "150 0 0.012451664544641972 0.7096774193548387\n",
      "[151] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "151 0 0.012441274709999561 0.7096774193548387\n",
      "[152] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "152 0 0.01243082620203495 0.7096774193548387\n",
      "[153] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "153 0 0.01242031529545784 0.7096774193548387\n",
      "[154] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "154 0 0.012409765273332596 0.7096774193548387\n",
      "[155] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "155 0 0.012399165891110897 0.7096774193548387\n",
      "[156] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "156 0 0.012388519011437893 0.7096774193548387\n",
      "[157] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "157 0 0.012377884238958359 0.7096774193548387\n",
      "[158] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "158 0 0.012367188930511475 0.7096774193548387\n",
      "[159] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "159 0 0.012356431223452091 0.7096774193548387\n",
      "[160] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "160 0 0.012345633469522 0.7096774193548387\n",
      "[161] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "161 0 0.01233478169888258 0.7096774193548387\n",
      "[162] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "162 0 0.012323861010372639 0.7096774193548387\n",
      "[163] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "163 0 0.012312935665249825 0.7096774193548387\n",
      "[164] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "164 0 0.012301962822675705 0.7096774193548387\n",
      "[165] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "165 0 0.012290921993553638 0.7096774193548387\n",
      "[166] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "166 0 0.01227985043078661 0.7096774193548387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[167] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "167 0 0.012268717400729656 0.7096774193548387\n",
      "[168] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "168 0 0.01225755363702774 0.7096774193548387\n",
      "[169] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "169 0 0.012246314436197281 0.7096774193548387\n",
      "[170] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "170 0 0.012234997935593128 0.7096774193548387\n",
      "[171] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "171 0 0.012223627418279648 0.7096774193548387\n",
      "[172] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "172 0 0.012212198227643967 0.7096774193548387\n",
      "[173] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "173 0 0.012200694531202316 0.7096774193548387\n",
      "[174] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "174 0 0.012189111672341824 0.7096774193548387\n",
      "[175] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "175 0 0.01217745617032051 0.7096774193548387\n",
      "[176] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "176 0 0.012165725231170654 0.7096774193548387\n",
      "[177] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "177 0 0.012153956107795238 0.7096774193548387\n",
      "[178] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "178 0 0.012142101302742958 0.7096774193548387\n",
      "[179] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "179 0 0.01213016640394926 0.7096774193548387\n",
      "[180] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "180 0 0.012118147686123848 0.7096774193548387\n",
      "[181] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "181 0 0.012106047943234444 0.7096774193548387\n",
      "[182] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "182 0 0.012093912810087204 0.7096774193548387\n",
      "[183] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "183 0 0.012081693857908249 0.7096774193548387\n",
      "[184] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "184 0 0.012069395743310452 0.7096774193548387\n",
      "[185] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "185 0 0.012057017534971237 0.7096774193548387\n",
      "[186] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "186 0 0.012044558301568031 0.7096774193548387\n",
      "[187] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "187 0 0.012032016180455685 0.7096774193548387\n",
      "[188] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "188 0 0.012019363231956959 0.7096774193548387\n",
      "[189] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "189 0 0.012006577104330063 0.7096774193548387\n",
      "[190] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "190 0 0.011993706226348877 0.7096774193548387\n",
      "[191] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "191 0 0.011980732902884483 0.7096774193548387\n",
      "[192] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "192 0 0.011967656202614307 0.7096774193548387\n",
      "[193] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "193 0 0.011954493820667267 0.7096774193548387\n",
      "[194] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.742), test: (0.012, 0.742)\n",
      "194 0 0.011941258795559406 0.7419354838709677\n",
      "[195] loss/acc for train: (0.012, 0.742), valid: (0.012, 0.742), test: (0.012, 0.742)\n",
      "195 0 0.01192792784422636 0.7419354838709677\n",
      "[196] loss/acc for train: (0.012, 0.742), valid: (0.012, 0.742), test: (0.012, 0.742)\n",
      "196 0 0.011914503760635853 0.7419354838709677\n",
      "[197] loss/acc for train: (0.012, 0.742), valid: (0.012, 0.742), test: (0.012, 0.742)\n",
      "197 0 0.01190098561346531 0.7419354838709677\n",
      "[198] loss/acc for train: (0.012, 0.742), valid: (0.012, 0.742), test: (0.012, 0.742)\n",
      "198 0 0.01188739389181137 0.7419354838709677\n",
      "[199] loss/acc for train: (0.012, 0.742), valid: (0.012, 0.742), test: (0.012, 0.742)\n",
      "199 0 0.011873709037899971 0.7419354838709677\n",
      "[200] loss/acc for train: (0.012, 0.742), valid: (0.012, 0.742), test: (0.012, 0.742)\n",
      "200 0 0.011859926395118237 0.7419354838709677\n",
      "[201] loss/acc for train: (0.012, 0.742), valid: (0.012, 0.742), test: (0.012, 0.742)\n",
      "201 0 0.011846057139337063 0.7419354838709677\n",
      "[202] loss/acc for train: (0.012, 0.742), valid: (0.012, 0.742), test: (0.012, 0.742)\n",
      "202 0 0.01183211337774992 0.7419354838709677\n",
      "[203] loss/acc for train: (0.012, 0.742), valid: (0.012, 0.742), test: (0.012, 0.742)\n",
      "203 0 0.011818071827292442 0.7419354838709677\n",
      "[204] loss/acc for train: (0.012, 0.742), valid: (0.012, 0.742), test: (0.012, 0.742)\n",
      "204 0 0.011803938075900078 0.7419354838709677\n",
      "[205] loss/acc for train: (0.012, 0.742), valid: (0.012, 0.742), test: (0.012, 0.742)\n",
      "205 0 0.011789713986217976 0.7419354838709677\n",
      "[206] loss/acc for train: (0.012, 0.742), valid: (0.012, 0.742), test: (0.012, 0.742)\n",
      "206 0 0.011775429360568523 0.7419354838709677\n",
      "[207] loss/acc for train: (0.012, 0.742), valid: (0.012, 0.742), test: (0.012, 0.742)\n",
      "207 0 0.011761044152081013 0.7419354838709677\n",
      "[208] loss/acc for train: (0.012, 0.742), valid: (0.012, 0.742), test: (0.012, 0.742)\n",
      "208 0 0.011746558360755444 0.7419354838709677\n",
      "[209] loss/acc for train: (0.012, 0.742), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "209 0 0.01173197478055954 0.7096774193548387\n",
      "[210] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "210 0 0.011717330664396286 0.7096774193548387\n",
      "[211] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "211 0 0.011702592484652996 0.7096774193548387\n",
      "[212] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "212 0 0.011687763966619968 0.7096774193548387\n",
      "[213] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "213 0 0.011672857217490673 0.7096774193548387\n",
      "[214] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "214 0 0.011657861061394215 0.7096774193548387\n",
      "[215] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "215 0 0.011642776429653168 0.7096774193548387\n",
      "[216] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "216 0 0.011627615429461002 0.7096774193548387\n",
      "[217] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "217 0 0.0116123603656888 0.7096774193548387\n",
      "[218] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "218 0 0.011596945114433765 0.7096774193548387\n",
      "[219] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "219 0 0.011581388302147388 0.7096774193548387\n",
      "[220] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "220 0 0.011565737426280975 0.7096774193548387\n",
      "[221] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "221 0 0.011549987830221653 0.7096774193548387\n",
      "[222] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "222 0 0.011534146964550018 0.7096774193548387\n",
      "[223] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "223 0 0.011518201790750027 0.7096774193548387\n",
      "[224] loss/acc for train: (0.012, 0.710), valid: (0.012, 0.710), test: (0.012, 0.710)\n",
      "224 0 0.011502185836434364 0.7096774193548387\n",
      "[225] loss/acc for train: (0.012, 0.710), valid: (0.011, 0.710), test: (0.011, 0.710)\n",
      "225 0 0.011486070230603218 0.7096774193548387\n",
      "[226] loss/acc for train: (0.011, 0.710), valid: (0.011, 0.710), test: (0.011, 0.710)\n",
      "226 0 0.011469844728708267 0.7096774193548387\n",
      "[227] loss/acc for train: (0.011, 0.710), valid: (0.011, 0.710), test: (0.011, 0.710)\n",
      "227 0 0.011453557759523392 0.7096774193548387\n",
      "[228] loss/acc for train: (0.011, 0.710), valid: (0.011, 0.710), test: (0.011, 0.710)\n",
      "228 0 0.011437182314693928 0.7096774193548387\n",
      "[229] loss/acc for train: (0.011, 0.710), valid: (0.011, 0.710), test: (0.011, 0.710)\n",
      "229 0 0.011420708149671555 0.7096774193548387\n",
      "[230] loss/acc for train: (0.011, 0.710), valid: (0.011, 0.710), test: (0.011, 0.710)\n",
      "230 0 0.01140415109694004 0.7096774193548387\n",
      "[231] loss/acc for train: (0.011, 0.710), valid: (0.011, 0.710), test: (0.011, 0.710)\n",
      "231 0 0.011387504637241364 0.7096774193548387\n",
      "[232] loss/acc for train: (0.011, 0.710), valid: (0.011, 0.710), test: (0.011, 0.710)\n",
      "232 0 0.011370774358510971 0.7096774193548387\n",
      "[233] loss/acc for train: (0.011, 0.710), valid: (0.011, 0.710), test: (0.011, 0.710)\n",
      "233 0 0.011353974230587482 0.7096774193548387\n",
      "[234] loss/acc for train: (0.011, 0.710), valid: (0.011, 0.710), test: (0.011, 0.710)\n",
      "234 0 0.01133707445114851 0.7096774193548387\n",
      "[235] loss/acc for train: (0.011, 0.710), valid: (0.011, 0.710), test: (0.011, 0.710)\n",
      "235 0 0.011320136487483978 0.7096774193548387\n",
      "[236] loss/acc for train: (0.011, 0.710), valid: (0.011, 0.710), test: (0.011, 0.710)\n",
      "236 0 0.01130310632288456 0.7096774193548387\n",
      "[237] loss/acc for train: (0.011, 0.710), valid: (0.011, 0.710), test: (0.011, 0.710)\n",
      "237 0 0.01128598302602768 0.7096774193548387\n",
      "[238] loss/acc for train: (0.011, 0.710), valid: (0.011, 0.710), test: (0.011, 0.710)\n",
      "238 0 0.011268772184848785 0.7096774193548387\n",
      "[239] loss/acc for train: (0.011, 0.710), valid: (0.011, 0.710), test: (0.011, 0.710)\n",
      "239 0 0.011251493357121944 0.7096774193548387\n",
      "[240] loss/acc for train: (0.011, 0.710), valid: (0.011, 0.710), test: (0.011, 0.710)\n",
      "240 0 0.011234156787395477 0.7096774193548387\n",
      "[241] loss/acc for train: (0.011, 0.710), valid: (0.011, 0.710), test: (0.011, 0.710)\n",
      "241 0 0.01121674757450819 0.7096774193548387\n",
      "[242] loss/acc for train: (0.011, 0.710), valid: (0.011, 0.710), test: (0.011, 0.710)\n",
      "242 0 0.011199254542589188 0.7096774193548387\n",
      "[243] loss/acc for train: (0.011, 0.710), valid: (0.011, 0.742), test: (0.011, 0.742)\n",
      "243 0 0.011181695386767387 0.7419354838709677\n",
      "[244] loss/acc for train: (0.011, 0.742), valid: (0.011, 0.806), test: (0.011, 0.806)\n",
      "244 0 0.011164081282913685 0.8064516129032258\n",
      "[245] loss/acc for train: (0.011, 0.806), valid: (0.011, 0.806), test: (0.011, 0.806)\n",
      "245 0 0.011146391741931438 0.8064516129032258\n",
      "[246] loss/acc for train: (0.011, 0.806), valid: (0.011, 0.806), test: (0.011, 0.806)\n",
      "246 0 0.011128628626465797 0.8064516129032258\n",
      "[247] loss/acc for train: (0.011, 0.806), valid: (0.011, 0.806), test: (0.011, 0.806)\n",
      "247 0 0.011110801249742508 0.8064516129032258\n",
      "[248] loss/acc for train: (0.011, 0.806), valid: (0.011, 0.806), test: (0.011, 0.806)\n",
      "248 0 0.011092945002019405 0.8064516129032258\n",
      "[249] loss/acc for train: (0.011, 0.806), valid: (0.011, 0.806), test: (0.011, 0.806)\n",
      "249 0 0.011075061745941639 0.8064516129032258\n",
      "[250] loss/acc for train: (0.011, 0.806), valid: (0.011, 0.806), test: (0.011, 0.806)\n",
      "250 0 0.011057134717702866 0.8064516129032258\n",
      "[251] loss/acc for train: (0.011, 0.806), valid: (0.011, 0.806), test: (0.011, 0.806)\n",
      "251 0 0.011039147153496742 0.8064516129032258\n",
      "[252] loss/acc for train: (0.011, 0.806), valid: (0.011, 0.806), test: (0.011, 0.806)\n",
      "252 0 0.011021124199032784 0.8064516129032258\n",
      "[253] loss/acc for train: (0.011, 0.806), valid: (0.011, 0.806), test: (0.011, 0.806)\n",
      "253 0 0.011003035120666027 0.8064516129032258\n",
      "[254] loss/acc for train: (0.011, 0.806), valid: (0.011, 0.806), test: (0.011, 0.806)\n",
      "254 0 0.010984883643686771 0.8064516129032258\n",
      "[255] loss/acc for train: (0.011, 0.806), valid: (0.011, 0.806), test: (0.011, 0.806)\n",
      "255 0 0.01096669677644968 0.8064516129032258\n",
      "[256] loss/acc for train: (0.011, 0.806), valid: (0.011, 0.839), test: (0.011, 0.839)\n",
      "256 0 0.01094846148043871 0.8387096774193549\n",
      "[257] loss/acc for train: (0.011, 0.839), valid: (0.011, 0.839), test: (0.011, 0.839)\n",
      "257 0 0.010930177755653858 0.8387096774193549\n",
      "[258] loss/acc for train: (0.011, 0.839), valid: (0.011, 0.871), test: (0.011, 0.871)\n",
      "258 0 0.010911848396062851 0.8709677419354839\n",
      "[259] loss/acc for train: (0.011, 0.871), valid: (0.011, 0.871), test: (0.011, 0.871)\n",
      "259 0 0.01089347992092371 0.8709677419354839\n",
      "[260] loss/acc for train: (0.011, 0.871), valid: (0.011, 0.871), test: (0.011, 0.871)\n",
      "260 0 0.010875057429075241 0.8709677419354839\n",
      "[261] loss/acc for train: (0.011, 0.871), valid: (0.011, 0.871), test: (0.011, 0.871)\n",
      "261 0 0.010856599546968937 0.8709677419354839\n",
      "[262] loss/acc for train: (0.011, 0.871), valid: (0.011, 0.871), test: (0.011, 0.871)\n",
      "262 0 0.010838103480637074 0.8709677419354839\n",
      "[263] loss/acc for train: (0.011, 0.871), valid: (0.011, 0.871), test: (0.011, 0.871)\n",
      "263 0 0.01081955898553133 0.8709677419354839\n",
      "[264] loss/acc for train: (0.011, 0.871), valid: (0.011, 0.871), test: (0.011, 0.871)\n",
      "264 0 0.010800966992974281 0.8709677419354839\n",
      "[265] loss/acc for train: (0.011, 0.871), valid: (0.011, 0.871), test: (0.011, 0.871)\n",
      "265 0 0.01078236848115921 0.8709677419354839\n",
      "[266] loss/acc for train: (0.011, 0.871), valid: (0.011, 0.871), test: (0.011, 0.871)\n",
      "266 0 0.010763718746602535 0.8709677419354839\n",
      "[267] loss/acc for train: (0.011, 0.871), valid: (0.011, 0.871), test: (0.011, 0.871)\n",
      "267 0 0.010745017789304256 0.8709677419354839\n",
      "[268] loss/acc for train: (0.011, 0.871), valid: (0.011, 0.871), test: (0.011, 0.871)\n",
      "268 0 0.010726281441748142 0.8709677419354839\n",
      "[269] loss/acc for train: (0.011, 0.871), valid: (0.011, 0.871), test: (0.011, 0.871)\n",
      "269 0 0.010707532986998558 0.8709677419354839\n",
      "[270] loss/acc for train: (0.011, 0.871), valid: (0.011, 0.871), test: (0.011, 0.871)\n",
      "270 0 0.01068874355405569 0.8709677419354839\n",
      "[271] loss/acc for train: (0.011, 0.871), valid: (0.011, 0.871), test: (0.011, 0.871)\n",
      "271 0 0.010669915936887264 0.8709677419354839\n",
      "[272] loss/acc for train: (0.011, 0.871), valid: (0.011, 0.871), test: (0.011, 0.871)\n",
      "272 0 0.010651077143847942 0.8709677419354839\n",
      "[273] loss/acc for train: (0.011, 0.871), valid: (0.011, 0.871), test: (0.011, 0.871)\n",
      "273 0 0.010632205754518509 0.8709677419354839\n",
      "[274] loss/acc for train: (0.011, 0.871), valid: (0.011, 0.871), test: (0.011, 0.871)\n",
      "274 0 0.01061328873038292 0.8709677419354839\n",
      "[275] loss/acc for train: (0.011, 0.871), valid: (0.011, 0.871), test: (0.011, 0.871)\n",
      "275 0 0.01059437170624733 0.8709677419354839\n",
      "[276] loss/acc for train: (0.011, 0.871), valid: (0.011, 0.871), test: (0.011, 0.871)\n",
      "276 0 0.010575429536402225 0.8709677419354839\n",
      "[277] loss/acc for train: (0.011, 0.871), valid: (0.011, 0.839), test: (0.011, 0.839)\n",
      "277 0 0.010556453838944435 0.8387096774193549\n",
      "[278] loss/acc for train: (0.011, 0.839), valid: (0.011, 0.839), test: (0.011, 0.839)\n",
      "278 0 0.010537449270486832 0.8387096774193549\n",
      "[279] loss/acc for train: (0.011, 0.839), valid: (0.011, 0.839), test: (0.011, 0.839)\n",
      "279 0 0.010518415831029415 0.8387096774193549\n",
      "[280] loss/acc for train: (0.011, 0.839), valid: (0.010, 0.839), test: (0.010, 0.839)\n",
      "280 0 0.010499410331249237 0.8387096774193549\n",
      "[281] loss/acc for train: (0.010, 0.839), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "281 0 0.010480370372533798 0.8064516129032258\n",
      "[282] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "282 0 0.010461295954883099 0.8064516129032258\n",
      "[283] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "283 0 0.010442188940942287 0.8064516129032258\n",
      "[284] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "284 0 0.010423076339066029 0.8064516129032258\n",
      "[285] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "285 0 0.010403976775705814 0.8064516129032258\n",
      "[286] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "286 0 0.010384853929281235 0.8064516129032258\n",
      "[287] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "287 0 0.010365711525082588 0.8064516129032258\n",
      "[288] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "288 0 0.010346549563109875 0.8064516129032258\n",
      "[289] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "289 0 0.010327419266104698 0.8064516129032258\n",
      "[290] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "290 0 0.01030827034264803 0.8064516129032258\n",
      "[291] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "291 0 0.010289099998772144 0.8064516129032258\n",
      "[292] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "292 0 0.010269910097122192 0.8064516129032258\n",
      "[293] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "293 0 0.010250728577375412 0.8064516129032258\n",
      "[294] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "294 0 0.0102315628901124 0.8064516129032258\n",
      "[295] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "295 0 0.010212384164333344 0.8064516129032258\n",
      "[296] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "296 0 0.010193194262683392 0.8064516129032258\n",
      "[297] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "297 0 0.010174006223678589 0.8064516129032258\n",
      "[298] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "298 0 0.010154835879802704 0.8064516129032258\n",
      "[299] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "299 0 0.010135655291378498 0.8064516129032258\n",
      "[300] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "300 0 0.010116497054696083 0.8064516129032258\n",
      "[301] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "301 0 0.010097337886691093 0.8064516129032258\n",
      "[302] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "302 0 0.010078173130750656 0.8064516129032258\n",
      "[303] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "303 0 0.010059015825390816 0.8064516129032258\n",
      "[304] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "304 0 0.010039878077805042 0.8064516129032258\n",
      "[305] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "305 0 0.01002073846757412 0.8064516129032258\n",
      "[306] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "306 0 0.010001634247601032 0.8064516129032258\n",
      "[307] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "307 0 0.009982530027627945 0.8064516129032258\n",
      "[308] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "308 0 0.009963425807654858 0.8064516129032258\n",
      "[309] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "309 0 0.009944327175617218 0.8064516129032258\n",
      "[310] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "310 0 0.009925264865159988 0.8064516129032258\n",
      "[311] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "311 0 0.009906203486025333 0.8064516129032258\n",
      "[312] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "312 0 0.009887183085083961 0.8064516129032258\n",
      "[313] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "313 0 0.009868167340755463 0.8064516129032258\n",
      "[314] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314 0 0.009849156253039837 0.8064516129032258\n",
      "[315] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "315 0 0.009830176830291748 0.8064516129032258\n",
      "[316] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "316 0 0.009811226278543472 0.8064516129032258\n",
      "[317] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "317 0 0.009792281314730644 0.8064516129032258\n",
      "[318] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "318 0 0.00977335125207901 0.8064516129032258\n",
      "[319] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "319 0 0.009754473343491554 0.8064516129032258\n",
      "[320] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "320 0 0.009735610336065292 0.8064516129032258\n",
      "[321] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "321 0 0.009716756641864777 0.8064516129032258\n",
      "[322] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "322 0 0.00969791505485773 0.8064516129032258\n",
      "[323] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "323 0 0.009679126553237438 0.8064516129032258\n",
      "[324] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "324 0 0.009660356678068638 0.8064516129032258\n",
      "[325] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "325 0 0.009641625918447971 0.8064516129032258\n",
      "[326] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "326 0 0.009622914716601372 0.8064516129032258\n",
      "[327] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "327 0 0.00960423145443201 0.8064516129032258\n",
      "[328] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "328 0 0.009585585445165634 0.8064516129032258\n",
      "[329] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "329 0 0.009566960856318474 0.8064516129032258\n",
      "[330] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "330 0 0.00954838003963232 0.8064516129032258\n",
      "[331] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "331 0 0.009529825299978256 0.8064516129032258\n",
      "[332] loss/acc for train: (0.010, 0.806), valid: (0.010, 0.806), test: (0.010, 0.806)\n",
      "332 0 0.009511299431324005 0.8064516129032258\n",
      "[333] loss/acc for train: (0.010, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "333 0 0.009492815472185612 0.8064516129032258\n",
      "[334] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "334 0 0.009474359452724457 0.8064516129032258\n",
      "[335] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "335 0 0.009455949999392033 0.8064516129032258\n",
      "[336] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "336 0 0.009437565691769123 0.8064516129032258\n",
      "[337] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "337 0 0.009419223293662071 0.8064516129032258\n",
      "[338] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "338 0 0.009400921873748302 0.8064516129032258\n",
      "[339] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "339 0 0.00938265211880207 0.8064516129032258\n",
      "[340] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "340 0 0.009364413097500801 0.8064516129032258\n",
      "[341] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "341 0 0.009346241131424904 0.8064516129032258\n",
      "[342] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "342 0 0.009328091517090797 0.8064516129032258\n",
      "[343] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "343 0 0.009309961460530758 0.8064516129032258\n",
      "[344] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "344 0 0.009291911497712135 0.8064516129032258\n",
      "[345] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "345 0 0.009273895993828773 0.8064516129032258\n",
      "[346] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "346 0 0.009255916811525822 0.8064516129032258\n",
      "[347] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "347 0 0.009237973019480705 0.8064516129032258\n",
      "[348] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "348 0 0.009220066480338573 0.8064516129032258\n",
      "[349] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "349 0 0.00920219998806715 0.8064516129032258\n",
      "[350] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "350 0 0.009184373542666435 0.8064516129032258\n",
      "[351] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "351 0 0.00916663184762001 0.8064516129032258\n",
      "[352] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "352 0 0.009148921817541122 0.8064516129032258\n",
      "[353] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "353 0 0.009131228551268578 0.8064516129032258\n",
      "[354] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "354 0 0.00911357905715704 0.8064516129032258\n",
      "[355] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "355 0 0.009096005000174046 0.8064516129032258\n",
      "[356] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "356 0 0.009078471921384335 0.8064516129032258\n",
      "[357] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "357 0 0.00906098261475563 0.8064516129032258\n",
      "[358] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "358 0 0.009043538011610508 0.8064516129032258\n",
      "[359] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "359 0 0.009026136249303818 0.8064516129032258\n",
      "[360] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "360 0 0.009008794091641903 0.8064516129032258\n",
      "[361] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "361 0 0.008991495706140995 0.8064516129032258\n",
      "[362] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "362 0 0.008974248543381691 0.8064516129032258\n",
      "[363] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "363 0 0.008957057259976864 0.8064516129032258\n",
      "[364] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "364 0 0.008939911611378193 0.8064516129032258\n",
      "[365] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "365 0 0.008922812528908253 0.8064516129032258\n",
      "[366] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "366 0 0.008905760943889618 0.8064516129032258\n",
      "[367] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "367 0 0.008888758718967438 0.8064516129032258\n",
      "[368] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "368 0 0.008871841244399548 0.8064516129032258\n",
      "[369] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "369 0 0.008854944258928299 0.8064516129032258\n",
      "[370] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "370 0 0.008838082663714886 0.8064516129032258\n",
      "[371] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "371 0 0.008821298368275166 0.8064516129032258\n",
      "[372] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "372 0 0.00880456529557705 0.8064516129032258\n",
      "[373] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "373 0 0.008787881582975388 0.8064516129032258\n",
      "[374] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "374 0 0.008771248161792755 0.8064516129032258\n",
      "[375] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "375 0 0.008754665032029152 0.8064516129032258\n",
      "[376] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "376 0 0.008738139644265175 0.8064516129032258\n",
      "[377] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "377 0 0.008721664547920227 0.8064516129032258\n",
      "[378] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "378 0 0.008705247193574905 0.8064516129032258\n",
      "[379] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "379 0 0.008688881993293762 0.8064516129032258\n",
      "[380] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.806), test: (0.009, 0.806)\n",
      "380 0 0.008672579191625118 0.8064516129032258\n",
      "[381] loss/acc for train: (0.009, 0.806), valid: (0.009, 0.839), test: (0.009, 0.839)\n",
      "381 0 0.008656318299472332 0.8387096774193549\n",
      "[382] loss/acc for train: (0.009, 0.839), valid: (0.009, 0.839), test: (0.009, 0.839)\n",
      "382 0 0.00864011887460947 0.8387096774193549\n",
      "[383] loss/acc for train: (0.009, 0.839), valid: (0.009, 0.839), test: (0.009, 0.839)\n",
      "383 0 0.008623972535133362 0.8387096774193549\n",
      "[384] loss/acc for train: (0.009, 0.839), valid: (0.009, 0.839), test: (0.009, 0.839)\n",
      "384 0 0.008607878349721432 0.8387096774193549\n",
      "[385] loss/acc for train: (0.009, 0.839), valid: (0.009, 0.839), test: (0.009, 0.839)\n",
      "385 0 0.008591839112341404 0.8387096774193549\n",
      "[386] loss/acc for train: (0.009, 0.839), valid: (0.009, 0.839), test: (0.009, 0.839)\n",
      "386 0 0.008575853891670704 0.8387096774193549\n",
      "[387] loss/acc for train: (0.009, 0.839), valid: (0.009, 0.839), test: (0.009, 0.839)\n",
      "387 0 0.008559930138289928 0.8387096774193549\n",
      "[388] loss/acc for train: (0.009, 0.839), valid: (0.009, 0.839), test: (0.009, 0.839)\n",
      "388 0 0.008544058538973331 0.8387096774193549\n",
      "[389] loss/acc for train: (0.009, 0.839), valid: (0.009, 0.839), test: (0.009, 0.839)\n",
      "389 0 0.008528242819011211 0.8387096774193549\n",
      "[390] loss/acc for train: (0.009, 0.839), valid: (0.009, 0.839), test: (0.009, 0.839)\n",
      "390 0 0.00851247925311327 0.8387096774193549\n",
      "[391] loss/acc for train: (0.009, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "391 0 0.00849677249789238 0.8387096774193549\n",
      "[392] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "392 0 0.008481117896735668 0.8387096774193549\n",
      "[393] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "393 0 0.008465532213449478 0.8387096774193549\n",
      "[394] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "394 0 0.008449983783066273 0.8387096774193549\n",
      "[395] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "395 0 0.008434503339231014 0.8387096774193549\n",
      "[396] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "396 0 0.008419075980782509 0.8387096774193549\n",
      "[397] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "397 0 0.008403703570365906 0.8387096774193549\n",
      "[398] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "398 0 0.008388386107981205 0.8387096774193549\n",
      "[399] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "399 0 0.00837312638759613 0.8387096774193549\n",
      "[400] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "400 0 0.008357921615242958 0.8387096774193549\n",
      "[401] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "401 0 0.008342776447534561 0.8709677419354839\n",
      "[402] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "402 0 0.008327687159180641 0.8709677419354839\n",
      "[403] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "403 0 0.008312650956213474 0.8709677419354839\n",
      "[404] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "404 0 0.008297672495245934 0.8709677419354839\n",
      "[405] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "405 0 0.00828274991363287 0.8709677419354839\n",
      "[406] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "406 0 0.008267880417406559 0.8709677419354839\n",
      "[407] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "407 0 0.008253068663179874 0.8709677419354839\n",
      "[408] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "408 0 0.008238311856985092 0.8709677419354839\n",
      "[409] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "409 0 0.008223610930144787 0.8709677419354839\n",
      "[410] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "410 0 0.008208965882658958 0.8709677419354839\n",
      "[411] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "411 0 0.008194376714527607 0.8709677419354839\n",
      "[412] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "412 0 0.008179857395589352 0.8709677419354839\n",
      "[413] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "413 0 0.008165369741618633 0.8709677419354839\n",
      "[414] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "414 0 0.008150951005518436 0.8709677419354839\n",
      "[415] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "415 0 0.008136586286127567 0.8709677419354839\n",
      "[416] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "416 0 0.008122279308736324 0.8709677419354839\n",
      "[417] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "417 0 0.008108026348054409 0.8709677419354839\n",
      "[418] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "418 0 0.008093828335404396 0.8709677419354839\n",
      "[419] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "419 0 0.00807968620210886 0.8709677419354839\n",
      "[420] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "420 0 0.008065599016845226 0.8709677419354839\n",
      "[421] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "421 0 0.00805156771093607 0.8709677419354839\n",
      "[422] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "422 0 0.008037589490413666 0.8709677419354839\n",
      "[423] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "423 0 0.008023668080568314 0.8709677419354839\n",
      "[424] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "424 0 0.008009800687432289 0.8709677419354839\n",
      "[425] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "425 0 0.007995989173650742 0.8709677419354839\n",
      "[426] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "426 0 0.007982233539223671 0.8709677419354839\n",
      "[427] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "427 0 0.007968530058860779 0.8709677419354839\n",
      "[428] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "428 0 0.007954882457852364 0.8709677419354839\n",
      "[429] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "429 0 0.007941287942230701 0.8709677419354839\n",
      "[430] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "430 0 0.007927749305963516 0.8709677419354839\n",
      "[431] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "431 0 0.007914264686405659 0.8709677419354839\n",
      "[432] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "432 0 0.007900834083557129 0.8709677419354839\n",
      "[433] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "433 0 0.007887458428740501 0.8709677419354839\n",
      "[434] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "434 0 0.007874134927988052 0.8709677419354839\n",
      "[435] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "435 0 0.00786086730659008 0.8709677419354839\n",
      "[436] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "436 0 0.007847649976611137 0.8709677419354839\n",
      "[437] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "437 0 0.007834486663341522 0.8709677419354839\n",
      "[438] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "438 0 0.007821377366781235 0.8709677419354839\n",
      "[439] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "439 0 0.007808318827301264 0.8709677419354839\n",
      "[440] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "440 0 0.007795315235853195 0.8709677419354839\n",
      "[441] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "441 0 0.007782363332808018 0.8709677419354839\n",
      "[442] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "442 0 0.007769464049488306 0.8709677419354839\n",
      "[443] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "443 0 0.0077566164545714855 0.8709677419354839\n",
      "[444] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "444 0 0.007743821945041418 0.8709677419354839\n",
      "[445] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "445 0 0.007731078192591667 0.8709677419354839\n",
      "[446] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "446 0 0.007718387991189957 0.8709677419354839\n",
      "[447] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "447 0 0.007705748081207275 0.8709677419354839\n",
      "[448] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "448 0 0.007693158928304911 0.8709677419354839\n",
      "[449] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "449 0 0.007680622395128012 0.8709677419354839\n",
      "[450] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "450 0 0.007668135687708855 0.8709677419354839\n",
      "[451] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "451 0 0.007655699737370014 0.8709677419354839\n",
      "[452] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "452 0 0.0076433164067566395 0.8709677419354839\n",
      "[453] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "453 0 0.0076309810392558575 0.8709677419354839\n",
      "[454] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "454 0 0.007618696894496679 0.8709677419354839\n",
      "[455] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "455 0 0.007606463506817818 0.8709677419354839\n",
      "[456] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "456 0 0.007594279479235411 0.8709677419354839\n",
      "[457] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "457 0 0.007582145277410746 0.8709677419354839\n",
      "[458] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "458 0 0.007570059970021248 0.8709677419354839\n",
      "[459] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "459 0 0.007558024022728205 0.8709677419354839\n",
      "[460] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "460 0 0.007546036969870329 0.8709677419354839\n",
      "[461] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "461 0 0.007534100208431482 0.8709677419354839\n",
      "[462] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "462 0 0.0075222100131213665 0.8709677419354839\n",
      "[463] loss/acc for train: (0.008, 0.871), valid: (0.008, 0.871), test: (0.008, 0.871)\n",
      "463 0 0.007510369643568993 0.8709677419354839\n",
      "[464] loss/acc for train: (0.008, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "464 0 0.0074985758401453495 0.8709677419354839\n",
      "[465] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "465 0 0.007486854679882526 0.8709677419354839\n",
      "[466] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "466 0 0.007475193589925766 0.8709677419354839\n",
      "[467] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "467 0 0.007463583257049322 0.8709677419354839\n",
      "[468] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "468 0 0.007452021352946758 0.8709677419354839\n",
      "[469] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469 0 0.007440507411956787 0.8709677419354839\n",
      "[470] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "470 0 0.007429042831063271 0.8709677419354839\n",
      "[471] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "471 0 0.00741762388497591 0.8709677419354839\n",
      "[472] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "472 0 0.007406253833323717 0.8709677419354839\n",
      "[473] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "473 0 0.00739492941647768 0.8709677419354839\n",
      "[474] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "474 0 0.007383745163679123 0.8709677419354839\n",
      "[475] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "475 0 0.007372609805315733 0.8709677419354839\n",
      "[476] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "476 0 0.007361493073403835 0.8709677419354839\n",
      "[477] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "477 0 0.007350399624556303 0.8709677419354839\n",
      "[478] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "478 0 0.00733933225274086 0.8709677419354839\n",
      "[479] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "479 0 0.00732829375192523 0.8709677419354839\n",
      "[480] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "480 0 0.007317290175706148 0.8709677419354839\n",
      "[481] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "481 0 0.007306346204131842 0.8709677419354839\n",
      "[482] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "482 0 0.007295510731637478 0.8709677419354839\n",
      "[483] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "483 0 0.007284713909029961 0.8709677419354839\n",
      "[484] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "484 0 0.007273952476680279 0.8709677419354839\n",
      "[485] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "485 0 0.007263227831572294 0.8709677419354839\n",
      "[486] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "486 0 0.007252539973706007 0.8709677419354839\n",
      "[487] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "487 0 0.007241886109113693 0.8709677419354839\n",
      "[488] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "488 0 0.007231271825730801 0.8709677419354839\n",
      "[489] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "489 0 0.007220708765089512 0.8709677419354839\n",
      "[490] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "490 0 0.007210222072899342 0.8709677419354839\n",
      "[491] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "491 0 0.007199763786047697 0.8709677419354839\n",
      "[492] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "492 0 0.00718933530151844 0.8709677419354839\n",
      "[493] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "493 0 0.00717893848195672 0.8709677419354839\n",
      "[494] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "494 0 0.007168618030846119 0.8709677419354839\n",
      "[495] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "495 0 0.007158338557928801 0.8709677419354839\n",
      "[496] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "496 0 0.007148087490350008 0.8709677419354839\n",
      "[497] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "497 0 0.007137867622077465 0.8709677419354839\n",
      "[498] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "498 0 0.007127678487449884 0.8709677419354839\n",
      "[499] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "499 0 0.007117565721273422 0.8709677419354839\n",
      "[500] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "500 0 0.007107492536306381 0.8709677419354839\n",
      "[501] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "501 0 0.0070974500849843025 0.8709677419354839\n",
      "[502] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "502 0 0.0070874374359846115 0.8709677419354839\n",
      "[503] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "503 0 0.00707745598629117 0.8709677419354839\n",
      "[504] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "504 0 0.007067510392516851 0.8709677419354839\n",
      "[505] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "505 0 0.007057634182274342 0.8709677419354839\n",
      "[506] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "506 0 0.007047782652080059 0.8709677419354839\n",
      "[507] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "507 0 0.007037973962724209 0.8709677419354839\n",
      "[508] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "508 0 0.007028206717222929 0.8709677419354839\n",
      "[509] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "509 0 0.007018472068011761 0.8709677419354839\n",
      "[510] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "510 0 0.007008782122284174 0.8709677419354839\n",
      "[511] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "511 0 0.006999128498136997 0.8709677419354839\n",
      "[512] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "512 0 0.006989510264247656 0.8709677419354839\n",
      "[513] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "513 0 0.006979933939874172 0.8709677419354839\n",
      "[514] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "514 0 0.0069703892804682255 0.8709677419354839\n",
      "[515] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "515 0 0.006960900500416756 0.8709677419354839\n",
      "[516] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "516 0 0.006951435003429651 0.8709677419354839\n",
      "[517] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "517 0 0.0069419932551681995 0.8709677419354839\n",
      "[518] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "518 0 0.0069326190277934074 0.8709677419354839\n",
      "[519] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "519 0 0.00692327506840229 0.8709677419354839\n",
      "[520] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "520 0 0.006913960445672274 0.8709677419354839\n",
      "[521] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "521 0 0.006904676090925932 0.8709677419354839\n",
      "[522] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "522 0 0.006895421072840691 0.8709677419354839\n",
      "[523] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "523 0 0.006886198651045561 0.8709677419354839\n",
      "[524] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "524 0 0.006877046078443527 0.8709677419354839\n",
      "[525] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "525 0 0.006867918185889721 0.8709677419354839\n",
      "[526] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "526 0 0.006858809385448694 0.8709677419354839\n",
      "[527] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "527 0 0.006849720608443022 0.8709677419354839\n",
      "[528] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "528 0 0.00684069748967886 0.8709677419354839\n",
      "[529] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "529 0 0.0068317134864628315 0.8709677419354839\n",
      "[530] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "530 0 0.00682275602594018 0.8709677419354839\n",
      "[531] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "531 0 0.0068138279020786285 0.8709677419354839\n",
      "[532] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "532 0 0.006804928183555603 0.8709677419354839\n",
      "[533] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "533 0 0.0067960601300001144 0.8709677419354839\n",
      "[534] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "534 0 0.006787221413105726 0.8709677419354839\n",
      "[535] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "535 0 0.006778417620807886 0.8709677419354839\n",
      "[536] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "536 0 0.006769667379558086 0.8709677419354839\n",
      "[537] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "537 0 0.006760929245501757 0.8709677419354839\n",
      "[538] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "538 0 0.006752246059477329 0.8709677419354839\n",
      "[539] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "539 0 0.006743591278791428 0.8709677419354839\n",
      "[540] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "540 0 0.006734966766089201 0.8709677419354839\n",
      "[541] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "541 0 0.006726368796080351 0.8709677419354839\n",
      "[542] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "542 0 0.0067178006283938885 0.8709677419354839\n",
      "[543] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "543 0 0.006709261331707239 0.8709677419354839\n",
      "[544] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "544 0 0.006700752768665552 0.8709677419354839\n",
      "[545] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "545 0 0.00669228658080101 0.8709677419354839\n",
      "[546] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "546 0 0.006683852057904005 0.8709677419354839\n",
      "[547] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "547 0 0.006675450596958399 0.8709677419354839\n",
      "[548] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "548 0 0.006667075678706169 0.8709677419354839\n",
      "[549] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "549 0 0.006658728700131178 0.8709677419354839\n",
      "[550] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "550 0 0.006650411989539862 0.8709677419354839\n",
      "[551] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "551 0 0.006642141845077276 0.8709677419354839\n",
      "[552] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "552 0 0.006633886136114597 0.8709677419354839\n",
      "[553] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "553 0 0.006625658832490444 0.8709677419354839\n",
      "[554] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "554 0 0.0066174715757369995 0.8709677419354839\n",
      "[555] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "555 0 0.006609311327338219 0.8709677419354839\n",
      "[556] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "556 0 0.006601179949939251 0.8709677419354839\n",
      "[557] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "557 0 0.006593074183911085 0.8709677419354839\n",
      "[558] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "558 0 0.00658499775454402 0.8709677419354839\n",
      "[559] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "559 0 0.0065769474022090435 0.8709677419354839\n",
      "[560] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "560 0 0.006568952929228544 0.8709677419354839\n",
      "[561] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "561 0 0.006560964044183493 0.8709677419354839\n",
      "[562] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "562 0 0.006552988663315773 0.8709677419354839\n",
      "[563] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "563 0 0.006545064505189657 0.8709677419354839\n",
      "[564] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "564 0 0.006537165027111769 0.8709677419354839\n",
      "[565] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "565 0 0.0065292976796627045 0.8709677419354839\n",
      "[566] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "566 0 0.0065214806236326694 0.8709677419354839\n",
      "[567] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "567 0 0.006513693835586309 0.8709677419354839\n",
      "[568] loss/acc for train: (0.007, 0.871), valid: (0.007, 0.871), test: (0.007, 0.871)\n",
      "568 0 0.0065059359185397625 0.8709677419354839\n",
      "[569] loss/acc for train: (0.007, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "569 0 0.006498206406831741 0.8709677419354839\n",
      "[570] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "570 0 0.0064905243925750256 0.8709677419354839\n",
      "[571] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "571 0 0.0064828465692698956 0.8709677419354839\n",
      "[572] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "572 0 0.0064751990139484406 0.8709677419354839\n",
      "[573] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "573 0 0.00646758871152997 0.8709677419354839\n",
      "[574] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "574 0 0.0064600021578371525 0.8709677419354839\n",
      "[575] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "575 0 0.006452443078160286 0.8709677419354839\n",
      "[576] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "576 0 0.006444909144192934 0.8709677419354839\n",
      "[577] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "577 0 0.006437399890273809 0.8709677419354839\n",
      "[578] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "578 0 0.006429917179048061 0.8709677419354839\n",
      "[579] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "579 0 0.0064224605448544025 0.8709677419354839\n",
      "[580] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "580 0 0.006415028590708971 0.8709677419354839\n",
      "[581] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "581 0 0.006407622713595629 0.8709677419354839\n",
      "[582] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "582 0 0.0064002410508692265 0.8709677419354839\n",
      "[583] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "583 0 0.006392884999513626 0.8709677419354839\n",
      "[584] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "584 0 0.00638555409386754 0.8709677419354839\n",
      "[585] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "585 0 0.006378247868269682 0.8709677419354839\n",
      "[586] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "586 0 0.006370981223881245 0.8709677419354839\n",
      "[587] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "587 0 0.0063637117855250835 0.8709677419354839\n",
      "[588] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "588 0 0.006356481928378344 0.8709677419354839\n",
      "[589] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "589 0 0.006349274888634682 0.8709677419354839\n",
      "[590] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "590 0 0.0063420915976166725 0.8709677419354839\n",
      "[591] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "591 0 0.006334932055324316 0.8709677419354839\n",
      "[592] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "592 0 0.006327795330435038 0.8709677419354839\n",
      "[593] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "593 0 0.00632068095728755 0.8709677419354839\n",
      "[594] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "594 0 0.00631358940154314 0.8709677419354839\n",
      "[595] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "595 0 0.006306521128863096 0.8709677419354839\n",
      "[596] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "596 0 0.006299475207924843 0.8709677419354839\n",
      "[597] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "597 0 0.00629245163872838 0.8709677419354839\n",
      "[598] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "598 0 0.00628545181825757 0.8709677419354839\n",
      "[599] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "599 0 0.006278472952544689 0.8709677419354839\n",
      "[600] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "600 0 0.0062715159729123116 0.8709677419354839\n",
      "[601] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "601 0 0.006264582276344299 0.8709677419354839\n",
      "[602] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "602 0 0.0062576825730502605 0.8709677419354839\n",
      "[603] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "603 0 0.006250809412449598 0.8709677419354839\n",
      "[604] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "604 0 0.006243958603590727 0.8709677419354839\n",
      "[605] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "605 0 0.0062371306121349335 0.8709677419354839\n",
      "[606] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "606 0 0.006230324041098356 0.8709677419354839\n",
      "[607] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "607 0 0.006223541684448719 0.8709677419354839\n",
      "[608] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "608 0 0.006216779351234436 0.8709677419354839\n",
      "[609] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "609 0 0.006210039835423231 0.8709677419354839\n",
      "[610] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "610 0 0.006203320808708668 0.8709677419354839\n",
      "[611] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "611 0 0.006196622271090746 0.8709677419354839\n",
      "[612] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "612 0 0.006189944222569466 0.8709677419354839\n",
      "[613] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "613 0 0.006183288060128689 0.8709677419354839\n",
      "[614] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "614 0 0.006176651921123266 0.8709677419354839\n",
      "[615] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "615 0 0.00617003720253706 0.8709677419354839\n",
      "[616] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "616 0 0.006163441110402346 0.8709677419354839\n",
      "[617] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "617 0 0.0061568645760416985 0.8709677419354839\n",
      "[618] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "618 0 0.0061503080651164055 0.8709677419354839\n",
      "[619] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "619 0 0.006143772043287754 0.8709677419354839\n",
      "[620] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "620 0 0.006137254647910595 0.8709677419354839\n",
      "[621] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "621 0 0.0061307563446462154 0.8709677419354839\n",
      "[622] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "622 0 0.006124277599155903 0.8709677419354839\n",
      "[623] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "623 0 0.00611781794577837 0.8709677419354839\n",
      "[624] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "624 0 0.006111375521868467 0.8709677419354839\n",
      "[625] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "625 0 0.006104953121393919 0.8709677419354839\n",
      "[626] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "626 0 0.006098548881709576 0.8709677419354839\n",
      "[627] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "627 0 0.006092162802815437 0.8709677419354839\n",
      "[628] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "628 0 0.006085795350372791 0.8709677419354839\n",
      "[629] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "629 0 0.006079444661736488 0.8709677419354839\n",
      "[630] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "630 0 0.006073113065212965 0.8709677419354839\n",
      "[631] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "631 0 0.006066799629479647 0.8709677419354839\n",
      "[632] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "632 0 0.006060502957552671 0.8709677419354839\n",
      "[633] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "633 0 0.0060542249120771885 0.8709677419354839\n",
      "[634] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "634 0 0.006047963630408049 0.8709677419354839\n",
      "[635] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "635 0 0.006041720975190401 0.8709677419354839\n",
      "[636] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "636 0 0.006035494152456522 0.8709677419354839\n",
      "[637] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "637 0 0.006029284559190273 0.8709677419354839\n",
      "[638] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "638 0 0.006023091729730368 0.8709677419354839\n",
      "[639] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "639 0 0.006016917992383242 0.8709677419354839\n",
      "[640] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "640 0 0.006010758690536022 0.8709677419354839\n",
      "[641] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "641 0 0.00600461708381772 0.8709677419354839\n",
      "[642] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "642 0 0.005998492240905762 0.8709677419354839\n",
      "[643] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "643 0 0.005992382764816284 0.8709677419354839\n",
      "[644] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "644 0 0.00598629005253315 0.8709677419354839\n",
      "[645] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "645 0 0.005980214104056358 0.8709677419354839\n",
      "[646] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "646 0 0.005974154453724623 0.8709677419354839\n",
      "[647] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "647 0 0.005968110170215368 0.8709677419354839\n",
      "[648] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "648 0 0.005962081719189882 0.8709677419354839\n",
      "[649] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "649 0 0.005956069100648165 0.8709677419354839\n",
      "[650] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "650 0 0.005950072780251503 0.8709677419354839\n",
      "[651] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "651 0 0.00594409229233861 0.8709677419354839\n",
      "[652] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "652 0 0.0059381271712481976 0.8709677419354839\n",
      "[653] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "653 0 0.005932176485657692 0.8709677419354839\n",
      "[654] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "654 0 0.0059262411668896675 0.8709677419354839\n",
      "[655] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "655 0 0.005920322146266699 0.8709677419354839\n",
      "[656] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "656 0 0.005914417561143637 0.8709677419354839\n",
      "[657] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "657 0 0.005908527877181768 0.8709677419354839\n",
      "[658] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "658 0 0.005902653560042381 0.8709677419354839\n",
      "[659] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "659 0 0.005896794144064188 0.8709677419354839\n",
      "[660] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "660 0 0.005890948697924614 0.8709677419354839\n",
      "[661] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "661 0 0.005885118618607521 0.8709677419354839\n",
      "[662] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "662 0 0.005879303440451622 0.8709677419354839\n",
      "[663] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "663 0 0.005873503163456917 0.8709677419354839\n",
      "[664] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "664 0 0.005867714993655682 0.8709677419354839\n",
      "[665] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "665 0 0.0058619435876607895 0.8709677419354839\n",
      "[666] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "666 0 0.005856184754520655 0.8709677419354839\n",
      "[667] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "667 0 0.005850440356880426 0.8709677419354839\n",
      "[668] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "668 0 0.005844710860401392 0.8709677419354839\n",
      "[669] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "669 0 0.005838993936777115 0.8709677419354839\n",
      "[670] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "670 0 0.005833291448652744 0.8709677419354839\n",
      "[671] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "671 0 0.005827602930366993 0.8709677419354839\n",
      "[672] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "672 0 0.0058219279162585735 0.8709677419354839\n",
      "[673] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "673 0 0.005816265940666199 0.8709677419354839\n",
      "[674] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "674 0 0.0058106184005737305 0.8709677419354839\n",
      "[675] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "675 0 0.0058049834333360195 0.8709677419354839\n",
      "[676] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "676 0 0.005799362435936928 0.8709677419354839\n",
      "[677] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "677 0 0.005793754942715168 0.8709677419354839\n",
      "[678] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "678 0 0.005788159556686878 0.8709677419354839\n",
      "[679] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "679 0 0.005782578606158495 0.8709677419354839\n",
      "[680] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "680 0 0.005777009762823582 0.8709677419354839\n",
      "[681] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "681 0 0.005771453958004713 0.8709677419354839\n",
      "[682] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "682 0 0.005765910726040602 0.8709677419354839\n",
      "[683] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "683 0 0.005760380998253822 0.8709677419354839\n",
      "[684] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "684 0 0.0057548638433218 0.8709677419354839\n",
      "[685] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "685 0 0.0057493592612445354 0.8709677419354839\n",
      "[686] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "686 0 0.005743866786360741 0.8709677419354839\n",
      "[687] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "687 0 0.005738386418670416 0.8709677419354839\n",
      "[688] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "688 0 0.005732919089496136 0.8709677419354839\n",
      "[689] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "689 0 0.005727464333176613 0.8709677419354839\n",
      "[690] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "690 0 0.00572202168405056 0.8709677419354839\n",
      "[691] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "691 0 0.0057165916077792645 0.8709677419354839\n",
      "[692] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "692 0 0.005711172241717577 0.8709677419354839\n",
      "[693] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "693 0 0.005705765448510647 0.8709677419354839\n",
      "[694] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "694 0 0.005700371693819761 0.8709677419354839\n",
      "[695] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "695 0 0.005694987718015909 0.8709677419354839\n",
      "[696] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "696 0 0.005689697340130806 0.8709677419354839\n",
      "[697] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "697 0 0.005684535484761 0.8709677419354839\n",
      "[698] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "698 0 0.005679388530552387 0.8709677419354839\n",
      "[699] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "699 0 0.005674255080521107 0.8709677419354839\n",
      "[700] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "700 0 0.005669134669005871 0.8709677419354839\n",
      "[701] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "701 0 0.005664029158651829 0.8709677419354839\n",
      "[702] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "702 0 0.005658937152475119 0.8709677419354839\n",
      "[703] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "703 0 0.00565385865047574 0.8709677419354839\n",
      "[704] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "704 0 0.005648795980960131 0.8709677419354839\n",
      "[705] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "705 0 0.005643746349960566 0.8709677419354839\n",
      "[706] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "706 0 0.00563871068879962 0.8709677419354839\n",
      "[707] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "707 0 0.005633690394461155 0.8709677419354839\n",
      "[708] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "708 0 0.005628681275993586 0.8709677419354839\n",
      "[709] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "709 0 0.005623687990009785 0.8709677419354839\n",
      "[710] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "710 0 0.005618706811219454 0.8709677419354839\n",
      "[711] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "711 0 0.005613740533590317 0.8709677419354839\n",
      "[712] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "712 0 0.00560878636315465 0.8709677419354839\n",
      "[713] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "713 0 0.005603844299912453 0.8709677419354839\n",
      "[714] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "714 0 0.0055989152751863 0.8709677419354839\n",
      "[715] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "715 0 0.005593997426331043 0.8709677419354839\n",
      "[716] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "716 0 0.005589091684669256 0.8709677419354839\n",
      "[717] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "717 0 0.005584198981523514 0.8709677419354839\n",
      "[718] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "718 0 0.005579316057264805 0.8709677419354839\n",
      "[719] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "719 0 0.005574444308876991 0.8709677419354839\n",
      "[720] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "720 0 0.005569585599005222 0.8709677419354839\n",
      "[721] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "721 0 0.0055647362023591995 0.8709677419354839\n",
      "[722] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "722 0 0.005559898447245359 0.8709677419354839\n",
      "[723] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "723 0 0.005555071402341127 0.8709677419354839\n",
      "[724] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "724 0 0.005550254601985216 0.8709677419354839\n",
      "[725] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "725 0 0.005545448046177626 0.8709677419354839\n",
      "[726] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "726 0 0.0055406526662409306 0.8709677419354839\n",
      "[727] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "727 0 0.005535868462175131 0.8709677419354839\n",
      "[728] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "728 0 0.005531094502657652 0.8709677419354839\n",
      "[729] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "729 0 0.005526330322027206 0.8709677419354839\n",
      "[730] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "730 0 0.005521577782928944 0.8709677419354839\n",
      "[731] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "731 0 0.00551683409139514 0.8709677419354839\n",
      "[732] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "732 0 0.005512101575732231 0.8709677419354839\n",
      "[733] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "733 0 0.005507378373295069 0.8709677419354839\n",
      "[734] loss/acc for train: (0.006, 0.871), valid: (0.006, 0.871), test: (0.006, 0.871)\n",
      "734 0 0.005502665415406227 0.8709677419354839\n",
      "[735] loss/acc for train: (0.006, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "735 0 0.0054979645647108555 0.8709677419354839\n",
      "[736] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "736 0 0.005493272095918655 0.8709677419354839\n",
      "[737] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "737 0 0.005488589871674776 0.8709677419354839\n",
      "[738] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "738 0 0.00548391742631793 0.8709677419354839\n",
      "[739] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "739 0 0.0054792556911706924 0.8709677419354839\n",
      "[740] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "740 0 0.005474603269249201 0.8709677419354839\n",
      "[741] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "741 0 0.005469960626214743 0.8709677419354839\n",
      "[742] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "742 0 0.005465328693389893 0.8709677419354839\n",
      "[743] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "743 0 0.005460705142468214 0.8709677419354839\n",
      "[744] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "744 0 0.005456091370433569 0.8709677419354839\n",
      "[745] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "745 0 0.005451487377285957 0.8709677419354839\n",
      "[746] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "746 0 0.0054468922317028046 0.8709677419354839\n",
      "[747] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "747 0 0.00544230779632926 0.8709677419354839\n",
      "[748] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "748 0 0.005437731742858887 0.8709677419354839\n",
      "[749] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "749 0 0.00543316500261426 0.8709677419354839\n",
      "[750] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "750 0 0.00542863504961133 0.8709677419354839\n",
      "[751] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "751 0 0.005424158647656441 0.8709677419354839\n",
      "[752] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "752 0 0.005419687833636999 0.8709677419354839\n",
      "[753] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "753 0 0.005415222141891718 0.8709677419354839\n",
      "[754] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "754 0 0.005410762969404459 0.8709677419354839\n",
      "[755] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "755 0 0.005406311247497797 0.8709677419354839\n",
      "[756] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "756 0 0.005401868373155594 0.8709677419354839\n",
      "[757] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "757 0 0.005397436209022999 0.8709677419354839\n",
      "[758] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "758 0 0.00539301335811615 0.8709677419354839\n",
      "[759] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "759 0 0.005388601217418909 0.8709677419354839\n",
      "[760] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "760 0 0.005384199786931276 0.8709677419354839\n",
      "[761] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "761 0 0.005379810463637114 0.8709677419354839\n",
      "[762] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "762 0 0.005375431384891272 0.8709677419354839\n",
      "[763] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "763 0 0.005371063482016325 0.8709677419354839\n",
      "[764] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "764 0 0.005366707220673561 0.8709677419354839\n",
      "[765] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "765 0 0.005362360272556543 0.8709677419354839\n",
      "[766] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "766 0 0.005358024965971708 0.8709677419354839\n",
      "[767] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "767 0 0.005353698506951332 0.8709677419354839\n",
      "[768] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "768 0 0.005349381361156702 0.8709677419354839\n",
      "[769] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "769 0 0.0053450739942491055 0.8709677419354839\n",
      "[770] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "770 0 0.005340774543583393 0.8709677419354839\n",
      "[771] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "771 0 0.0053364853374660015 0.8709677419354839\n",
      "[772] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "772 0 0.005332203581929207 0.8709677419354839\n",
      "[773] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "773 0 0.005327929742634296 0.8709677419354839\n",
      "[774] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "774 0 0.005323665216565132 0.8709677419354839\n",
      "[775] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "775 0 0.005319408606737852 0.8709677419354839\n",
      "[776] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "776 0 0.005315160378813744 0.8709677419354839\n",
      "[777] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "777 0 0.005310920067131519 0.8709677419354839\n",
      "[778] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "778 0 0.005306742154061794 0.8709677419354839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[779] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "779 0 0.005302571691572666 0.8709677419354839\n",
      "[780] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "780 0 0.005298408679664135 0.8709677419354839\n",
      "[781] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "781 0 0.005294254049658775 0.8709677419354839\n",
      "[782] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "782 0 0.005290105473250151 0.8709677419354839\n",
      "[783] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "783 0 0.005285965744405985 0.8709677419354839\n",
      "[784] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "784 0 0.005281832069158554 0.8709677419354839\n",
      "[785] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "785 0 0.005277706775814295 0.8709677419354839\n",
      "[786] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "786 0 0.00527358939871192 0.8709677419354839\n",
      "[787] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "787 0 0.005269481334835291 0.8709677419354839\n",
      "[788] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.871), test: (0.005, 0.871)\n",
      "788 0 0.005265380721539259 0.8709677419354839\n",
      "[789] loss/acc for train: (0.005, 0.871), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "789 0 0.0052612884901463985 0.9032258064516129\n",
      "[790] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "790 0 0.005257204174995422 0.9032258064516129\n",
      "[791] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "791 0 0.00525312777608633 0.9032258064516129\n",
      "[792] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "792 0 0.005249060224741697 0.9032258064516129\n",
      "[793] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "793 0 0.005245001520961523 0.9032258064516129\n",
      "[794] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "794 0 0.005240949802100658 0.9032258064516129\n",
      "[795] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "795 0 0.00523690739646554 0.9032258064516129\n",
      "[796] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "796 0 0.005232871975749731 0.9032258064516129\n",
      "[797] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "797 0 0.005228844936937094 0.9032258064516129\n",
      "[798] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "798 0 0.005224825814366341 0.9032258064516129\n",
      "[799] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "799 0 0.005220815073698759 0.9032258064516129\n",
      "[800] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "800 0 0.0052168117836117744 0.9032258064516129\n",
      "[801] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "801 0 0.005212817341089249 0.9032258064516129\n",
      "[802] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "802 0 0.005208829417824745 0.9032258064516129\n",
      "[803] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "803 0 0.005204849410802126 0.9032258064516129\n",
      "[804] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "804 0 0.005200877785682678 0.9032258064516129\n",
      "[805] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "805 0 0.005196912679821253 0.9032258064516129\n",
      "[806] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "806 0 0.005192956421524286 0.9032258064516129\n",
      "[807] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "807 0 0.005189007148146629 0.9032258064516129\n",
      "[808] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "808 0 0.005185065791010857 0.9032258064516129\n",
      "[809] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "809 0 0.005181130953133106 0.9032258064516129\n",
      "[810] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "810 0 0.005177205428481102 0.9032258064516129\n",
      "[811] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "811 0 0.00517328642308712 0.9032258064516129\n",
      "[812] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "812 0 0.005169374402612448 0.9032258064516129\n",
      "[813] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "813 0 0.005165469832718372 0.9032258064516129\n",
      "[814] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "814 0 0.005161572713404894 0.9032258064516129\n",
      "[815] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "815 0 0.0051576835103333 0.9032258064516129\n",
      "[816] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "816 0 0.005153800826519728 0.9032258064516129\n",
      "[817] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "817 0 0.00514992605894804 0.9032258064516129\n",
      "[818] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "818 0 0.005146058276295662 0.9032258064516129\n",
      "[819] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "819 0 0.005142197012901306 0.9032258064516129\n",
      "[820] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "820 0 0.005138343665748835 0.9032258064516129\n",
      "[821] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "821 0 0.005134496837854385 0.9032258064516129\n",
      "[822] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "822 0 0.005130657460540533 0.9032258064516129\n",
      "[823] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "823 0 0.005126824602484703 0.9032258064516129\n",
      "[824] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "824 0 0.005122998263686895 0.9032258064516129\n",
      "[825] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "825 0 0.005119180306792259 0.9032258064516129\n",
      "[826] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "826 0 0.005115367937833071 0.9032258064516129\n",
      "[827] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "827 0 0.005111562553793192 0.9032258064516129\n",
      "[828] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "828 0 0.005107764154672623 0.9032258064516129\n",
      "[829] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "829 0 0.0051039718091487885 0.9032258064516129\n",
      "[830] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "830 0 0.005100187845528126 0.9032258064516129\n",
      "[831] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "831 0 0.005096409469842911 0.9032258064516129\n",
      "[832] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "832 0 0.005092637613415718 0.9032258064516129\n",
      "[833] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "833 0 0.005088872276246548 0.9032258064516129\n",
      "[834] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "834 0 0.005085112992674112 0.9032258064516129\n",
      "[835] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "835 0 0.005081361625343561 0.9032258064516129\n",
      "[836] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "836 0 0.00507761538028717 0.9032258064516129\n",
      "[837] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "837 0 0.005073875654488802 0.9032258064516129\n",
      "[838] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "838 0 0.00507014337927103 0.9032258064516129\n",
      "[839] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "839 0 0.005066416226327419 0.9032258064516129\n",
      "[840] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "840 0 0.005062696523964405 0.9032258064516129\n",
      "[841] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "841 0 0.005058981943875551 0.9032258064516129\n",
      "[842] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "842 0 0.00505527388304472 0.9032258064516129\n",
      "[843] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "843 0 0.0050515723414719105 0.9032258064516129\n",
      "[844] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "844 0 0.0050478773191571236 0.9032258064516129\n",
      "[845] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "845 0 0.005044188350439072 0.9032258064516129\n",
      "[846] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "846 0 0.005040505435317755 0.9032258064516129\n",
      "[847] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "847 0 0.0050368281081318855 0.9032258064516129\n",
      "[848] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "848 0 0.005033156834542751 0.9032258064516129\n",
      "[849] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "849 0 0.005029491614550352 0.9032258064516129\n",
      "[850] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "850 0 0.005025832448154688 0.9032258064516129\n",
      "[851] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "851 0 0.005022180266678333 0.9032258064516129\n",
      "[852] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "852 0 0.005018564872443676 0.9032258064516129\n",
      "[853] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "853 0 0.0050149643793702126 0.9032258064516129\n",
      "[854] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "854 0 0.0050113629549741745 0.9032258064516129\n",
      "[855] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "855 0 0.0050077615305781364 0.9032258064516129\n",
      "[856] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "856 0 0.005004161968827248 0.9032258064516129\n",
      "[857] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "857 0 0.005000567063689232 0.9032258064516129\n",
      "[858] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "858 0 0.004996975883841515 0.9032258064516129\n",
      "[859] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "859 0 0.00499339122325182 0.9032258064516129\n",
      "[860] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "860 0 0.00498981261625886 0.9032258064516129\n",
      "[861] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "861 0 0.004986240994185209 0.9032258064516129\n",
      "[862] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "862 0 0.004982677288353443 0.9032258064516129\n",
      "[863] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "863 0 0.004979128483682871 0.9032258064516129\n",
      "[864] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "864 0 0.004975596908479929 0.9032258064516129\n",
      "[865] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "865 0 0.004972063470631838 0.9032258064516129\n",
      "[866] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "866 0 0.004968527238816023 0.9032258064516129\n",
      "[867] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "867 0 0.004964989144355059 0.9032258064516129\n",
      "[868] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "868 0 0.0049614752642810345 0.9032258064516129\n",
      "[869] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "869 0 0.004957965575158596 0.9032258064516129\n",
      "[870] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "870 0 0.004954460542649031 0.9032258064516129\n",
      "[871] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "871 0 0.004950960166752338 0.9032258064516129\n",
      "[872] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "872 0 0.004947463981807232 0.9032258064516129\n",
      "[873] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "873 0 0.0049439724534749985 0.9032258064516129\n",
      "[874] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "874 0 0.004940486513078213 0.9032258064516129\n",
      "[875] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "875 0 0.004937005694955587 0.9032258064516129\n",
      "[876] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "876 0 0.0049335346557199955 0.9032258064516129\n",
      "[877] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "877 0 0.004930069204419851 0.9032258064516129\n",
      "[878] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "878 0 0.0049266088753938675 0.9032258064516129\n",
      "[879] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "879 0 0.004923155065625906 0.9032258064516129\n",
      "[880] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "880 0 0.004919706843793392 0.9032258064516129\n",
      "[881] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "881 0 0.004916262812912464 0.9032258064516129\n",
      "[882] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "882 0 0.004912828095257282 0.9032258064516129\n",
      "[883] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "883 0 0.00490940036252141 0.9032258064516129\n",
      "[884] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "884 0 0.00490597216412425 0.9032258064516129\n",
      "[885] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "885 0 0.004902554210275412 0.9032258064516129\n",
      "[886] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "886 0 0.004899141378700733 0.9032258064516129\n",
      "[887] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "887 0 0.004895733669400215 0.9032258064516129\n",
      "[888] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "888 0 0.004892330151051283 0.9032258064516129\n",
      "[889] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "889 0 0.004888932220637798 0.9032258064516129\n",
      "[890] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "890 0 0.004885539878159761 0.9032258064516129\n",
      "[891] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "891 0 0.004882153123617172 0.9032258064516129\n",
      "[892] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "892 0 0.004878771957010031 0.9032258064516129\n",
      "[893] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "893 0 0.004875394515693188 0.9032258064516129\n",
      "[894] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "894 0 0.00487202312797308 0.9032258064516129\n",
      "[895] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "895 0 0.004868661984801292 0.9032258064516129\n",
      "[896] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "896 0 0.004865295719355345 0.9032258064516129\n",
      "[897] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "897 0 0.004861942958086729 0.9032258064516129\n",
      "[898] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "898 0 0.0048585934564471245 0.9032258064516129\n",
      "[899] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "899 0 0.004855249542742968 0.9032258064516129\n",
      "[900] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "900 0 0.004851909354329109 0.9032258064516129\n",
      "[901] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "901 0 0.004848572891205549 0.9032258064516129\n",
      "[902] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "902 0 0.004845240619033575 0.9032258064516129\n",
      "[903] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "903 0 0.004841912537813187 0.9032258064516129\n",
      "[904] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "904 0 0.004838589113205671 0.9032258064516129\n",
      "[905] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "905 0 0.004835270810872316 0.9032258064516129\n",
      "[906] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "906 0 0.004831956699490547 0.9032258064516129\n",
      "[907] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "907 0 0.004828649573028088 0.9032258064516129\n",
      "[908] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "908 0 0.004825348034501076 0.9032258064516129\n",
      "[909] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "909 0 0.004822051618248224 0.9032258064516129\n",
      "[910] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "910 0 0.0048187593929469585 0.9032258064516129\n",
      "[911] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "911 0 0.004815470892935991 0.9032258064516129\n",
      "[912] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "912 0 0.004812185652554035 0.9032258064516129\n",
      "[913] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "913 0 0.004808906000107527 0.9032258064516129\n",
      "[914] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "914 0 0.004805630072951317 0.9032258064516129\n",
      "[915] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "915 0 0.00480235880240798 0.9032258064516129\n",
      "[916] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "916 0 0.0047990973107516766 0.9032258064516129\n",
      "[917] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "917 0 0.004795833490788937 0.9032258064516129\n",
      "[918] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "918 0 0.004792576655745506 0.9032258064516129\n",
      "[919] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "919 0 0.004789325874298811 0.9032258064516129\n",
      "[920] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "920 0 0.004786079749464989 0.9032258064516129\n",
      "[921] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "921 0 0.004782836884260178 0.9032258064516129\n",
      "[922] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "922 0 0.004779599141329527 0.9032258064516129\n",
      "[923] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "923 0 0.0047763641923666 0.9032258064516129\n",
      "[924] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "924 0 0.0047731343656778336 0.9032258064516129\n",
      "[925] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "925 0 0.004769907798618078 0.9032258064516129\n",
      "[926] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "926 0 0.004766686353832483 0.9032258064516129\n",
      "[927] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "927 0 0.004763468634337187 0.9032258064516129\n",
      "[928] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "928 0 0.004760255571454763 0.9032258064516129\n",
      "[929] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "929 0 0.004757050424814224 0.9032258064516129\n",
      "[930] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "930 0 0.004753843415528536 0.9032258064516129\n",
      "[931] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "931 0 0.004750644788146019 0.9032258064516129\n",
      "[932] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "932 0 0.004747450817376375 0.9032258064516129\n",
      "[933] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "933 0 0.0047442615032196045 0.9032258064516129\n",
      "[934] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "934 0 0.004741075914353132 0.9032258064516129\n",
      "[935] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "935 0 0.004737893119454384 0.9032258064516129\n",
      "[936] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "936 0 0.004734715912491083 0.9032258064516129\n",
      "[937] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "937 0 0.004731541033834219 0.9032258064516129\n",
      "[938] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "938 0 0.004728371277451515 0.9032258064516129\n",
      "[939] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "939 0 0.00472520524635911 0.9032258064516129\n",
      "[940] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "940 0 0.00472204340621829 0.9032258064516129\n",
      "[941] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "941 0 0.004718884360045195 0.9032258064516129\n",
      "[942] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "942 0 0.004715729970484972 0.9032258064516129\n",
      "[943] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "943 0 0.0047125802375376225 0.9032258064516129\n",
      "[944] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "944 0 0.004709435161203146 0.9032258064516129\n",
      "[945] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "945 0 0.004706294741481543 0.9032258064516129\n",
      "[946] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "946 0 0.004703156184405088 0.9032258064516129\n",
      "[947] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "947 0 0.004700023215264082 0.9032258064516129\n",
      "[948] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "948 0 0.004696894437074661 0.9032258064516129\n",
      "[949] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "949 0 0.004693769849836826 0.9032258064516129\n",
      "[950] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "950 0 0.0046906485222280025 0.9032258064516129\n",
      "[951] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "951 0 0.004687531851232052 0.9032258064516129\n",
      "[952] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "952 0 0.0046844189055264 0.9032258064516129\n",
      "[953] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "953 0 0.004681308753788471 0.9032258064516129\n",
      "[954] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "954 0 0.00467820605263114 0.9032258064516129\n",
      "[955] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "955 0 0.004675103351473808 0.9032258064516129\n",
      "[956] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "956 0 0.0046720062382519245 0.9032258064516129\n",
      "[957] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "957 0 0.0046689133159816265 0.9032258064516129\n",
      "[958] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "958 0 0.004665824119001627 0.9032258064516129\n",
      "[959] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "959 0 0.004662739112973213 0.9032258064516129\n",
      "[960] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "960 0 0.004659656435251236 0.9032258064516129\n",
      "[961] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "961 0 0.004656578879803419 0.9032258064516129\n",
      "[962] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "962 0 0.004653504583984613 0.9032258064516129\n",
      "[963] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "963 0 0.004650433547794819 0.9032258064516129\n",
      "[964] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "964 0 0.004647367168217897 0.9032258064516129\n",
      "[965] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "965 0 0.004644304513931274 0.9032258064516129\n",
      "[966] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "966 0 0.004641245119273663 0.9032258064516129\n",
      "[967] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "967 0 0.004638189449906349 0.9032258064516129\n",
      "[968] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "968 0 0.004635142162442207 0.9032258064516129\n",
      "[969] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "969 0 0.004632091149687767 0.9032258064516129\n",
      "[970] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "970 0 0.004629047587513924 0.9032258064516129\n",
      "[971] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "971 0 0.004626007284969091 0.9032258064516129\n",
      "[972] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "972 0 0.004622971639037132 0.9032258064516129\n",
      "[973] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "973 0 0.004619938787072897 0.9032258064516129\n",
      "[974] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "974 0 0.00461690966039896 0.9032258064516129\n",
      "[975] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "975 0 0.004613883793354034 0.9032258064516129\n",
      "[976] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "976 0 0.004610862582921982 0.9032258064516129\n",
      "[977] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "977 0 0.004607843235135078 0.9032258064516129\n",
      "[978] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "978 0 0.004604828543961048 0.9032258064516129\n",
      "[979] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "979 0 0.004601817578077316 0.9032258064516129\n",
      "[980] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "980 0 0.00459881080314517 0.9032258064516129\n",
      "[981] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "981 0 0.004595806822180748 0.9032258064516129\n",
      "[982] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "982 0 0.004592807963490486 0.9032258064516129\n",
      "[983] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "983 0 0.004589810036122799 0.9032258064516129\n",
      "[984] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "984 0 0.004586817231029272 0.9032258064516129\n",
      "[985] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "985 0 0.004583828616887331 0.9032258064516129\n",
      "[986] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "986 0 0.0045808423310518265 0.9032258064516129\n",
      "[987] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "987 0 0.004577860701829195 0.9032258064516129\n",
      "[988] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "988 0 0.004574881866574287 0.9032258064516129\n",
      "[989] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "989 0 0.004571906756609678 0.9032258064516129\n",
      "[990] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "990 0 0.00456893490627408 0.9032258064516129\n",
      "[991] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "991 0 0.0045659663155674934 0.9032258064516129\n",
      "[992] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "992 0 0.004563000984489918 0.9032258064516129\n",
      "[993] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "993 0 0.0045600393787026405 0.9032258064516129\n",
      "[994] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "994 0 0.004557081963866949 0.9032258064516129\n",
      "[995] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "995 0 0.0045541273429989815 0.9032258064516129\n",
      "[996] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "996 0 0.004551175981760025 0.9032258064516129\n",
      "[997] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "997 0 0.004548228345811367 0.9032258064516129\n",
      "[998] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "998 0 0.004545284900814295 0.9032258064516129\n",
      "[999] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "999 0 0.004542343318462372 0.9032258064516129\n",
      "[1000] loss/acc for train: (0.005, 0.903), valid: (0.005, 0.903), test: (0.005, 0.903)\n",
      "Done 1.315051555633545\n",
      "test accuracy 0.903\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = df_combined[['MAG','MAG5yr','Count_L','Count_S']]\n",
    "labels = df_combined[['MAG10yr']]\n",
    "labels = labels['MAG10yr'].astype(int)\n",
    "\n",
    "batch_size = 35\n",
    "test_loader, val_loader, train_loader, train_dataset, val_dataset, test_dataset, num_classes = split_data(data, labels, batch_size)\n",
    "\n",
    "#print_dataset2(train_dataset, \"Training Dataset\")\n",
    "#print_dataset2(val_dataset  , \"Validation Dataset\")\n",
    "#print_dataset2(test_dataset , \"Testing Dataset\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 1\n",
    "input_dim = 256\n",
    "\n",
    "# Instantiate model and define loss function and optimizer\n",
    "print(num_classes)\n",
    "model = NeuralNetwork(input_variables=4,num_classes=2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "epochs=1000\n",
    "train_metrics, val_metrics, test_metrics = train_test_model_epochs(model,num_epochs=epochs)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_results( pd.DataFrame(train_metrics)\n",
    "            , pd.DataFrame(val_metrics)\n",
    "            , pd.DataFrame(test_metrics)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0307d14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "40199656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [0]\n",
      "1\n",
      "Start  1683924820.362926\n",
      "0 0 0.016292527318000793 0.06451612903225806\n",
      "[1] loss/acc for train: (0.016, 0.065), valid: (0.016, 0.065), test: (0.016, 0.065)\n",
      "1 0 0.016233177855610847 0.06451612903225806\n",
      "[2] loss/acc for train: (0.016, 0.065), valid: (0.016, 0.065), test: (0.016, 0.065)\n",
      "2 0 0.016174226999282837 0.06451612903225806\n",
      "[3] loss/acc for train: (0.016, 0.065), valid: (0.016, 0.065), test: (0.016, 0.065)\n",
      "3 0 0.01611568219959736 0.06451612903225806\n",
      "[4] loss/acc for train: (0.016, 0.065), valid: (0.016, 0.065), test: (0.016, 0.065)\n",
      "4 0 0.01605754718184471 0.06451612903225806\n",
      "[5] loss/acc for train: (0.016, 0.065), valid: (0.016, 0.065), test: (0.016, 0.065)\n",
      "5 0 0.01599982939660549 0.06451612903225806\n",
      "[6] loss/acc for train: (0.016, 0.065), valid: (0.016, 0.065), test: (0.016, 0.065)\n",
      "6 0 0.0159425288438797 0.06451612903225806\n",
      "[7] loss/acc for train: (0.016, 0.065), valid: (0.016, 0.065), test: (0.016, 0.065)\n",
      "7 0 0.015885651111602783 0.06451612903225806\n",
      "[8] loss/acc for train: (0.016, 0.065), valid: (0.016, 0.065), test: (0.016, 0.065)\n",
      "8 0 0.015829196199774742 0.06451612903225806\n",
      "[9] loss/acc for train: (0.016, 0.065), valid: (0.016, 0.065), test: (0.016, 0.065)\n",
      "9 0 0.015773175284266472 0.06451612903225806\n",
      "[10] loss/acc for train: (0.016, 0.065), valid: (0.016, 0.065), test: (0.016, 0.065)\n",
      "10 0 0.015717580914497375 0.06451612903225806\n",
      "[11] loss/acc for train: (0.016, 0.065), valid: (0.016, 0.065), test: (0.016, 0.065)\n",
      "11 0 0.01566242426633835 0.06451612903225806\n",
      "[12] loss/acc for train: (0.016, 0.065), valid: (0.016, 0.065), test: (0.016, 0.065)\n",
      "12 0 0.015607703477144241 0.06451612903225806\n",
      "[13] loss/acc for train: (0.016, 0.065), valid: (0.016, 0.065), test: (0.016, 0.065)\n",
      "13 0 0.015553419478237629 0.06451612903225806\n",
      "[14] loss/acc for train: (0.016, 0.065), valid: (0.015, 0.065), test: (0.015, 0.065)\n",
      "14 0 0.015499575063586235 0.06451612903225806\n",
      "[15] loss/acc for train: (0.015, 0.065), valid: (0.015, 0.065), test: (0.015, 0.065)\n",
      "15 0 0.015446173958480358 0.06451612903225806\n",
      "[16] loss/acc for train: (0.015, 0.065), valid: (0.015, 0.065), test: (0.015, 0.065)\n",
      "16 0 0.015393213368952274 0.06451612903225806\n",
      "[17] loss/acc for train: (0.015, 0.065), valid: (0.015, 0.097), test: (0.015, 0.097)\n",
      "17 0 0.015340694226324558 0.0967741935483871\n",
      "[18] loss/acc for train: (0.015, 0.097), valid: (0.015, 0.129), test: (0.015, 0.129)\n",
      "18 0 0.015288613736629486 0.12903225806451613\n",
      "[19] loss/acc for train: (0.015, 0.129), valid: (0.015, 0.161), test: (0.015, 0.161)\n",
      "19 0 0.015236979350447655 0.16129032258064516\n",
      "[20] loss/acc for train: (0.015, 0.161), valid: (0.015, 0.161), test: (0.015, 0.161)\n",
      "20 0 0.015185784548521042 0.16129032258064516\n",
      "[21] loss/acc for train: (0.015, 0.161), valid: (0.015, 0.194), test: (0.015, 0.194)\n",
      "21 0 0.015135029330849648 0.1935483870967742\n",
      "[22] loss/acc for train: (0.015, 0.194), valid: (0.015, 0.194), test: (0.015, 0.194)\n",
      "22 0 0.015084713697433472 0.1935483870967742\n",
      "[23] loss/acc for train: (0.015, 0.194), valid: (0.015, 0.194), test: (0.015, 0.194)\n",
      "23 0 0.015034829266369343 0.1935483870967742\n",
      "[24] loss/acc for train: (0.015, 0.194), valid: (0.015, 0.194), test: (0.015, 0.194)\n",
      "24 0 0.014985383488237858 0.1935483870967742\n",
      "[25] loss/acc for train: (0.015, 0.194), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "25 0 0.014936370775103569 0.22580645161290322\n",
      "[26] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.258), test: (0.015, 0.258)\n",
      "26 0 0.014887787401676178 0.25806451612903225\n",
      "[27] loss/acc for train: (0.015, 0.258), valid: (0.015, 0.258), test: (0.015, 0.258)\n",
      "27 0 0.014839639887213707 0.25806451612903225\n",
      "[28] loss/acc for train: (0.015, 0.258), valid: (0.015, 0.258), test: (0.015, 0.258)\n",
      "28 0 0.014791983179748058 0.25806451612903225\n",
      "[29] loss/acc for train: (0.015, 0.258), valid: (0.015, 0.258), test: (0.015, 0.258)\n",
      "29 0 0.01474475022405386 0.25806451612903225\n",
      "[30] loss/acc for train: (0.015, 0.258), valid: (0.015, 0.258), test: (0.015, 0.258)\n",
      "30 0 0.014697934500873089 0.25806451612903225\n",
      "[31] loss/acc for train: (0.015, 0.258), valid: (0.015, 0.258), test: (0.015, 0.258)\n",
      "31 0 0.014651631005108356 0.25806451612903225\n",
      "[32] loss/acc for train: (0.015, 0.258), valid: (0.015, 0.258), test: (0.015, 0.258)\n",
      "32 0 0.014605815522372723 0.25806451612903225\n",
      "[33] loss/acc for train: (0.015, 0.258), valid: (0.015, 0.258), test: (0.015, 0.258)\n",
      "33 0 0.014560412615537643 0.25806451612903225\n",
      "[34] loss/acc for train: (0.015, 0.258), valid: (0.015, 0.258), test: (0.015, 0.258)\n",
      "34 0 0.014515413902699947 0.25806451612903225\n",
      "[35] loss/acc for train: (0.015, 0.258), valid: (0.014, 0.258), test: (0.014, 0.258)\n",
      "35 0 0.014470814727246761 0.25806451612903225\n",
      "[36] loss/acc for train: (0.014, 0.258), valid: (0.014, 0.258), test: (0.014, 0.258)\n",
      "36 0 0.014426691457629204 0.25806451612903225\n",
      "[37] loss/acc for train: (0.014, 0.258), valid: (0.014, 0.258), test: (0.014, 0.258)\n",
      "37 0 0.014383118599653244 0.25806451612903225\n",
      "[38] loss/acc for train: (0.014, 0.258), valid: (0.014, 0.258), test: (0.014, 0.258)\n",
      "38 0 0.01433993224054575 0.25806451612903225\n",
      "[39] loss/acc for train: (0.014, 0.258), valid: (0.014, 0.290), test: (0.014, 0.290)\n",
      "39 0 0.014297126792371273 0.2903225806451613\n",
      "[40] loss/acc for train: (0.014, 0.290), valid: (0.014, 0.419), test: (0.014, 0.419)\n",
      "40 0 0.014254694804549217 0.41935483870967744\n",
      "[41] loss/acc for train: (0.014, 0.419), valid: (0.014, 0.419), test: (0.014, 0.419)\n",
      "41 0 0.014212633483111858 0.41935483870967744\n",
      "[42] loss/acc for train: (0.014, 0.419), valid: (0.014, 0.419), test: (0.014, 0.419)\n",
      "42 0 0.014170926064252853 0.41935483870967744\n",
      "[43] loss/acc for train: (0.014, 0.419), valid: (0.014, 0.419), test: (0.014, 0.419)\n",
      "43 0 0.01412956789135933 0.41935483870967744\n",
      "[44] loss/acc for train: (0.014, 0.419), valid: (0.014, 0.516), test: (0.014, 0.516)\n",
      "44 0 0.014088558033108711 0.5161290322580645\n",
      "[45] loss/acc for train: (0.014, 0.516), valid: (0.014, 0.516), test: (0.014, 0.516)\n",
      "45 0 0.014047885313630104 0.5161290322580645\n",
      "[46] loss/acc for train: (0.014, 0.516), valid: (0.014, 0.548), test: (0.014, 0.548)\n",
      "46 0 0.014007538557052612 0.5483870967741935\n",
      "[47] loss/acc for train: (0.014, 0.548), valid: (0.014, 0.548), test: (0.014, 0.548)\n",
      "47 0 0.013967517763376236 0.5483870967741935\n",
      "[48] loss/acc for train: (0.014, 0.548), valid: (0.014, 0.548), test: (0.014, 0.548)\n",
      "48 0 0.01392780989408493 0.5483870967741935\n",
      "[49] loss/acc for train: (0.014, 0.548), valid: (0.014, 0.548), test: (0.014, 0.548)\n",
      "49 0 0.013888411223888397 0.5483870967741935\n",
      "[50] loss/acc for train: (0.014, 0.548), valid: (0.014, 0.548), test: (0.014, 0.548)\n",
      "50 0 0.013849317096173763 0.5483870967741935\n",
      "[51] loss/acc for train: (0.014, 0.548), valid: (0.014, 0.548), test: (0.014, 0.548)\n",
      "51 0 0.013810514472424984 0.5483870967741935\n",
      "[52] loss/acc for train: (0.014, 0.548), valid: (0.014, 0.548), test: (0.014, 0.548)\n",
      "52 0 0.013772002421319485 0.5483870967741935\n",
      "[53] loss/acc for train: (0.014, 0.548), valid: (0.014, 0.548), test: (0.014, 0.548)\n",
      "53 0 0.01373377162963152 0.5483870967741935\n",
      "[54] loss/acc for train: (0.014, 0.548), valid: (0.014, 0.548), test: (0.014, 0.548)\n",
      "54 0 0.013695814646780491 0.5483870967741935\n",
      "[55] loss/acc for train: (0.014, 0.548), valid: (0.014, 0.548), test: (0.014, 0.548)\n",
      "55 0 0.013658211566507816 0.5483870967741935\n",
      "[56] loss/acc for train: (0.014, 0.548), valid: (0.014, 0.548), test: (0.014, 0.548)\n",
      "56 0 0.013620926067233086 0.5483870967741935\n",
      "[57] loss/acc for train: (0.014, 0.548), valid: (0.014, 0.548), test: (0.014, 0.548)\n",
      "57 0 0.013583903200924397 0.5483870967741935\n",
      "[58] loss/acc for train: (0.014, 0.548), valid: (0.014, 0.548), test: (0.014, 0.548)\n",
      "58 0 0.013547134585678577 0.5483870967741935\n",
      "[59] loss/acc for train: (0.014, 0.548), valid: (0.014, 0.645), test: (0.014, 0.645)\n",
      "59 0 0.013510611839592457 0.6451612903225806\n",
      "[60] loss/acc for train: (0.014, 0.645), valid: (0.013, 0.645), test: (0.013, 0.645)\n",
      "60 0 0.013474328443408012 0.6451612903225806\n",
      "[61] loss/acc for train: (0.013, 0.645), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "61 0 0.013438275083899498 0.6774193548387096\n",
      "[62] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "62 0 0.013402448035776615 0.6774193548387096\n",
      "[63] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "63 0 0.013366837054491043 0.6774193548387096\n",
      "[64] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "64 0 0.013331437483429909 0.7096774193548387\n",
      "[65] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.742), test: (0.013, 0.742)\n",
      "65 0 0.01329624094069004 0.7419354838709677\n",
      "[66] loss/acc for train: (0.013, 0.742), valid: (0.013, 0.839), test: (0.013, 0.839)\n",
      "66 0 0.013261242769658566 0.8387096774193549\n",
      "[67] loss/acc for train: (0.013, 0.839), valid: (0.013, 0.968), test: (0.013, 0.968)\n",
      "67 0 0.013226433657109737 0.967741935483871\n",
      "[68] loss/acc for train: (0.013, 0.968), valid: (0.013, 0.968), test: (0.013, 0.968)\n",
      "68 0 0.013191809877753258 0.967741935483871\n",
      "[69] loss/acc for train: (0.013, 0.968), valid: (0.013, 1.000), test: (0.013, 1.000)\n",
      "69 0 0.013157363049685955 1.0\n",
      "[70] loss/acc for train: (0.013, 1.000), valid: (0.013, 1.000), test: (0.013, 1.000)\n",
      "70 0 0.013123090378940105 1.0\n",
      "[71] loss/acc for train: (0.013, 1.000), valid: (0.013, 0.935), test: (0.013, 0.935)\n",
      "71 0 0.013088984414935112 0.9354838709677419\n",
      "[72] loss/acc for train: (0.013, 0.935), valid: (0.013, 0.935), test: (0.013, 0.935)\n",
      "72 0 0.01305503398180008 0.9354838709677419\n",
      "[73] loss/acc for train: (0.013, 0.935), valid: (0.013, 0.935), test: (0.013, 0.935)\n",
      "73 0 0.013021241873502731 0.9354838709677419\n",
      "[74] loss/acc for train: (0.013, 0.935), valid: (0.013, 0.935), test: (0.013, 0.935)\n",
      "74 0 0.012987595982849598 0.9354838709677419\n",
      "[75] loss/acc for train: (0.013, 0.935), valid: (0.013, 0.935), test: (0.013, 0.935)\n",
      "75 0 0.012954095378518105 0.9354838709677419\n",
      "[76] loss/acc for train: (0.013, 0.935), valid: (0.013, 0.935), test: (0.013, 0.935)\n",
      "76 0 0.012920732609927654 0.9354838709677419\n",
      "[77] loss/acc for train: (0.013, 0.935), valid: (0.013, 0.935), test: (0.013, 0.935)\n",
      "77 0 0.012887503020465374 0.9354838709677419\n",
      "[78] loss/acc for train: (0.013, 0.935), valid: (0.013, 0.935), test: (0.013, 0.935)\n",
      "78 0 0.012854400090873241 0.9354838709677419\n",
      "[79] loss/acc for train: (0.013, 0.935), valid: (0.013, 0.935), test: (0.013, 0.935)\n",
      "79 0 0.012821419164538383 0.9354838709677419\n",
      "[80] loss/acc for train: (0.013, 0.935), valid: (0.013, 0.935), test: (0.013, 0.935)\n",
      "80 0 0.012788556516170502 0.9354838709677419\n",
      "[81] loss/acc for train: (0.013, 0.935), valid: (0.013, 0.935), test: (0.013, 0.935)\n",
      "81 0 0.012755808420479298 0.9354838709677419\n",
      "[82] loss/acc for train: (0.013, 0.935), valid: (0.013, 0.935), test: (0.013, 0.935)\n",
      "82 0 0.012723168358206749 0.9354838709677419\n",
      "[83] loss/acc for train: (0.013, 0.935), valid: (0.013, 0.935), test: (0.013, 0.935)\n",
      "83 0 0.012690632604062557 0.9354838709677419\n",
      "[84] loss/acc for train: (0.013, 0.935), valid: (0.013, 0.935), test: (0.013, 0.935)\n",
      "84 0 0.012658195570111275 0.9354838709677419\n",
      "[85] loss/acc for train: (0.013, 0.935), valid: (0.013, 0.935), test: (0.013, 0.935)\n",
      "85 0 0.01262585911899805 0.9354838709677419\n",
      "[86] loss/acc for train: (0.013, 0.935), valid: (0.013, 0.935), test: (0.013, 0.935)\n",
      "86 0 0.012593632563948631 0.9354838709677419\n",
      "[87] loss/acc for train: (0.013, 0.935), valid: (0.013, 0.935), test: (0.013, 0.935)\n",
      "87 0 0.012561499141156673 0.9354838709677419\n",
      "[88] loss/acc for train: (0.013, 0.935), valid: (0.013, 0.935), test: (0.013, 0.935)\n",
      "88 0 0.012529448606073856 0.9354838709677419\n",
      "[89] loss/acc for train: (0.013, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "89 0 0.012497480027377605 0.9354838709677419\n",
      "[90] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "90 0 0.012465590611100197 0.9354838709677419\n",
      "[91] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "91 0 0.012433771975338459 0.9354838709677419\n",
      "[92] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "92 0 0.012402025051414967 0.9354838709677419\n",
      "[93] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "93 0 0.012370348908007145 0.9354838709677419\n",
      "[94] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "94 0 0.012338739819824696 0.9354838709677419\n",
      "[95] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "95 0 0.012307193130254745 0.9354838709677419\n",
      "[96] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "96 0 0.012275706976652145 0.9354838709677419\n",
      "[97] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "97 0 0.012244278565049171 0.9354838709677419\n",
      "[98] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "98 0 0.012212909758090973 0.9354838709677419\n",
      "[99] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "99 0 0.012181592173874378 0.9354838709677419\n",
      "[100] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "100 0 0.012150328606367111 0.9354838709677419\n",
      "[101] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "101 0 0.012119113467633724 0.9354838709677419\n",
      "[102] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "102 0 0.012087952345609665 0.9354838709677419\n",
      "[103] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "103 0 0.012056834995746613 0.9354838709677419\n",
      "[104] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "104 0 0.012025761418044567 0.9354838709677419\n",
      "[105] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "105 0 0.011994737200438976 0.9354838709677419\n",
      "[106] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "106 0 0.011963754892349243 0.9354838709677419\n",
      "[107] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "107 0 0.011932814493775368 0.9354838709677419\n",
      "[108] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "108 0 0.011901915073394775 0.9354838709677419\n",
      "[109] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "109 0 0.011871053837239742 0.9354838709677419\n",
      "[110] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "110 0 0.011840236373245716 0.9354838709677419\n",
      "[111] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "111 0 0.011809454299509525 0.9354838709677419\n",
      "[112] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "112 0 0.011778712272644043 0.9354838709677419\n",
      "[113] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "113 0 0.011748007498681545 0.9354838709677419\n",
      "[114] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "114 0 0.011717338114976883 0.9354838709677419\n",
      "[115] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "115 0 0.011686707846820354 0.9354838709677419\n",
      "[116] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "116 0 0.011656110174953938 0.9354838709677419\n",
      "[117] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "117 0 0.011625552549958229 0.9354838709677419\n",
      "[118] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "118 0 0.011595027521252632 0.9354838709677419\n",
      "[119] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "119 0 0.011564538814127445 0.9354838709677419\n",
      "[120] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "120 0 0.011534085497260094 0.9354838709677419\n",
      "[121] loss/acc for train: (0.012, 0.935), valid: (0.012, 0.935), test: (0.012, 0.935)\n",
      "121 0 0.011503669433295727 0.9354838709677419\n",
      "[122] loss/acc for train: (0.012, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "122 0 0.011473285965621471 0.9354838709677419\n",
      "[123] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "123 0 0.011442937888205051 0.9354838709677419\n",
      "[124] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "124 0 0.01141262799501419 0.9354838709677419\n",
      "[125] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "125 0 0.011382353492081165 0.9354838709677419\n",
      "[126] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "126 0 0.0113521134480834 0.9354838709677419\n",
      "[127] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "127 0 0.011321907863020897 0.9354838709677419\n",
      "[128] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "128 0 0.011291739530861378 0.9354838709677419\n",
      "[129] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "129 0 0.011261608451604843 0.9354838709677419\n",
      "[130] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "130 0 0.011231515556573868 0.9354838709677419\n",
      "[131] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "131 0 0.011201459914445877 0.9354838709677419\n",
      "[132] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "132 0 0.01117144338786602 0.9354838709677419\n",
      "[133] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "133 0 0.011141463182866573 0.9354838709677419\n",
      "[134] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "134 0 0.011111523024737835 0.9354838709677419\n",
      "[135] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "135 0 0.01108162198215723 0.9354838709677419\n",
      "[136] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "136 0 0.011051761917769909 0.9354838709677419\n",
      "[137] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "137 0 0.011021941900253296 0.9354838709677419\n",
      "[138] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "138 0 0.01099216379225254 0.9354838709677419\n",
      "[139] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "139 0 0.010962423868477345 0.9354838709677419\n",
      "[140] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "140 0 0.010932731442153454 0.9354838709677419\n",
      "[141] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "141 0 0.010903079062700272 0.9354838709677419\n",
      "[142] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "142 0 0.010873474180698395 0.9354838709677419\n",
      "[143] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "143 0 0.010843946598470211 0.9354838709677419\n",
      "[144] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "144 0 0.010814491659402847 0.9354838709677419\n",
      "[145] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "145 0 0.010785087011754513 0.9354838709677419\n",
      "[146] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "146 0 0.010755733586847782 0.9354838709677419\n",
      "[147] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147 0 0.010726426728069782 0.9354838709677419\n",
      "[148] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "148 0 0.010697170160710812 0.9354838709677419\n",
      "[149] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "149 0 0.01066796574741602 0.9354838709677419\n",
      "[150] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "150 0 0.010638811625540257 0.9354838709677419\n",
      "[151] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "151 0 0.010609708726406097 0.9354838709677419\n",
      "[152] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "152 0 0.010580657981336117 0.9354838709677419\n",
      "[153] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "153 0 0.010551657527685165 0.9354838709677419\n",
      "[154] loss/acc for train: (0.011, 0.935), valid: (0.011, 0.935), test: (0.011, 0.935)\n",
      "154 0 0.010522712022066116 0.9354838709677419\n",
      "[155] loss/acc for train: (0.011, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "155 0 0.010493820533156395 0.9354838709677419\n",
      "[156] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "156 0 0.010464983060956001 0.9354838709677419\n",
      "[157] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "157 0 0.01043620239943266 0.9354838709677419\n",
      "[158] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "158 0 0.01040747668594122 0.9354838709677419\n",
      "[159] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "159 0 0.010378806851804256 0.9354838709677419\n",
      "[160] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "160 0 0.01035019475966692 0.9354838709677419\n",
      "[161] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "161 0 0.010321642272174358 0.9354838709677419\n",
      "[162] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "162 0 0.010293148458003998 0.9354838709677419\n",
      "[163] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "163 0 0.010264713317155838 0.9354838709677419\n",
      "[164] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "164 0 0.010236340574920177 0.9354838709677419\n",
      "[165] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "165 0 0.010208029299974442 0.9354838709677419\n",
      "[166] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "166 0 0.010179782286286354 0.9354838709677419\n",
      "[167] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "167 0 0.010151597671210766 0.9354838709677419\n",
      "[168] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "168 0 0.010123477317392826 0.9354838709677419\n",
      "[169] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "169 0 0.010095421224832535 0.9354838709677419\n",
      "[170] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "170 0 0.010067434050142765 0.9354838709677419\n",
      "[171] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "171 0 0.010039512999355793 0.9354838709677419\n",
      "[172] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "172 0 0.010011660866439342 0.9354838709677419\n",
      "[173] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "173 0 0.009983876720070839 0.9354838709677419\n",
      "[174] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "174 0 0.009956162422895432 0.9354838709677419\n",
      "[175] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "175 0 0.009928518906235695 0.9354838709677419\n",
      "[176] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "176 0 0.009900946170091629 0.9354838709677419\n",
      "[177] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "177 0 0.009873474016785622 0.9354838709677419\n",
      "[178] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "178 0 0.00984608381986618 0.9354838709677419\n",
      "[179] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "179 0 0.009818781167268753 0.9354838709677419\n",
      "[180] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "180 0 0.009791577234864235 0.9354838709677419\n",
      "[181] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "181 0 0.009764452464878559 0.9354838709677419\n",
      "[182] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "182 0 0.0097374077886343 0.9354838709677419\n",
      "[183] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "183 0 0.009710472077131271 0.9354838709677419\n",
      "[184] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "184 0 0.009683639742434025 0.9354838709677419\n",
      "[185] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "185 0 0.009656894020736217 0.9354838709677419\n",
      "[186] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "186 0 0.009630233980715275 0.9354838709677419\n",
      "[187] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "187 0 0.009603655897080898 0.9354838709677419\n",
      "[188] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "188 0 0.009577159769833088 0.9354838709677419\n",
      "[189] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "189 0 0.009550749324262142 0.9354838709677419\n",
      "[190] loss/acc for train: (0.010, 0.935), valid: (0.010, 0.935), test: (0.010, 0.935)\n",
      "190 0 0.009524419903755188 0.9354838709677419\n",
      "[191] loss/acc for train: (0.010, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "191 0 0.009498176164925098 0.9354838709677419\n",
      "[192] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "192 0 0.00947201531380415 0.9354838709677419\n",
      "[193] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "193 0 0.00944594107568264 0.9354838709677419\n",
      "[194] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "194 0 0.00941995158791542 0.9354838709677419\n",
      "[195] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "195 0 0.009394047781825066 0.9354838709677419\n",
      "[196] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "196 0 0.009368229657411575 0.9354838709677419\n",
      "[197] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "197 0 0.009342498145997524 0.9354838709677419\n",
      "[198] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "198 0 0.009316856041550636 0.9354838709677419\n",
      "[199] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "199 0 0.009291300550103188 0.9354838709677419\n",
      "[200] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "200 0 0.009265832602977753 0.9354838709677419\n",
      "[201] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "201 0 0.009240454994142056 0.9354838709677419\n",
      "[202] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "202 0 0.009215167723596096 0.9354838709677419\n",
      "[203] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "203 0 0.009189970791339874 0.9354838709677419\n",
      "[204] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "204 0 0.00916486419737339 0.9354838709677419\n",
      "[205] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "205 0 0.009139848873019218 0.9354838709677419\n",
      "[206] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "206 0 0.009114925749599934 0.9354838709677419\n",
      "[207] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "207 0 0.009090094827115536 0.9354838709677419\n",
      "[208] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "208 0 0.009065357968211174 0.9354838709677419\n",
      "[209] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "209 0 0.009040714241564274 0.9354838709677419\n",
      "[210] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "210 0 0.009016165509819984 0.9354838709677419\n",
      "[211] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "211 0 0.008991709910333157 0.9354838709677419\n",
      "[212] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "212 0 0.008967351168394089 0.9354838709677419\n",
      "[213] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "213 0 0.008943088352680206 0.9354838709677419\n",
      "[214] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "214 0 0.008918922394514084 0.9354838709677419\n",
      "[215] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "215 0 0.008894850499927998 0.9354838709677419\n",
      "[216] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "216 0 0.00887087918817997 0.9354838709677419\n",
      "[217] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "217 0 0.008847004733979702 0.9354838709677419\n",
      "[218] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "218 0 0.008823227137327194 0.9354838709677419\n",
      "[219] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "219 0 0.008799550123512745 0.9354838709677419\n",
      "[220] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "220 0 0.008775971829891205 0.9354838709677419\n",
      "[221] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "221 0 0.008752492256462574 0.9354838709677419\n",
      "[222] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "222 0 0.008729112334549427 0.9354838709677419\n",
      "[223] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "223 0 0.008705832064151764 0.9354838709677419\n",
      "[224] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "224 0 0.008682653307914734 0.9354838709677419\n",
      "[225] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "225 0 0.008659576065838337 0.9354838709677419\n",
      "[226] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "226 0 0.008636599406599998 0.9354838709677419\n",
      "[227] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "227 0 0.008613723330199718 0.9354838709677419\n",
      "[228] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "228 0 0.008590948767960072 0.9354838709677419\n",
      "[229] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "229 0 0.008568278513848782 0.9354838709677419\n",
      "[230] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "230 0 0.00854570884257555 0.9354838709677419\n",
      "[231] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "231 0 0.008523241616785526 0.9354838709677419\n",
      "[232] loss/acc for train: (0.009, 0.935), valid: (0.009, 0.935), test: (0.009, 0.935)\n",
      "232 0 0.008500877767801285 0.9354838709677419\n",
      "[233] loss/acc for train: (0.009, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "233 0 0.008478616364300251 0.9354838709677419\n",
      "[234] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "234 0 0.008456457406282425 0.9354838709677419\n",
      "[235] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "235 0 0.008434402756392956 0.9354838709677419\n",
      "[236] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "236 0 0.00841244962066412 0.9354838709677419\n",
      "[237] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "237 0 0.008390601724386215 0.9354838709677419\n",
      "[238] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "238 0 0.008368856273591518 0.9354838709677419\n",
      "[239] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "239 0 0.008347214199602604 0.9354838709677419\n",
      "[240] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "240 0 0.008325676433742046 0.9354838709677419\n",
      "[241] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "241 0 0.008304242044687271 0.9354838709677419\n",
      "[242] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "242 0 0.008282911963760853 0.9354838709677419\n",
      "[243] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "243 0 0.008261686190962791 0.9354838709677419\n",
      "[244] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "244 0 0.008240562863647938 0.9354838709677419\n",
      "[245] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "245 0 0.008219543844461441 0.9354838709677419\n",
      "[246] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "246 0 0.008198628202080727 0.9354838709677419\n",
      "[247] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "247 0 0.008177820593118668 0.9354838709677419\n",
      "[248] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "248 0 0.008157124742865562 0.9354838709677419\n",
      "[249] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "249 0 0.008136533200740814 0.9354838709677419\n",
      "[250] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "250 0 0.008116045966744423 0.9354838709677419\n",
      "[251] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "251 0 0.008095663040876389 0.9354838709677419\n",
      "[252] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "252 0 0.008075383491814137 0.9354838709677419\n",
      "[253] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "253 0 0.008055216632783413 0.9354838709677419\n",
      "[254] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "254 0 0.008035155013203621 0.9354838709677419\n",
      "[255] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "255 0 0.008015196770429611 0.9354838709677419\n",
      "[256] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "256 0 0.007995341904461384 0.9354838709677419\n",
      "[257] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "257 0 0.007975591346621513 0.9354838709677419\n",
      "[258] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "258 0 0.007955941371619701 0.9354838709677419\n",
      "[259] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "259 0 0.007936397567391396 0.9354838709677419\n",
      "[260] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "260 0 0.007916955277323723 0.9354838709677419\n",
      "[261] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "261 0 0.007897614501416683 0.9354838709677419\n",
      "[262] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "262 0 0.007878377102315426 0.9354838709677419\n",
      "[263] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "263 0 0.007859241217374802 0.9354838709677419\n",
      "[264] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "264 0 0.00784020684659481 0.9354838709677419\n",
      "[265] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "265 0 0.007821273058652878 0.9354838709677419\n",
      "[266] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "266 0 0.00780244218185544 0.9354838709677419\n",
      "[267] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "267 0 0.007783710956573486 0.9354838709677419\n",
      "[268] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "268 0 0.007765080779790878 0.9354838709677419\n",
      "[269] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "269 0 0.007746551651507616 0.9354838709677419\n",
      "[270] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "270 0 0.0077281249687075615 0.9354838709677419\n",
      "[271] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "271 0 0.007709797006100416 0.9354838709677419\n",
      "[272] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "272 0 0.007691569160670042 0.9354838709677419\n",
      "[273] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "273 0 0.007673441898077726 0.9354838709677419\n",
      "[274] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "274 0 0.0076554142870008945 0.9354838709677419\n",
      "[275] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "275 0 0.007637485861778259 0.9354838709677419\n",
      "[276] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "276 0 0.007619655691087246 0.9354838709677419\n",
      "[277] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "277 0 0.007601925637573004 0.9354838709677419\n",
      "[278] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "278 0 0.007584293372929096 0.9354838709677419\n",
      "[279] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "279 0 0.00756676122546196 0.9354838709677419\n",
      "[280] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "280 0 0.007549326866865158 0.9354838709677419\n",
      "[281] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "281 0 0.007531990297138691 0.9354838709677419\n",
      "[282] loss/acc for train: (0.008, 0.935), valid: (0.008, 0.935), test: (0.008, 0.935)\n",
      "282 0 0.0075147515162825584 0.9354838709677419\n",
      "[283] loss/acc for train: (0.008, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "283 0 0.007497611455619335 0.9354838709677419\n",
      "[284] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "284 0 0.007480567786842585 0.9354838709677419\n",
      "[285] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "285 0 0.007463622838258743 0.9354838709677419\n",
      "[286] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "286 0 0.007446772418916225 0.9354838709677419\n",
      "[287] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "287 0 0.007430020719766617 0.9354838709677419\n",
      "[288] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "288 0 0.007413365412503481 0.9354838709677419\n",
      "[289] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "289 0 0.007396805100142956 0.9354838709677419\n",
      "[290] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "290 0 0.007380340714007616 0.9354838709677419\n",
      "[291] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "291 0 0.007363973185420036 0.9354838709677419\n",
      "[292] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "292 0 0.007347701583057642 0.9354838709677419\n",
      "[293] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "293 0 0.007331524044275284 0.9354838709677419\n",
      "[294] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "294 0 0.007315441966056824 0.9354838709677419\n",
      "[295] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "295 0 0.007299454882740974 0.9354838709677419\n",
      "[296] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "296 0 0.007283561397343874 0.9354838709677419\n",
      "[297] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "297 0 0.007267763838171959 0.9354838709677419\n",
      "[298] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "298 0 0.007252058945596218 0.9354838709677419\n",
      "[299] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "299 0 0.007236446253955364 0.9354838709677419\n",
      "[300] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "300 0 0.007220929488539696 0.9354838709677419\n",
      "[301] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "301 0 0.007205503527075052 0.9354838709677419\n",
      "[302] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "302 0 0.00719017069786787 0.9354838709677419\n",
      "[303] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "303 0 0.007174932397902012 0.9354838709677419\n",
      "[304] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "304 0 0.007159784436225891 0.9354838709677419\n",
      "[305] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "305 0 0.007144728675484657 0.9354838709677419\n",
      "[306] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "306 0 0.00712976511567831 0.9354838709677419\n",
      "[307] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "307 0 0.007114891428500414 0.9354838709677419\n",
      "[308] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "308 0 0.007100109476596117 0.9354838709677419\n",
      "[309] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "309 0 0.0070854187943041325 0.9354838709677419\n",
      "[310] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "310 0 0.007070816587656736 0.9354838709677419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[311] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "311 0 0.00705630611628294 0.9354838709677419\n",
      "[312] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "312 0 0.007041884586215019 0.9354838709677419\n",
      "[313] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "313 0 0.007027552928775549 0.9354838709677419\n",
      "[314] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "314 0 0.007013310678303242 0.9354838709677419\n",
      "[315] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "315 0 0.0069991606287658215 0.9354838709677419\n",
      "[316] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "316 0 0.006985098589211702 0.9354838709677419\n",
      "[317] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "317 0 0.006971125025302172 0.9354838709677419\n",
      "[318] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "318 0 0.006957239471375942 0.9354838709677419\n",
      "[319] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "319 0 0.006943440530449152 0.9354838709677419\n",
      "[320] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "320 0 0.006929729133844376 0.9354838709677419\n",
      "[321] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "321 0 0.006916107144206762 0.9354838709677419\n",
      "[322] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "322 0 0.00690257316455245 0.9354838709677419\n",
      "[323] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "323 0 0.006889122538268566 0.9354838709677419\n",
      "[324] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "324 0 0.006875759921967983 0.9354838709677419\n",
      "[325] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "325 0 0.006862482521682978 0.9354838709677419\n",
      "[326] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "326 0 0.0068492889404296875 0.9354838709677419\n",
      "[327] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "327 0 0.006836180575191975 0.9354838709677419\n",
      "[328] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "328 0 0.0068231564946472645 0.9354838709677419\n",
      "[329] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "329 0 0.006810215301811695 0.9354838709677419\n",
      "[330] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "330 0 0.0067973569966852665 0.9354838709677419\n",
      "[331] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "331 0 0.006784582510590553 0.9354838709677419\n",
      "[332] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "332 0 0.006771889980882406 0.9354838709677419\n",
      "[333] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "333 0 0.006759279873222113 0.9354838709677419\n",
      "[334] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "334 0 0.006746751256287098 0.9354838709677419\n",
      "[335] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "335 0 0.0067343031987547874 0.9354838709677419\n",
      "[336] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "336 0 0.00672193756327033 0.9354838709677419\n",
      "[337] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "337 0 0.00670965202152729 0.9354838709677419\n",
      "[338] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "338 0 0.00669744610786438 0.9354838709677419\n",
      "[339] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "339 0 0.006685319356620312 0.9354838709677419\n",
      "[340] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "340 0 0.0066732740961015224 0.9354838709677419\n",
      "[341] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "341 0 0.006661306135356426 0.9354838709677419\n",
      "[342] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "342 0 0.006649416871368885 0.9354838709677419\n",
      "[343] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "343 0 0.006637605372816324 0.9354838709677419\n",
      "[344] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "344 0 0.0066258711740374565 0.9354838709677419\n",
      "[345] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "345 0 0.006614214740693569 0.9354838709677419\n",
      "[346] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "346 0 0.0066026365384459496 0.9354838709677419\n",
      "[347] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "347 0 0.0065911333076655865 0.9354838709677419\n",
      "[348] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "348 0 0.006579706445336342 0.9354838709677419\n",
      "[349] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "349 0 0.006568355951458216 0.9354838709677419\n",
      "[350] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "350 0 0.006557080894708633 0.9354838709677419\n",
      "[351] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "351 0 0.006545879412442446 0.9354838709677419\n",
      "[352] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "352 0 0.006534753367304802 0.9354838709677419\n",
      "[353] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "353 0 0.006523700896650553 0.9354838709677419\n",
      "[354] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "354 0 0.006512722000479698 0.9354838709677419\n",
      "[355] loss/acc for train: (0.007, 0.935), valid: (0.007, 0.935), test: (0.007, 0.935)\n",
      "355 0 0.0065018171444535255 0.9354838709677419\n",
      "[356] loss/acc for train: (0.007, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "356 0 0.006490984931588173 0.9354838709677419\n",
      "[357] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "357 0 0.006480223964899778 0.9354838709677419\n",
      "[358] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "358 0 0.0064695365726947784 0.9354838709677419\n",
      "[359] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "359 0 0.006458920426666737 0.9354838709677419\n",
      "[360] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "360 0 0.0064483750611543655 0.9354838709677419\n",
      "[361] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "361 0 0.006437900010496378 0.9354838709677419\n",
      "[362] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "362 0 0.006427495274692774 0.9354838709677419\n",
      "[363] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "363 0 0.006417161785066128 0.9354838709677419\n",
      "[364] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "364 0 0.006406897213310003 0.9354838709677419\n",
      "[365] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "365 0 0.0063967015594244 0.9354838709677419\n",
      "[366] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "366 0 0.006386573892086744 0.9354838709677419\n",
      "[367] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "367 0 0.0063765160739421844 0.9354838709677419\n",
      "[368] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "368 0 0.006366525311022997 0.9354838709677419\n",
      "[369] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "369 0 0.006356603000313044 0.9354838709677419\n",
      "[370] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "370 0 0.006346746813505888 0.9354838709677419\n",
      "[371] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "371 0 0.00633695675060153 0.9354838709677419\n",
      "[372] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "372 0 0.00632723281159997 0.9354838709677419\n",
      "[373] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "373 0 0.006317576393485069 0.9354838709677419\n",
      "[374] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "374 0 0.0063079833053052425 0.9354838709677419\n",
      "[375] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "375 0 0.006298455409705639 0.9354838709677419\n",
      "[376] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "376 0 0.006288992706686258 0.9354838709677419\n",
      "[377] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "377 0 0.0062795947305858135 0.9354838709677419\n",
      "[378] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "378 0 0.006270260084420443 0.9354838709677419\n",
      "[379] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "379 0 0.0062609887681901455 0.9354838709677419\n",
      "[380] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "380 0 0.006251778453588486 0.9354838709677419\n",
      "[381] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "381 0 0.006242633331567049 0.9354838709677419\n",
      "[382] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "382 0 0.006233549676835537 0.9354838709677419\n",
      "[383] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "383 0 0.006224526558071375 0.9354838709677419\n",
      "[384] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "384 0 0.006215565837919712 0.9354838709677419\n",
      "[385] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "385 0 0.006206665188074112 0.9354838709677419\n",
      "[386] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "386 0 0.006197825074195862 0.9354838709677419\n",
      "[387] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "387 0 0.006189045496284962 0.9354838709677419\n",
      "[388] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "388 0 0.00618032505735755 0.9354838709677419\n",
      "[389] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "389 0 0.006171662826091051 0.9354838709677419\n",
      "[390] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "390 0 0.0061630611307919025 0.9354838709677419\n",
      "[391] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "391 0 0.0061545176431536674 0.9354838709677419\n",
      "[392] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "392 0 0.006146030966192484 0.9354838709677419\n",
      "[393] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "393 0 0.006137602496892214 0.9354838709677419\n",
      "[394] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "394 0 0.006129230372607708 0.9354838709677419\n",
      "[395] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "395 0 0.006120915990322828 0.9354838709677419\n",
      "[396] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "396 0 0.006112657953053713 0.9354838709677419\n",
      "[397] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "397 0 0.006104455795139074 0.9354838709677419\n",
      "[398] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "398 0 0.006096309516578913 0.9354838709677419\n",
      "[399] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "399 0 0.0060882167890667915 0.9354838709677419\n",
      "[400] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "400 0 0.006080180872231722 0.9354838709677419\n",
      "[401] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "401 0 0.006072198040783405 0.9354838709677419\n",
      "[402] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "402 0 0.006064268760383129 0.9354838709677419\n",
      "[403] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "403 0 0.00605639535933733 0.9354838709677419\n",
      "[404] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "404 0 0.006048572715371847 0.9354838709677419\n",
      "[405] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "405 0 0.0060408031567931175 0.9354838709677419\n",
      "[406] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "406 0 0.006033087149262428 0.9354838709677419\n",
      "[407] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "407 0 0.00602542283013463 0.9354838709677419\n",
      "[408] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "408 0 0.006017809733748436 0.9354838709677419\n",
      "[409] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "409 0 0.006010247394442558 0.9354838709677419\n",
      "[410] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "410 0 0.006002736743539572 0.9354838709677419\n",
      "[411] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "411 0 0.005995275918394327 0.9354838709677419\n",
      "[412] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "412 0 0.005987866315990686 0.9354838709677419\n",
      "[413] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "413 0 0.005980505142360926 0.9354838709677419\n",
      "[414] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "414 0 0.005973193794488907 0.9354838709677419\n",
      "[415] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "415 0 0.005965930875390768 0.9354838709677419\n",
      "[416] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "416 0 0.005958717316389084 0.9354838709677419\n",
      "[417] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "417 0 0.005951551720499992 0.9354838709677419\n",
      "[418] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "418 0 0.005944434553384781 0.9354838709677419\n",
      "[419] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "419 0 0.0059373630210757256 0.9354838709677419\n",
      "[420] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "420 0 0.0059303403832018375 0.9354838709677419\n",
      "[421] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "421 0 0.005923362914472818 0.9354838709677419\n",
      "[422] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "422 0 0.00591643201187253 0.9354838709677419\n",
      "[423] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "423 0 0.005909549072384834 0.9354838709677419\n",
      "[424] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "424 0 0.005902709439396858 0.9354838709677419\n",
      "[425] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "425 0 0.005895915441215038 0.9354838709677419\n",
      "[426] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "426 0 0.0058891661465168 0.9354838709677419\n",
      "[427] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "427 0 0.005882461555302143 0.9354838709677419\n",
      "[428] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "428 0 0.005875802598893642 0.9354838709677419\n",
      "[429] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "429 0 0.005869186017662287 0.9354838709677419\n",
      "[430] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "430 0 0.005862614139914513 0.9354838709677419\n",
      "[431] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "431 0 0.005856083240360022 0.9354838709677419\n",
      "[432] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "432 0 0.00584959564730525 0.9354838709677419\n",
      "[433] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "433 0 0.005843151360750198 0.9354838709677419\n",
      "[434] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "434 0 0.005836748983711004 0.9354838709677419\n",
      "[435] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "435 0 0.005830386653542519 0.9354838709677419\n",
      "[436] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "436 0 0.00582406809553504 0.9354838709677419\n",
      "[437] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "437 0 0.005817788653075695 0.9354838709677419\n",
      "[438] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "438 0 0.005811551585793495 0.9354838709677419\n",
      "[439] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "439 0 0.0058053527027368546 0.9354838709677419\n",
      "[440] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "440 0 0.005799194797873497 0.9354838709677419\n",
      "[441] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "441 0 0.005793076008558273 0.9354838709677419\n",
      "[442] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "442 0 0.005786997266113758 0.9354838709677419\n",
      "[443] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "443 0 0.005780958570539951 0.9354838709677419\n",
      "[444] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "444 0 0.0057749561965465546 0.9354838709677419\n",
      "[445] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "445 0 0.005768992938101292 0.9354838709677419\n",
      "[446] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "446 0 0.005763067398220301 0.9354838709677419\n",
      "[447] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "447 0 0.005757180042564869 0.9354838709677419\n",
      "[448] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "448 0 0.0057513294741511345 0.9354838709677419\n",
      "[449] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "449 0 0.005745517089962959 0.9354838709677419\n",
      "[450] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "450 0 0.0057397400960326195 0.9354838709677419\n",
      "[451] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "451 0 0.005734000355005264 0.9354838709677419\n",
      "[452] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "452 0 0.005728296469897032 0.9354838709677419\n",
      "[453] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "453 0 0.00572262704372406 0.9354838709677419\n",
      "[454] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "454 0 0.005716994404792786 0.9354838709677419\n",
      "[455] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "455 0 0.005711396224796772 0.9354838709677419\n",
      "[456] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "456 0 0.005705833435058594 0.9354838709677419\n",
      "[457] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "457 0 0.005700305104255676 0.9354838709677419\n",
      "[458] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "458 0 0.005694810301065445 0.9354838709677419\n",
      "[459] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "459 0 0.0056893485598266125 0.9354838709677419\n",
      "[460] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "460 0 0.005683922208845615 0.9354838709677419\n",
      "[461] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "461 0 0.0056785279884934425 0.9354838709677419\n",
      "[462] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "462 0 0.005673167295753956 0.9354838709677419\n",
      "[463] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "463 0 0.005667838267982006 0.9354838709677419\n",
      "[464] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "464 0 0.005662541836500168 0.9354838709677419\n",
      "[465] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "465 0 0.0056572784669697285 0.9354838709677419\n",
      "[466] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "466 0 0.005652046296745539 0.9354838709677419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[467] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "467 0 0.005646846257150173 0.9354838709677419\n",
      "[468] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "468 0 0.005641676019877195 0.9354838709677419\n",
      "[469] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "469 0 0.005636536981910467 0.9354838709677419\n",
      "[470] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "470 0 0.005631428211927414 0.9354838709677419\n",
      "[471] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "471 0 0.005626352038234472 0.9354838709677419\n",
      "[472] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "472 0 0.005621304735541344 0.9354838709677419\n",
      "[473] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "473 0 0.005616285838186741 0.9354838709677419\n",
      "[474] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "474 0 0.005611298140138388 0.9354838709677419\n",
      "[475] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "475 0 0.005606338381767273 0.9354838709677419\n",
      "[476] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "476 0 0.005601407960057259 0.9354838709677419\n",
      "[477] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "477 0 0.005596506409347057 0.9354838709677419\n",
      "[478] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "478 0 0.005591633729636669 0.9354838709677419\n",
      "[479] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "479 0 0.005586788058280945 0.9354838709677419\n",
      "[480] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "480 0 0.005581970792263746 0.9354838709677419\n",
      "[481] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "481 0 0.005577181000262499 0.9354838709677419\n",
      "[482] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "482 0 0.005572417750954628 0.9354838709677419\n",
      "[483] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "483 0 0.005567682906985283 0.9354838709677419\n",
      "[484] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "484 0 0.005562974605709314 0.9354838709677419\n",
      "[485] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "485 0 0.005558292381465435 0.9354838709677419\n",
      "[486] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "486 0 0.005553637631237507 0.9354838709677419\n",
      "[487] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "487 0 0.005549007561057806 0.9354838709677419\n",
      "[488] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "488 0 0.005544403102248907 0.9354838709677419\n",
      "[489] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "489 0 0.00553982425481081 0.9354838709677419\n",
      "[490] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "490 0 0.00553527195006609 0.9354838709677419\n",
      "[491] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "491 0 0.005530743394047022 0.9354838709677419\n",
      "[492] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "492 0 0.005526239983737469 0.9354838709677419\n",
      "[493] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "493 0 0.005521760787814856 0.9354838709677419\n",
      "[494] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "494 0 0.005517306737601757 0.9354838709677419\n",
      "[495] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "495 0 0.005512875504791737 0.9354838709677419\n",
      "[496] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "496 0 0.0055084689520299435 0.9354838709677419\n",
      "[497] loss/acc for train: (0.006, 0.935), valid: (0.006, 0.935), test: (0.006, 0.935)\n",
      "497 0 0.00550408661365509 0.9354838709677419\n",
      "[498] loss/acc for train: (0.006, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "498 0 0.005499725230038166 0.9354838709677419\n",
      "[499] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "499 0 0.005495388992130756 0.9354838709677419\n",
      "[500] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "500 0 0.0054910737089812756 0.9354838709677419\n",
      "[501] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "501 0 0.005486782640218735 0.9354838709677419\n",
      "[502] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "502 0 0.005482513923197985 0.9354838709677419\n",
      "[503] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "503 0 0.005478267092257738 0.9354838709677419\n",
      "[504] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "504 0 0.00547404121607542 0.9354838709677419\n",
      "[505] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "505 0 0.005469838157296181 0.9354838709677419\n",
      "[506] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "506 0 0.005465656518936157 0.9354838709677419\n",
      "[507] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "507 0 0.00546149630099535 0.9354838709677419\n",
      "[508] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "508 0 0.005457356572151184 0.9354838709677419\n",
      "[509] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "509 0 0.00545323733240366 0.9354838709677419\n",
      "[510] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "510 0 0.005449139047414064 0.9354838709677419\n",
      "[511] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "511 0 0.0054450612515211105 0.9354838709677419\n",
      "[512] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "512 0 0.005441003479063511 0.9354838709677419\n",
      "[513] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "513 0 0.0054369657300412655 0.9354838709677419\n",
      "[514] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "514 0 0.0054329470731318 0.9354838709677419\n",
      "[515] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "515 0 0.0054289489053189754 0.9354838709677419\n",
      "[516] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "516 0 0.005424969829618931 0.9354838709677419\n",
      "[517] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "517 0 0.005421008914709091 0.9354838709677419\n",
      "[518] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "518 0 0.005417068023234606 0.9354838709677419\n",
      "[519] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "519 0 0.005413145292550325 0.9354838709677419\n",
      "[520] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "520 0 0.00540924072265625 0.9354838709677419\n",
      "[521] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "521 0 0.0054053557105362415 0.9354838709677419\n",
      "[522] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "522 0 0.0054014865309000015 0.9354838709677419\n",
      "[523] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "523 0 0.00539763830602169 0.9354838709677419\n",
      "[524] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "524 0 0.00539380544796586 0.9354838709677419\n",
      "[525] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "525 0 0.005389990285038948 0.9354838709677419\n",
      "[526] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "526 0 0.0053861928172409534 0.9354838709677419\n",
      "[527] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "527 0 0.005382412113249302 0.9354838709677419\n",
      "[528] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "528 0 0.005378648638725281 0.9354838709677419\n",
      "[529] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "529 0 0.005374901928007603 0.9354838709677419\n",
      "[530] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "530 0 0.005371171049773693 0.9354838709677419\n",
      "[531] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "531 0 0.005367457866668701 0.9354838709677419\n",
      "[532] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "532 0 0.005363759584724903 0.9354838709677419\n",
      "[533] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "533 0 0.0053600771352648735 0.9354838709677419\n",
      "[534] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "534 0 0.005356411449611187 0.9354838709677419\n",
      "[535] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "535 0 0.005352761130779982 0.9354838709677419\n",
      "[536] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "536 0 0.005349125247448683 0.9354838709677419\n",
      "[537] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "537 0 0.005345506127923727 0.9354838709677419\n",
      "[538] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "538 0 0.0053419009782373905 0.9354838709677419\n",
      "[539] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "539 0 0.005338310729712248 0.9354838709677419\n",
      "[540] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "540 0 0.005334736313670874 0.9354838709677419\n",
      "[541] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "541 0 0.005331175401806831 0.9354838709677419\n",
      "[542] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "542 0 0.005327628459781408 0.9354838709677419\n",
      "[543] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "543 0 0.0053240954875946045 0.9354838709677419\n",
      "[544] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "544 0 0.005320578347891569 0.9354838709677419\n",
      "[545] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "545 0 0.005317073315382004 0.9354838709677419\n",
      "[546] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "546 0 0.005313582252711058 0.9354838709677419\n",
      "[547] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "547 0 0.005310105625540018 0.9354838709677419\n",
      "[548] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "548 0 0.005306641571223736 0.9354838709677419\n",
      "[549] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "549 0 0.005303190555423498 0.9354838709677419\n",
      "[550] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "550 0 0.005299753043800592 0.9354838709677419\n",
      "[551] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "551 0 0.005296328105032444 0.9354838709677419\n",
      "[552] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "552 0 0.005292915273457766 0.9354838709677419\n",
      "[553] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "553 0 0.005289515946060419 0.9354838709677419\n",
      "[554] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "554 0 0.005286128725856543 0.9354838709677419\n",
      "[555] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "555 0 0.005282753147184849 0.9354838709677419\n",
      "[556] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "556 0 0.0052793906070292 0.9354838709677419\n",
      "[557] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "557 0 0.005276039242744446 0.9354838709677419\n",
      "[558] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "558 0 0.005272699519991875 0.9354838709677419\n",
      "[559] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "559 0 0.005269371904432774 0.9354838709677419\n",
      "[560] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "560 0 0.0052660549990832806 0.9354838709677419\n",
      "[561] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "561 0 0.0052627502009272575 0.9354838709677419\n",
      "[562] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "562 0 0.00525945657864213 0.9354838709677419\n",
      "[563] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "563 0 0.00525617366656661 0.9354838709677419\n",
      "[564] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "564 0 0.005252900067716837 0.9354838709677419\n",
      "[565] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "565 0 0.005249639041721821 0.9354838709677419\n",
      "[566] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "566 0 0.005246388725936413 0.9354838709677419\n",
      "[567] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "567 0 0.005243148189038038 0.9354838709677419\n",
      "[568] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "568 0 0.005239917431026697 0.9354838709677419\n",
      "[569] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "569 0 0.005236697383224964 0.9354838709677419\n",
      "[570] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "570 0 0.00523348618298769 0.9354838709677419\n",
      "[571] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "571 0 0.0052302866242825985 0.9354838709677419\n",
      "[572] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "572 0 0.0052270954474806786 0.9354838709677419\n",
      "[573] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "573 0 0.005223914515227079 0.9354838709677419\n",
      "[574] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "574 0 0.005220742896199226 0.9354838709677419\n",
      "[575] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "575 0 0.005217581521719694 0.9354838709677419\n",
      "[576] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "576 0 0.005214427597820759 0.9354838709677419\n",
      "[577] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "577 0 0.005211283452808857 0.9354838709677419\n",
      "[578] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "578 0 0.005208148155361414 0.9354838709677419\n",
      "[579] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "579 0 0.00520502170547843 0.9354838709677419\n",
      "[580] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "580 0 0.0052019041031599045 0.9354838709677419\n",
      "[581] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "581 0 0.005198793951421976 0.9354838709677419\n",
      "[582] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "582 0 0.005195693578571081 0.9354838709677419\n",
      "[583] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "583 0 0.005192600656300783 0.9354838709677419\n",
      "[584] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "584 0 0.005189516115933657 0.9354838709677419\n",
      "[585] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "585 0 0.005186440423130989 0.9354838709677419\n",
      "[586] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "586 0 0.0051833768375217915 0.9354838709677419\n",
      "[587] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "587 0 0.0051803202368319035 0.9354838709677419\n",
      "[588] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "588 0 0.005177270621061325 0.9354838709677419\n",
      "[589] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "589 0 0.00517423078417778 0.9354838709677419\n",
      "[590] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "590 0 0.005171198397874832 0.9354838709677419\n",
      "[591] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "591 0 0.0051681725308299065 0.9354838709677419\n",
      "[592] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "592 0 0.005165154114365578 0.9354838709677419\n",
      "[593] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "593 0 0.005162143614143133 0.9354838709677419\n",
      "[594] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "594 0 0.005159140098839998 0.9354838709677419\n",
      "[595] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "595 0 0.005156142637133598 0.9354838709677419\n",
      "[596] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "596 0 0.005153153091669083 0.9354838709677419\n",
      "[597] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "597 0 0.005150170996785164 0.9354838709677419\n",
      "[598] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "598 0 0.005147193558514118 0.9354838709677419\n",
      "[599] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "599 0 0.005144224967807531 0.9354838709677419\n",
      "[600] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "600 0 0.005141261033713818 0.9354838709677419\n",
      "[601] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "601 0 0.005138303618878126 0.9354838709677419\n",
      "[602] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "602 0 0.005135352723300457 0.9354838709677419\n",
      "[603] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "603 0 0.0051324074156582355 0.9354838709677419\n",
      "[604] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "604 0 0.005129469092935324 0.9354838709677419\n",
      "[605] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "605 0 0.00512653635814786 0.9354838709677419\n",
      "[606] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "606 0 0.005123608745634556 0.9354838709677419\n",
      "[607] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "607 0 0.0051206867210567 0.9354838709677419\n",
      "[608] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "608 0 0.005117771215736866 0.9354838709677419\n",
      "[609] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "609 0 0.005114859901368618 0.9354838709677419\n",
      "[610] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "610 0 0.005111954640597105 0.9354838709677419\n",
      "[611] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "611 0 0.005109054502099752 0.9354838709677419\n",
      "[612] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "612 0 0.00510615948587656 0.9354838709677419\n",
      "[613] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "613 0 0.005103269126266241 0.9354838709677419\n",
      "[614] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "614 0 0.00510038435459137 0.9354838709677419\n",
      "[615] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "615 0 0.005097504239529371 0.9354838709677419\n",
      "[616] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "616 0 0.005094628781080246 0.9354838709677419\n",
      "[617] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "617 0 0.005091757047921419 0.9354838709677419\n",
      "[618] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "618 0 0.005088891368359327 0.9354838709677419\n",
      "[619] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "619 0 0.005086028482764959 0.9354838709677419\n",
      "[620] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "620 0 0.005083170719444752 0.9354838709677419\n",
      "[621] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "621 0 0.00508031714707613 0.9354838709677419\n",
      "[622] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "622 0 0.005077467765659094 0.9354838709677419\n",
      "[623] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "623 0 0.005074622109532356 0.9354838709677419\n",
      "[624] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "624 0 0.0050717806443572044 0.9354838709677419\n",
      "[625] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "625 0 0.005068942904472351 0.9354838709677419\n",
      "[626] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "626 0 0.0050661093555390835 0.9354838709677419\n",
      "[627] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "627 0 0.00506327860057354 0.9354838709677419\n",
      "[628] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "628 0 0.0050604515708982944 0.9354838709677419\n",
      "[629] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "629 0 0.005057628266513348 0.9354838709677419\n",
      "[630] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "630 0 0.005054809618741274 0.9354838709677419\n",
      "[631] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "631 0 0.005051992367953062 0.9354838709677419\n",
      "[632] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "632 0 0.005049179308116436 0.9354838709677419\n",
      "[633] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "633 0 0.005046369042247534 0.9354838709677419\n",
      "[634] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "634 0 0.005043562036007643 0.9354838709677419\n",
      "[635] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "635 0 0.005040758289396763 0.9354838709677419\n",
      "[636] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "636 0 0.0050379568710923195 0.9354838709677419\n",
      "[637] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "637 0 0.0050351582467556 0.9354838709677419\n",
      "[638] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "638 0 0.005032361950725317 0.9354838709677419\n",
      "[639] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "639 0 0.0050295693799853325 0.9354838709677419\n",
      "[640] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "640 0 0.005026778671890497 0.9354838709677419\n",
      "[641] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "641 0 0.0050239902921020985 0.9354838709677419\n",
      "[642] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "642 0 0.005021204240620136 0.9354838709677419\n",
      "[643] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "643 0 0.005018421448767185 0.9354838709677419\n",
      "[644] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "644 0 0.005015639588236809 0.9354838709677419\n",
      "[645] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "645 0 0.005012860521674156 0.9354838709677419\n",
      "[646] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "646 0 0.005010083317756653 0.9354838709677419\n",
      "[647] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "647 0 0.005007307976484299 0.9354838709677419\n",
      "[648] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "648 0 0.005004535429179668 0.9354838709677419\n",
      "[649] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "649 0 0.005001763813197613 0.9354838709677419\n",
      "[650] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "650 0 0.004998994059860706 0.9354838709677419\n",
      "[651] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "651 0 0.004996225703507662 0.9354838709677419\n",
      "[652] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "652 0 0.0049934592097997665 0.9354838709677419\n",
      "[653] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "653 0 0.0049906945787370205 0.9354838709677419\n",
      "[654] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "654 0 0.004987931344658136 0.9354838709677419\n",
      "[655] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "655 0 0.004985169507563114 0.9354838709677419\n",
      "[656] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "656 0 0.004982408601790667 0.9354838709677419\n",
      "[657] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "657 0 0.004979649093002081 0.9354838709677419\n",
      "[658] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "658 0 0.0049768914468586445 0.9354838709677419\n",
      "[659] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "659 0 0.004974133800715208 0.9354838709677419\n",
      "[660] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "660 0 0.0049713775515556335 0.9354838709677419\n",
      "[661] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "661 0 0.004968622233718634 0.9354838709677419\n",
      "[662] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "662 0 0.004965867847204208 0.9354838709677419\n",
      "[663] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "663 0 0.00496311392635107 0.9354838709677419\n",
      "[664] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "664 0 0.004960361402481794 0.9354838709677419\n",
      "[665] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "665 0 0.004957609344273806 0.9354838709677419\n",
      "[666] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "666 0 0.004954857286065817 0.9354838709677419\n",
      "[667] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "667 0 0.004952106159180403 0.9354838709677419\n",
      "[668] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "668 0 0.004949355032294989 0.9354838709677419\n",
      "[669] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "669 0 0.004946605768054724 0.9354838709677419\n",
      "[670] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "670 0 0.004943855572491884 0.9354838709677419\n",
      "[671] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "671 0 0.004941105376929045 0.9354838709677419\n",
      "[672] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "672 0 0.0049383570440113544 0.9354838709677419\n",
      "[673] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "673 0 0.004935607314109802 0.9354838709677419\n",
      "[674] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "674 0 0.00493285758420825 0.9354838709677419\n",
      "[675] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "675 0 0.0049301087856292725 0.9354838709677419\n",
      "[676] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "676 0 0.004927359987050295 0.9354838709677419\n",
      "[677] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "677 0 0.00492461072281003 0.9354838709677419\n",
      "[678] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "678 0 0.004921861458569765 0.9354838709677419\n",
      "[679] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "679 0 0.004919111263006926 0.9354838709677419\n",
      "[680] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "680 0 0.004916361067444086 0.9354838709677419\n",
      "[681] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "681 0 0.004913610406219959 0.9354838709677419\n",
      "[682] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "682 0 0.0049108597449958324 0.9354838709677419\n",
      "[683] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "683 0 0.004908108152449131 0.9354838709677419\n",
      "[684] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "684 0 0.00490535655990243 0.9354838709677419\n",
      "[685] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "685 0 0.004902604967355728 0.9354838709677419\n",
      "[686] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "686 0 0.0048998515121638775 0.9354838709677419\n",
      "[687] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "687 0 0.0048970975913107395 0.9354838709677419\n",
      "[688] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "688 0 0.004894344136118889 0.9354838709677419\n",
      "[689] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "689 0 0.004891588352620602 0.9354838709677419\n",
      "[690] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "690 0 0.004888832103461027 0.9354838709677419\n",
      "[691] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "691 0 0.004886075388640165 0.9354838709677419\n",
      "[692] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "692 0 0.004883316345512867 0.9354838709677419\n",
      "[693] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "693 0 0.004880557768046856 0.9354838709677419\n",
      "[694] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "694 0 0.004877797327935696 0.9354838709677419\n",
      "[695] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "695 0 0.004875035956501961 0.9354838709677419\n",
      "[696] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "696 0 0.004872273653745651 0.9354838709677419\n",
      "[697] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "697 0 0.0048695094883441925 0.9354838709677419\n",
      "[698] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "698 0 0.0048667434602975845 0.9354838709677419\n",
      "[699] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "699 0 0.004863977897912264 0.9354838709677419\n",
      "[700] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "700 0 0.004861211869865656 0.9354838709677419\n",
      "[701] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "701 0 0.0048584467731416225 0.9354838709677419\n",
      "[702] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "702 0 0.004855679348111153 0.9354838709677419\n",
      "[703] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "703 0 0.00485291238874197 0.9354838709677419\n",
      "[704] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "704 0 0.004850143101066351 0.9354838709677419\n",
      "[705] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "705 0 0.00484737241640687 0.9354838709677419\n",
      "[706] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "706 0 0.004844600334763527 0.9354838709677419\n",
      "[707] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "707 0 0.004841826390475035 0.9354838709677419\n",
      "[708] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "708 0 0.004839051980525255 0.9354838709677419\n",
      "[709] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "709 0 0.004836274776607752 0.9354838709677419\n",
      "[710] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "710 0 0.004833496641367674 0.9354838709677419\n",
      "[711] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "711 0 0.0048307194374501705 0.9354838709677419\n",
      "[712] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "712 0 0.0048279413022100925 0.9354838709677419\n",
      "[713] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "713 0 0.004825161304324865 0.9354838709677419\n",
      "[714] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "714 0 0.0048223803751170635 0.9354838709677419\n",
      "[715] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "715 0 0.004819597117602825 0.9354838709677419\n",
      "[716] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "716 0 0.004816812463104725 0.9354838709677419\n",
      "[717] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "717 0 0.004814025945961475 0.9354838709677419\n",
      "[718] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "718 0 0.004811237566173077 0.9354838709677419\n",
      "[719] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "719 0 0.004808446858078241 0.9354838709677419\n",
      "[720] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "720 0 0.004805654287338257 0.9354838709677419\n",
      "[721] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "721 0 0.004802859388291836 0.9354838709677419\n",
      "[722] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "722 0 0.004800063092261553 0.9354838709677419\n",
      "[723] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "723 0 0.004797264467924833 0.9354838709677419\n",
      "[724] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "724 0 0.004794462583959103 0.9354838709677419\n",
      "[725] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "725 0 0.004791659768670797 0.9354838709677419\n",
      "[726] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "726 0 0.004788854159414768 0.9354838709677419\n",
      "[727] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "727 0 0.0047860462218523026 0.9354838709677419\n",
      "[728] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "728 0 0.004783235490322113 0.9354838709677419\n",
      "[729] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "729 0 0.004780422896146774 0.9354838709677419\n",
      "[730] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "730 0 0.004777607042342424 0.9354838709677419\n",
      "[731] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "731 0 0.004774789325892925 0.9354838709677419\n",
      "[732] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "732 0 0.004771968349814415 0.9354838709677419\n",
      "[733] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "733 0 0.004769144579768181 0.9354838709677419\n",
      "[734] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "734 0 0.004766319878399372 0.9354838709677419\n",
      "[735] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "735 0 0.004763490986078978 0.9354838709677419\n",
      "[736] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "736 0 0.004760658834129572 0.9354838709677419\n",
      "[737] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "737 0 0.004757824819535017 0.9354838709677419\n",
      "[738] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "738 0 0.004754988010972738 0.9354838709677419\n",
      "[739] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "739 0 0.004752147942781448 0.9354838709677419\n",
      "[740] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "740 0 0.004749305080622435 0.9354838709677419\n",
      "[741] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "741 0 0.004746459424495697 0.9354838709677419\n",
      "[742] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "742 0 0.004743610974401236 0.9354838709677419\n",
      "[743] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "743 0 0.004740759264677763 0.9354838709677419\n",
      "[744] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "744 0 0.004737904295325279 0.9354838709677419\n",
      "[745] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "745 0 0.004735046997666359 0.9354838709677419\n",
      "[746] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "746 0 0.004732185509055853 0.9354838709677419\n",
      "[747] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "747 0 0.00472932169213891 0.9354838709677419\n",
      "[748] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "748 0 0.0047264546155929565 0.9354838709677419\n",
      "[749] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "749 0 0.004723583813756704 0.9354838709677419\n",
      "[750] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "750 0 0.004720709752291441 0.9354838709677419\n",
      "[751] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "751 0 0.004717833362519741 0.9354838709677419\n",
      "[752] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "752 0 0.004714952316135168 0.9354838709677419\n",
      "[753] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "753 0 0.004712069407105446 0.9354838709677419\n",
      "[754] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "754 0 0.004709181375801563 0.9354838709677419\n",
      "[755] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "755 0 0.004706291481852531 0.9354838709677419\n",
      "[756] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "756 0 0.004703397862613201 0.9354838709677419\n",
      "[757] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "757 0 0.004700500518083572 0.9354838709677419\n",
      "[758] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "758 0 0.0046975999139249325 0.9354838709677419\n",
      "[759] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "759 0 0.004694695118814707 0.9354838709677419\n",
      "[760] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "760 0 0.004691787529736757 0.9354838709677419\n",
      "[761] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "761 0 0.004688876215368509 0.9354838709677419\n",
      "[762] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "762 0 0.004685961175709963 0.9354838709677419\n",
      "[763] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "763 0 0.004683042876422405 0.9354838709677419\n",
      "[764] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "764 0 0.0046801199205219746 0.9354838709677419\n",
      "[765] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "765 0 0.00467719417065382 0.9354838709677419\n",
      "[766] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "766 0 0.004674264695495367 0.9354838709677419\n",
      "[767] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "767 0 0.004671331495046616 0.9354838709677419\n",
      "[768] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "768 0 0.004668394103646278 0.9354838709677419\n",
      "[769] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "769 0 0.004665452986955643 0.9354838709677419\n",
      "[770] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "770 0 0.004662508610635996 0.9354838709677419\n",
      "[771] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "771 0 0.004659560509026051 0.9354838709677419\n",
      "[772] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "772 0 0.004656607750803232 0.9354838709677419\n",
      "[773] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "773 0 0.004653651267290115 0.9354838709677419\n",
      "[774] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "774 0 0.004650691524147987 0.9354838709677419\n",
      "[775] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "775 0 0.004647728055715561 0.9354838709677419\n",
      "[776] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "776 0 0.004644759465008974 0.9354838709677419\n",
      "[777] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "777 0 0.004641787614673376 0.9354838709677419\n",
      "[778] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "778 0 0.00463881203904748 0.9354838709677419\n",
      "[779] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "779 0 0.00463583180680871 0.9354838709677419\n",
      "[780] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "780 0 0.004632847849279642 0.9354838709677419\n",
      "[781] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "781 0 0.004629860166460276 0.9354838709677419\n",
      "[782] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "782 0 0.004626867827028036 0.9354838709677419\n",
      "[783] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "783 0 0.004623872693628073 0.9354838709677419\n",
      "[784] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "784 0 0.004620872903615236 0.9354838709677419\n",
      "[785] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "785 0 0.004617868456989527 0.9354838709677419\n",
      "[786] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "786 0 0.004614860285073519 0.9354838709677419\n",
      "[787] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "787 0 0.00461184699088335 0.9354838709677419\n",
      "[788] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "788 0 0.004608830902725458 0.9354838709677419\n",
      "[789] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "789 0 0.004605810157954693 0.9354838709677419\n",
      "[790] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "790 0 0.004602785222232342 0.9354838709677419\n",
      "[791] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "791 0 0.004599755629897118 0.9354838709677419\n",
      "[792] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "792 0 0.004596722312271595 0.9354838709677419\n",
      "[793] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "793 0 0.004593684803694487 0.9354838709677419\n",
      "[794] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "794 0 0.00459064356982708 0.9354838709677419\n",
      "[795] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "795 0 0.004587596748024225 0.9354838709677419\n",
      "[796] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "796 0 0.004584545735269785 0.9354838709677419\n",
      "[797] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "797 0 0.004581491928547621 0.9354838709677419\n",
      "[798] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "798 0 0.004578432533890009 0.9354838709677419\n",
      "[799] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "799 0 0.004575368948280811 0.9354838709677419\n",
      "[800] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "800 0 0.004572300706058741 0.9354838709677419\n",
      "[801] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "801 0 0.004569229204207659 0.9354838709677419\n",
      "[802] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "802 0 0.004566153045743704 0.9354838709677419\n",
      "[803] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "803 0 0.004563072230666876 0.9354838709677419\n",
      "[804] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "804 0 0.004559986758977175 0.9354838709677419\n",
      "[805] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "805 0 0.004556897561997175 0.9354838709677419\n",
      "[806] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "806 0 0.004553803242743015 0.9354838709677419\n",
      "[807] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "807 0 0.00455070473253727 0.9354838709677419\n",
      "[808] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "808 0 0.004547602031379938 0.9354838709677419\n",
      "[809] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "809 0 0.004544495139271021 0.9354838709677419\n",
      "[810] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "810 0 0.004541383590549231 0.9354838709677419\n",
      "[811] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "811 0 0.00453826691955328 0.9354838709677419\n",
      "[812] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "812 0 0.004535146523267031 0.9354838709677419\n",
      "[813] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "813 0 0.0045320214703679085 0.9354838709677419\n",
      "[814] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "814 0 0.004528891760855913 0.9354838709677419\n",
      "[815] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "815 0 0.004525757860392332 0.9354838709677419\n",
      "[816] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "816 0 0.004522619768977165 0.9354838709677419\n",
      "[817] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "817 0 0.004519476089626551 0.9354838709677419\n",
      "[818] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "818 0 0.004516329150646925 0.9354838709677419\n",
      "[819] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "819 0 0.004513177089393139 0.9354838709677419\n",
      "[820] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "820 0 0.00451002037152648 0.9354838709677419\n",
      "[821] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "821 0 0.0045068589970469475 0.9354838709677419\n",
      "[822] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "822 0 0.004503694362938404 0.9354838709677419\n",
      "[823] loss/acc for train: (0.005, 0.935), valid: (0.005, 0.935), test: (0.005, 0.935)\n",
      "823 0 0.004500524140894413 0.9354838709677419\n",
      "[824] loss/acc for train: (0.005, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "824 0 0.004497349262237549 0.9354838709677419\n",
      "[825] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "825 0 0.004494170192629099 0.9354838709677419\n",
      "[826] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "826 0 0.004490986932069063 0.9354838709677419\n",
      "[827] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "827 0 0.004487799014896154 0.9354838709677419\n",
      "[828] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "828 0 0.0044846064411103725 0.9354838709677419\n",
      "[829] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "829 0 0.00448140874505043 0.9354838709677419\n",
      "[830] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "830 0 0.00447820732370019 0.9354838709677419\n",
      "[831] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "831 0 0.0044750007800757885 0.9354838709677419\n",
      "[832] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "832 0 0.004471790511161089 0.9354838709677419\n",
      "[833] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "833 0 0.004468575119972229 0.9354838709677419\n",
      "[834] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "834 0 0.004465355072170496 0.9354838709677419\n",
      "[835] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "835 0 0.004462130833417177 0.9354838709677419\n",
      "[836] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "836 0 0.004458902403712273 0.9354838709677419\n",
      "[837] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "837 0 0.004455668851733208 0.9354838709677419\n",
      "[838] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "838 0 0.004452431108802557 0.9354838709677419\n",
      "[839] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "839 0 0.004449188709259033 0.9354838709677419\n",
      "[840] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "840 0 0.004445941653102636 0.9354838709677419\n",
      "[841] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "841 0 0.004442691337317228 0.9354838709677419\n",
      "[842] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "842 0 0.004439443349838257 0.9354838709677419\n",
      "[843] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "843 0 0.004436191637068987 0.9354838709677419\n",
      "[844] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "844 0 0.004432935267686844 0.9354838709677419\n",
      "[845] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "845 0 0.004429676104336977 0.9354838709677419\n",
      "[846] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "846 0 0.004426419734954834 0.9354838709677419\n",
      "[847] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "847 0 0.004423159174621105 0.9354838709677419\n",
      "[848] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "848 0 0.004419895354658365 0.9354838709677419\n",
      "[849] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "849 0 0.0044166273437440395 0.9354838709677419\n",
      "[850] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "850 0 0.004413356073200703 0.9354838709677419\n",
      "[851] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "851 0 0.00441008061170578 0.9354838709677419\n",
      "[852] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "852 0 0.004406800959259272 0.9354838709677419\n",
      "[853] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "853 0 0.004403518512845039 0.9354838709677419\n",
      "[854] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "854 0 0.004400231875479221 0.9354838709677419\n",
      "[855] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "855 0 0.004396940115839243 0.9354838709677419\n",
      "[856] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "856 0 0.004393646027892828 0.9354838709677419\n",
      "[857] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "857 0 0.004390346817672253 0.9354838709677419\n",
      "[858] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "858 0 0.004387044347822666 0.9354838709677419\n",
      "[859] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "859 0 0.004383741412311792 0.9354838709677419\n",
      "[860] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "860 0 0.004380436148494482 0.9354838709677419\n",
      "[861] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "861 0 0.0043771276250481606 0.9354838709677419\n",
      "[862] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "862 0 0.004373814910650253 0.9354838709677419\n",
      "[863] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "863 0 0.004370499402284622 0.9354838709677419\n",
      "[864] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "864 0 0.004367178305983543 0.9354838709677419\n",
      "[865] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "865 0 0.004363855347037315 0.9354838709677419\n",
      "[866] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "866 0 0.004360527265816927 0.9354838709677419\n",
      "[867] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "867 0 0.004357196856290102 0.9354838709677419\n",
      "[868] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "868 0 0.004353860858827829 0.9354838709677419\n",
      "[869] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "869 0 0.004350522067397833 0.9354838709677419\n",
      "[870] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "870 0 0.004347179550677538 0.9354838709677419\n",
      "[871] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "871 0 0.004343832843005657 0.9354838709677419\n",
      "[872] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "872 0 0.004340484272688627 0.9354838709677419\n",
      "[873] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "873 0 0.004337134771049023 0.9354838709677419\n",
      "[874] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "874 0 0.004333780612796545 0.9354838709677419\n",
      "[875] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "875 0 0.0043304236605763435 0.9354838709677419\n",
      "[876] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "876 0 0.004327062983065844 0.9354838709677419\n",
      "[877] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "877 0 0.004323698114603758 0.9354838709677419\n",
      "[878] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "878 0 0.004320329520851374 0.9354838709677419\n",
      "[879] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "879 0 0.004316957667469978 0.9354838709677419\n",
      "[880] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "880 0 0.0043135820887982845 0.9354838709677419\n",
      "[881] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "881 0 0.004310202784836292 0.9354838709677419\n",
      "[882] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "882 0 0.004306819289922714 0.9354838709677419\n",
      "[883] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "883 0 0.0043034334667027 0.9354838709677419\n",
      "[884] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "884 0 0.004300042521208525 0.9354838709677419\n",
      "[885] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "885 0 0.004296649247407913 0.9354838709677419\n",
      "[886] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "886 0 0.004293251316994429 0.9354838709677419\n",
      "[887] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "887 0 0.004289849661290646 0.9354838709677419\n",
      "[888] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "888 0 0.004286445211619139 0.9354838709677419\n",
      "[889] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "889 0 0.004283037036657333 0.9354838709677419\n",
      "[890] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "890 0 0.00427962513640523 0.9354838709677419\n",
      "[891] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "891 0 0.004276209976524115 0.9354838709677419\n",
      "[892] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "892 0 0.0042727915570139885 0.9354838709677419\n",
      "[893] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "893 0 0.004269368015229702 0.9354838709677419\n",
      "[894] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "894 0 0.004265941679477692 0.9354838709677419\n",
      "[895] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "895 0 0.00426251208409667 0.9354838709677419\n",
      "[896] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "896 0 0.0042590792290866375 0.9354838709677419\n",
      "[897] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "897 0 0.004255642648786306 0.9354838709677419\n",
      "[898] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "898 0 0.004252202343195677 0.9354838709677419\n",
      "[899] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "899 0 0.004248759709298611 0.9354838709677419\n",
      "[900] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "900 0 0.0042453124187886715 0.9354838709677419\n",
      "[901] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "901 0 0.004241862799972296 0.9354838709677419\n",
      "[902] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "902 0 0.004238408990204334 0.9354838709677419\n",
      "[903] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "903 0 0.004234951920807362 0.9354838709677419\n",
      "[904] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "904 0 0.004231490660458803 0.9354838709677419\n",
      "[905] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "905 0 0.0042280275374650955 0.9354838709677419\n",
      "[906] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "906 0 0.004224560689181089 0.9354838709677419\n",
      "[907] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "907 0 0.004221090581268072 0.9354838709677419\n",
      "[908] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "908 0 0.004217616748064756 0.9354838709677419\n",
      "[909] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "909 0 0.004214140586555004 0.9354838709677419\n",
      "[910] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "910 0 0.004210660699754953 0.9354838709677419\n",
      "[911] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "911 0 0.0042071775533258915 0.9354838709677419\n",
      "[912] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "912 0 0.004203691612929106 0.9354838709677419\n",
      "[913] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "913 0 0.0042002019472420216 0.9354838709677419\n",
      "[914] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "914 0 0.004196710418909788 0.9354838709677419\n",
      "[915] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "915 0 0.004193214699625969 0.9354838709677419\n",
      "[916] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "916 0 0.004189716186374426 0.9354838709677419\n",
      "[917] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "917 0 0.004186214879155159 0.9354838709677419\n",
      "[918] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "918 0 0.004182709846645594 0.9354838709677419\n",
      "[919] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "919 0 0.004179202485829592 0.9354838709677419\n",
      "[920] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "920 0 0.004175692796707153 0.9354838709677419\n",
      "[921] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "921 0 0.004172179382294416 0.9354838709677419\n",
      "[922] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "922 0 0.004168662708252668 0.9354838709677419\n",
      "[923] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "923 0 0.004165143705904484 0.9354838709677419\n",
      "[924] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "924 0 0.004161622375249863 0.9354838709677419\n",
      "[925] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "925 0 0.00415809778496623 0.9354838709677419\n",
      "[926] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "926 0 0.0041545694693923 0.9354838709677419\n",
      "[927] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "927 0 0.004151039756834507 0.9354838709677419\n",
      "[928] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "928 0 0.004147506784647703 0.9354838709677419\n",
      "[929] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "929 0 0.0041439710184931755 0.9354838709677419\n",
      "[930] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "930 0 0.004140433855354786 0.9354838709677419\n",
      "[931] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "931 0 0.004136892966926098 0.9354838709677419\n",
      "[932] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "932 0 0.004133349284529686 0.9354838709677419\n",
      "[933] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "933 0 0.0041298032738268375 0.9354838709677419\n",
      "[934] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "934 0 0.004126254469156265 0.9354838709677419\n",
      "[935] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "935 0 0.0041227033361792564 0.9354838709677419\n",
      "[936] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "936 0 0.004119149874895811 0.9354838709677419\n",
      "[937] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "937 0 0.004115594085305929 0.9354838709677419\n",
      "[938] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "938 0 0.0041120355017483234 0.9354838709677419\n",
      "[939] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "939 0 0.0041084750555455685 0.9354838709677419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[940] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "940 0 0.00410491181537509 0.9354838709677419\n",
      "[941] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "941 0 0.004101346246898174 0.9354838709677419\n",
      "[942] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "942 0 0.00409777881577611 0.9354838709677419\n",
      "[943] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "943 0 0.004094208590686321 0.9354838709677419\n",
      "[944] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "944 0 0.004090636502951384 0.9354838709677419\n",
      "[945] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "945 0 0.004087062552571297 0.9354838709677419\n",
      "[946] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "946 0 0.004083485342562199 0.9354838709677419\n",
      "[947] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "947 0 0.004079907201230526 0.9354838709677419\n",
      "[948] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "948 0 0.004076326731592417 0.9354838709677419\n",
      "[949] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "949 0 0.004072743467986584 0.9354838709677419\n",
      "[950] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "950 0 0.004069158807396889 0.9354838709677419\n",
      "[951] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "951 0 0.0040655722841620445 0.9354838709677419\n",
      "[952] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "952 0 0.004061983432620764 0.9354838709677419\n",
      "[953] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "953 0 0.0040583922527730465 0.9354838709677419\n",
      "[954] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "954 0 0.004054801072925329 0.9354838709677419\n",
      "[955] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "955 0 0.0040512061677873135 0.9354838709677419\n",
      "[956] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "956 0 0.004047609865665436 0.9354838709677419\n",
      "[957] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "957 0 0.004044011700898409 0.9354838709677419\n",
      "[958] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "958 0 0.004040411673486233 0.9354838709677419\n",
      "[959] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "959 0 0.004036810249090195 0.9354838709677419\n",
      "[960] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "960 0 0.004033207427710295 0.9354838709677419\n",
      "[961] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "961 0 0.004029603209346533 0.9354838709677419\n",
      "[962] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "962 0 0.004025996662676334 0.9354838709677419\n",
      "[963] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "963 0 0.004022388719022274 0.9354838709677419\n",
      "[964] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "964 0 0.004018779844045639 0.9354838709677419\n",
      "[965] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "965 0 0.0040151686407625675 0.9354838709677419\n",
      "[966] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "966 0 0.004011556506156921 0.9354838709677419\n",
      "[967] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "967 0 0.004007942508906126 0.9354838709677419\n",
      "[968] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "968 0 0.004004327580332756 0.9354838709677419\n",
      "[969] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "969 0 0.004000710789114237 0.9354838709677419\n",
      "[970] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "970 0 0.00399709353223443 0.9354838709677419\n",
      "[971] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "971 0 0.0039934744127094746 0.9354838709677419\n",
      "[972] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "972 0 0.003989854361861944 0.9354838709677419\n",
      "[973] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "973 0 0.003986232448369265 0.9354838709677419\n",
      "[974] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "974 0 0.00398260960355401 0.9354838709677419\n",
      "[975] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "975 0 0.003978986293077469 0.9354838709677419\n",
      "[976] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "976 0 0.003975361585617065 0.9354838709677419\n",
      "[977] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "977 0 0.003971735015511513 0.9354838709677419\n",
      "[978] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "978 0 0.00396810844540596 0.9354838709677419\n",
      "[979] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "979 0 0.003964480943977833 0.9354838709677419\n",
      "[980] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "980 0 0.003960851579904556 0.9354838709677419\n",
      "[981] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "981 0 0.00395722221583128 0.9354838709677419\n",
      "[982] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "982 0 0.003953591454774141 0.9354838709677419\n",
      "[983] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "983 0 0.0039499602280557156 0.9354838709677419\n",
      "[984] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "984 0 0.0039463285356760025 0.9354838709677419\n",
      "[985] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "985 0 0.00394269498065114 0.9354838709677419\n",
      "[986] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "986 0 0.003939061891287565 0.9354838709677419\n",
      "[987] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "987 0 0.003935427404940128 0.9354838709677419\n",
      "[988] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "988 0 0.003931792452931404 0.9354838709677419\n",
      "[989] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "989 0 0.003928157035261393 0.9354838709677419\n",
      "[990] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "990 0 0.0039245206862688065 0.9354838709677419\n",
      "[991] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "991 0 0.00392088433727622 0.9354838709677419\n",
      "[992] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "992 0 0.00391724705696106 0.9354838709677419\n",
      "[993] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "993 0 0.003913609776645899 0.9354838709677419\n",
      "[994] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "994 0 0.0039099715650081635 0.9354838709677419\n",
      "[995] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "995 0 0.003906333819031715 0.9354838709677419\n",
      "[996] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "996 0 0.0039026946760714054 0.9354838709677419\n",
      "[997] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "997 0 0.0038990566972643137 0.9354838709677419\n",
      "[998] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "998 0 0.0038954168558120728 0.9354838709677419\n",
      "[999] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "999 0 0.0038917777128517628 0.9354838709677419\n",
      "[1000] loss/acc for train: (0.004, 0.935), valid: (0.004, 0.935), test: (0.004, 0.935)\n",
      "Done 1.30198073387146\n",
      "test accuracy 1.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = df_combined[['MAG5yr','MAG10yr','Count_L','Count_S']]\n",
    "labels = df_combined[['MAG']]\n",
    "labels = labels['MAG'].astype(int)\n",
    "\n",
    "batch_size = 35\n",
    "test_loader, val_loader, train_loader, train_dataset, val_dataset, test_dataset, num_classes = split_data(data, labels, batch_size)\n",
    "\n",
    "#print_dataset2(train_dataset, \"Training Dataset\")\n",
    "#print_dataset2(val_dataset  , \"Validation Dataset\")\n",
    "#print_dataset2(test_dataset , \"Testing Dataset\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 1\n",
    "input_dim = 256\n",
    "\n",
    "# Instantiate model and define loss function and optimizer\n",
    "print(num_classes)\n",
    "model = NeuralNetwork(input_variables=4,num_classes=2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "epochs=1000\n",
    "train_metrics, val_metrics, test_metrics = train_test_model_epochs(model,num_epochs=epochs)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_results( pd.DataFrame(train_metrics)\n",
    "            , pd.DataFrame(val_metrics)\n",
    "            , pd.DataFrame(test_metrics)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b4620fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 [0 1]\n",
      "2\n",
      "Start  1683924899.9601915\n",
      "0 0 0.015445897355675697 0.22580645161290322\n",
      "[1] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "1 0 0.015414243564009666 0.22580645161290322\n",
      "[2] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "2 0 0.015382763929665089 0.22580645161290322\n",
      "[3] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "3 0 0.015351450070738792 0.22580645161290322\n",
      "[4] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "4 0 0.015320312231779099 0.22580645161290322\n",
      "[5] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "5 0 0.015289343893527985 0.22580645161290322\n",
      "[6] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "6 0 0.015258555300533772 0.22580645161290322\n",
      "[7] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "7 0 0.01522794645279646 0.22580645161290322\n",
      "[8] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "8 0 0.015197520144283772 0.22580645161290322\n",
      "[9] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "9 0 0.015167278237640858 0.22580645161290322\n",
      "[10] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "10 0 0.015137217938899994 0.22580645161290322\n",
      "[11] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "11 0 0.015107349492609501 0.22580645161290322\n",
      "[12] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "12 0 0.015077667310833931 0.22580645161290322\n",
      "[13] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "13 0 0.015048176981508732 0.22580645161290322\n",
      "[14] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "14 0 0.015018874779343605 0.22580645161290322\n",
      "[15] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "15 0 0.014989769086241722 0.22580645161290322\n",
      "[16] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "16 0 0.014960856176912785 0.22580645161290322\n",
      "[17] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "17 0 0.014932137914001942 0.22580645161290322\n",
      "[18] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "18 0 0.014903616160154343 0.22580645161290322\n",
      "[19] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "19 0 0.014875289052724838 0.22580645161290322\n",
      "[20] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "20 0 0.014847158454358578 0.22580645161290322\n",
      "[21] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "21 0 0.014819223433732986 0.22580645161290322\n",
      "[22] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "22 0 0.014791484922170639 0.22580645161290322\n",
      "[23] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "23 0 0.014763948507606983 0.22580645161290322\n",
      "[24] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "24 0 0.014736604876816273 0.22580645161290322\n",
      "[25] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "25 0 0.01470946054905653 0.22580645161290322\n",
      "[26] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "26 0 0.014682512730360031 0.22580645161290322\n",
      "[27] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "27 0 0.014655759558081627 0.22580645161290322\n",
      "[28] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "28 0 0.014629199169576168 0.22580645161290322\n",
      "[29] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "29 0 0.014602836221456528 0.22580645161290322\n",
      "[30] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "30 0 0.014576668851077557 0.22580645161290322\n",
      "[31] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "31 0 0.014550694264471531 0.22580645161290322\n",
      "[32] loss/acc for train: (0.015, 0.226), valid: (0.015, 0.226), test: (0.015, 0.226)\n",
      "32 0 0.014524910598993301 0.22580645161290322\n",
      "[33] loss/acc for train: (0.015, 0.226), valid: (0.014, 0.226), test: (0.014, 0.226)\n",
      "33 0 0.014499320648610592 0.22580645161290322\n",
      "[34] loss/acc for train: (0.014, 0.226), valid: (0.014, 0.226), test: (0.014, 0.226)\n",
      "34 0 0.01447391975671053 0.22580645161290322\n",
      "[35] loss/acc for train: (0.014, 0.226), valid: (0.014, 0.226), test: (0.014, 0.226)\n",
      "35 0 0.014448709785938263 0.22580645161290322\n",
      "[36] loss/acc for train: (0.014, 0.226), valid: (0.014, 0.161), test: (0.014, 0.161)\n",
      "36 0 0.014423685148358345 0.16129032258064516\n",
      "[37] loss/acc for train: (0.014, 0.161), valid: (0.014, 0.161), test: (0.014, 0.161)\n",
      "37 0 0.014398851431906223 0.16129032258064516\n",
      "[38] loss/acc for train: (0.014, 0.161), valid: (0.014, 0.258), test: (0.014, 0.258)\n",
      "38 0 0.0143742011860013 0.25806451612903225\n",
      "[39] loss/acc for train: (0.014, 0.258), valid: (0.014, 0.258), test: (0.014, 0.258)\n",
      "39 0 0.014349738135933876 0.25806451612903225\n",
      "[40] loss/acc for train: (0.014, 0.258), valid: (0.014, 0.258), test: (0.014, 0.258)\n",
      "40 0 0.014325456693768501 0.25806451612903225\n",
      "[41] loss/acc for train: (0.014, 0.258), valid: (0.014, 0.323), test: (0.014, 0.323)\n",
      "41 0 0.014301355928182602 0.3225806451612903\n",
      "[42] loss/acc for train: (0.014, 0.323), valid: (0.014, 0.258), test: (0.014, 0.258)\n",
      "42 0 0.014277437701821327 0.25806451612903225\n",
      "[43] loss/acc for train: (0.014, 0.258), valid: (0.014, 0.290), test: (0.014, 0.290)\n",
      "43 0 0.014253701083362103 0.2903225806451613\n",
      "[44] loss/acc for train: (0.014, 0.290), valid: (0.014, 0.355), test: (0.014, 0.355)\n",
      "44 0 0.014230141416192055 0.3548387096774194\n",
      "[45] loss/acc for train: (0.014, 0.355), valid: (0.014, 0.355), test: (0.014, 0.355)\n",
      "45 0 0.01420675590634346 0.3548387096774194\n",
      "[46] loss/acc for train: (0.014, 0.355), valid: (0.014, 0.290), test: (0.014, 0.290)\n",
      "46 0 0.014183548279106617 0.2903225806451613\n",
      "[47] loss/acc for train: (0.014, 0.290), valid: (0.014, 0.290), test: (0.014, 0.290)\n",
      "47 0 0.014160514809191227 0.2903225806451613\n",
      "[48] loss/acc for train: (0.014, 0.290), valid: (0.014, 0.290), test: (0.014, 0.290)\n",
      "48 0 0.014137654565274715 0.2903225806451613\n",
      "[49] loss/acc for train: (0.014, 0.290), valid: (0.014, 0.290), test: (0.014, 0.290)\n",
      "49 0 0.01411496289074421 0.2903225806451613\n",
      "[50] loss/acc for train: (0.014, 0.290), valid: (0.014, 0.323), test: (0.014, 0.323)\n",
      "50 0 0.014092444442212582 0.3225806451612903\n",
      "[51] loss/acc for train: (0.014, 0.323), valid: (0.014, 0.323), test: (0.014, 0.323)\n",
      "51 0 0.014070093631744385 0.3225806451612903\n",
      "[52] loss/acc for train: (0.014, 0.323), valid: (0.014, 0.323), test: (0.014, 0.323)\n",
      "52 0 0.014047911390662193 0.3225806451612903\n",
      "[53] loss/acc for train: (0.014, 0.323), valid: (0.014, 0.323), test: (0.014, 0.323)\n",
      "53 0 0.014025893062353134 0.3225806451612903\n",
      "[54] loss/acc for train: (0.014, 0.323), valid: (0.014, 0.355), test: (0.014, 0.355)\n",
      "54 0 0.01400404330343008 0.3548387096774194\n",
      "[55] loss/acc for train: (0.014, 0.355), valid: (0.014, 0.419), test: (0.014, 0.419)\n",
      "55 0 0.01398230716586113 0.41935483870967744\n",
      "[56] loss/acc for train: (0.014, 0.419), valid: (0.014, 0.452), test: (0.014, 0.452)\n",
      "56 0 0.013960383832454681 0.45161290322580644\n",
      "[57] loss/acc for train: (0.014, 0.452), valid: (0.014, 0.452), test: (0.014, 0.452)\n",
      "57 0 0.013938597403466702 0.45161290322580644\n",
      "[58] loss/acc for train: (0.014, 0.452), valid: (0.014, 0.516), test: (0.014, 0.516)\n",
      "58 0 0.013916943222284317 0.5161290322580645\n",
      "[59] loss/acc for train: (0.014, 0.516), valid: (0.014, 0.548), test: (0.014, 0.548)\n",
      "59 0 0.013895425945520401 0.5483870967741935\n",
      "[60] loss/acc for train: (0.014, 0.548), valid: (0.014, 0.548), test: (0.014, 0.548)\n",
      "60 0 0.01387404277920723 0.5483870967741935\n",
      "[61] loss/acc for train: (0.014, 0.548), valid: (0.014, 0.548), test: (0.014, 0.548)\n",
      "61 0 0.01385271642357111 0.5483870967741935\n",
      "[62] loss/acc for train: (0.014, 0.548), valid: (0.014, 0.548), test: (0.014, 0.548)\n",
      "62 0 0.01383120659738779 0.5483870967741935\n",
      "[63] loss/acc for train: (0.014, 0.548), valid: (0.014, 0.581), test: (0.014, 0.581)\n",
      "63 0 0.013809805735945702 0.5806451612903226\n",
      "[64] loss/acc for train: (0.014, 0.581), valid: (0.014, 0.581), test: (0.014, 0.581)\n",
      "64 0 0.013788520358502865 0.5806451612903226\n",
      "[65] loss/acc for train: (0.014, 0.581), valid: (0.014, 0.581), test: (0.014, 0.581)\n",
      "65 0 0.013767347671091557 0.5806451612903226\n",
      "[66] loss/acc for train: (0.014, 0.581), valid: (0.014, 0.581), test: (0.014, 0.581)\n",
      "66 0 0.013746295124292374 0.5806451612903226\n",
      "[67] loss/acc for train: (0.014, 0.581), valid: (0.014, 0.581), test: (0.014, 0.581)\n",
      "67 0 0.013725364580750465 0.5806451612903226\n",
      "[68] loss/acc for train: (0.014, 0.581), valid: (0.014, 0.581), test: (0.014, 0.581)\n",
      "68 0 0.013704556040465832 0.5806451612903226\n",
      "[69] loss/acc for train: (0.014, 0.581), valid: (0.014, 0.581), test: (0.014, 0.581)\n",
      "69 0 0.013683877885341644 0.5806451612903226\n",
      "[70] loss/acc for train: (0.014, 0.581), valid: (0.014, 0.581), test: (0.014, 0.581)\n",
      "70 0 0.013663322664797306 0.5806451612903226\n",
      "[71] loss/acc for train: (0.014, 0.581), valid: (0.014, 0.581), test: (0.014, 0.581)\n",
      "71 0 0.013642898760735989 0.5806451612903226\n",
      "[72] loss/acc for train: (0.014, 0.581), valid: (0.014, 0.581), test: (0.014, 0.581)\n",
      "72 0 0.013622606173157692 0.5806451612903226\n",
      "[73] loss/acc for train: (0.014, 0.581), valid: (0.014, 0.581), test: (0.014, 0.581)\n",
      "73 0 0.013602444902062416 0.5806451612903226\n",
      "[74] loss/acc for train: (0.014, 0.581), valid: (0.014, 0.581), test: (0.014, 0.581)\n",
      "74 0 0.013582413084805012 0.5806451612903226\n",
      "[75] loss/acc for train: (0.014, 0.581), valid: (0.014, 0.581), test: (0.014, 0.581)\n",
      "75 0 0.013562513515353203 0.5806451612903226\n",
      "[76] loss/acc for train: (0.014, 0.581), valid: (0.014, 0.613), test: (0.014, 0.613)\n",
      "76 0 0.013542748987674713 0.6129032258064516\n",
      "[77] loss/acc for train: (0.014, 0.613), valid: (0.014, 0.613), test: (0.014, 0.613)\n",
      "77 0 0.01352311484515667 0.6129032258064516\n",
      "[78] loss/acc for train: (0.014, 0.613), valid: (0.014, 0.677), test: (0.014, 0.677)\n",
      "78 0 0.01350361481308937 0.6774193548387096\n",
      "[79] loss/acc for train: (0.014, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "79 0 0.013484245166182518 0.6774193548387096\n",
      "[80] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "80 0 0.013465013355016708 0.6774193548387096\n",
      "[81] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "81 0 0.013445910066366196 0.6774193548387096\n",
      "[82] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "82 0 0.013426940888166428 0.6774193548387096\n",
      "[83] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "83 0 0.013408102095127106 0.6774193548387096\n",
      "[84] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.677), test: (0.013, 0.677)\n",
      "84 0 0.013389396481215954 0.6774193548387096\n",
      "[85] loss/acc for train: (0.013, 0.677), valid: (0.013, 0.710), test: (0.013, 0.710)\n",
      "85 0 0.013370823115110397 0.7096774193548387\n",
      "[86] loss/acc for train: (0.013, 0.710), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "86 0 0.013352380134165287 0.7741935483870968\n",
      "[87] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "87 0 0.01333406288176775 0.7741935483870968\n",
      "[88] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "88 0 0.013315881602466106 0.7741935483870968\n",
      "[89] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "89 0 0.013297823257744312 0.7741935483870968\n",
      "[90] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "90 0 0.013279898092150688 0.7741935483870968\n",
      "[91] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "91 0 0.013262084685266018 0.7741935483870968\n",
      "[92] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "92 0 0.013243993744254112 0.7741935483870968\n",
      "[93] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "93 0 0.013225997798144817 0.7741935483870968\n",
      "[94] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "94 0 0.013208099640905857 0.7741935483870968\n",
      "[95] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "95 0 0.013190302066504955 0.7741935483870968\n",
      "[96] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "96 0 0.013172606006264687 0.7741935483870968\n",
      "[97] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "97 0 0.013155016116797924 0.7741935483870968\n",
      "[98] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "98 0 0.013137532398104668 0.7741935483870968\n",
      "[99] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "99 0 0.013120156712830067 0.7741935483870968\n",
      "[100] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "100 0 0.013102889060974121 0.7741935483870968\n",
      "[101] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "101 0 0.013085735961794853 0.7741935483870968\n",
      "[102] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "102 0 0.013068689964711666 0.7741935483870968\n",
      "[103] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "103 0 0.013051756657660007 0.7741935483870968\n",
      "[104] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "104 0 0.013034925796091557 0.7741935483870968\n",
      "[105] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "105 0 0.01301804929971695 0.7741935483870968\n",
      "[106] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "106 0 0.01300126314163208 0.7741935483870968\n",
      "[107] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "107 0 0.012984578497707844 0.7741935483870968\n",
      "[108] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "108 0 0.012967987917363644 0.7741935483870968\n",
      "[109] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "109 0 0.01295115239918232 0.7741935483870968\n",
      "[110] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "110 0 0.012934362515807152 0.7741935483870968\n",
      "[111] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "111 0 0.012917468324303627 0.7741935483870968\n",
      "[112] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "112 0 0.01290053129196167 0.7741935483870968\n",
      "[113] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "113 0 0.012883647345006466 0.7741935483870968\n",
      "[114] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "114 0 0.012866820208728313 0.7741935483870968\n",
      "[115] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "115 0 0.012850053608417511 0.7741935483870968\n",
      "[116] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "116 0 0.012833353132009506 0.7741935483870968\n",
      "[117] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "117 0 0.0128167187795043 0.7741935483870968\n",
      "[118] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "118 0 0.012799962423741817 0.7741935483870968\n",
      "[119] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "119 0 0.012783113867044449 0.7741935483870968\n",
      "[120] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "120 0 0.012765679508447647 0.7741935483870968\n",
      "[121] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "121 0 0.012748252600431442 0.7741935483870968\n",
      "[122] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "122 0 0.012730836868286133 0.7741935483870968\n",
      "[123] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "123 0 0.01271344069391489 0.7741935483870968\n",
      "[124] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "124 0 0.012696006335318089 0.7741935483870968\n",
      "[125] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "125 0 0.012678290717303753 0.7741935483870968\n",
      "[126] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "126 0 0.012660217471420765 0.7741935483870968\n",
      "[127] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "127 0 0.012642132118344307 0.7741935483870968\n",
      "[128] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "128 0 0.012623817659914494 0.7741935483870968\n",
      "[129] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "129 0 0.012605197727680206 0.7741935483870968\n",
      "[130] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "130 0 0.012586533091962337 0.7741935483870968\n",
      "[131] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "131 0 0.012567847035825253 0.7741935483870968\n",
      "[132] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "132 0 0.012549144215881824 0.7741935483870968\n",
      "[133] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "133 0 0.012530438601970673 0.7741935483870968\n",
      "[134] loss/acc for train: (0.013, 0.774), valid: (0.013, 0.774), test: (0.013, 0.774)\n",
      "134 0 0.012511484324932098 0.7741935483870968\n",
      "[135] loss/acc for train: (0.013, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "135 0 0.012492272071540356 0.7741935483870968\n",
      "[136] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "136 0 0.012472635135054588 0.7741935483870968\n",
      "[137] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "137 0 0.012452158145606518 0.7741935483870968\n",
      "[138] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "138 0 0.012431459501385689 0.7741935483870968\n",
      "[139] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "139 0 0.0124110272154212 0.7741935483870968\n",
      "[140] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "140 0 0.01239157933741808 0.7741935483870968\n",
      "[141] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "141 0 0.012371819466352463 0.7741935483870968\n",
      "[142] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "142 0 0.012351823970675468 0.7741935483870968\n",
      "[143] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "143 0 0.012331804260611534 0.7741935483870968\n",
      "[144] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "144 0 0.012311666272580624 0.7741935483870968\n",
      "[145] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "145 0 0.012291238643229008 0.7741935483870968\n",
      "[146] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "146 0 0.012270797044038773 0.7741935483870968\n",
      "[147] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "147 0 0.012250350788235664 0.7741935483870968\n",
      "[148] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "148 0 0.012229915708303452 0.7741935483870968\n",
      "[149] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "149 0 0.012208912521600723 0.7741935483870968\n",
      "[150] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "150 0 0.012186987325549126 0.7741935483870968\n",
      "[151] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "151 0 0.012165000662207603 0.7741935483870968\n",
      "[152] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "152 0 0.012143704108893871 0.7741935483870968\n",
      "[153] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "153 0 0.012122397311031818 0.7741935483870968\n",
      "[154] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "154 0 0.012101500295102596 0.7741935483870968\n",
      "[155] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "155 0 0.012081453576683998 0.7741935483870968\n",
      "[156] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "156 0 0.012061556801199913 0.7741935483870968\n",
      "[157] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "157 0 0.012042374350130558 0.7741935483870968\n",
      "[158] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "158 0 0.012024378404021263 0.7741935483870968\n",
      "[159] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "159 0 0.012006882578134537 0.7741935483870968\n",
      "[160] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "160 0 0.011989613994956017 0.7741935483870968\n",
      "[161] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "161 0 0.011972552165389061 0.7741935483870968\n",
      "[162] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "162 0 0.011955548077821732 0.7741935483870968\n",
      "[163] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "163 0 0.011938530020415783 0.7741935483870968\n",
      "[164] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "164 0 0.011921709403395653 0.7741935483870968\n",
      "[165] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "165 0 0.011905083432793617 0.7741935483870968\n",
      "[166] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "166 0 0.011888649314641953 0.7741935483870968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[167] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "167 0 0.011872401461005211 0.7741935483870968\n",
      "[168] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "168 0 0.011856338940560818 0.7741935483870968\n",
      "[169] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "169 0 0.011840462684631348 0.7741935483870968\n",
      "[170] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "170 0 0.011824765242636204 0.7741935483870968\n",
      "[171] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "171 0 0.011809243820607662 0.7741935483870968\n",
      "[172] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "172 0 0.011793899349868298 0.7741935483870968\n",
      "[173] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "173 0 0.011778725311160088 0.7741935483870968\n",
      "[174] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "174 0 0.011763722635805607 0.7741935483870968\n",
      "[175] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "175 0 0.011748884804546833 0.7741935483870968\n",
      "[176] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "176 0 0.011734211817383766 0.7741935483870968\n",
      "[177] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "177 0 0.011719700880348682 0.7741935483870968\n",
      "[178] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "178 0 0.011705347336828709 0.7741935483870968\n",
      "[179] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "179 0 0.011691019870340824 0.7741935483870968\n",
      "[180] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "180 0 0.011676694266498089 0.7741935483870968\n",
      "[181] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "181 0 0.0116624990478158 0.7741935483870968\n",
      "[182] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "182 0 0.01164843887090683 0.7741935483870968\n",
      "[183] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "183 0 0.011634515598416328 0.7741935483870968\n",
      "[184] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "184 0 0.011620725505053997 0.7741935483870968\n",
      "[185] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "185 0 0.01160706952214241 0.7741935483870968\n",
      "[186] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "186 0 0.011593551374971867 0.7741935483870968\n",
      "[187] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "187 0 0.011580164544284344 0.7741935483870968\n",
      "[188] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "188 0 0.011566908098757267 0.7741935483870968\n",
      "[189] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "189 0 0.01155378483235836 0.7741935483870968\n",
      "[190] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "190 0 0.011540788225829601 0.7741935483870968\n",
      "[191] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "191 0 0.011527921073138714 0.7741935483870968\n",
      "[192] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "192 0 0.0115151796489954 0.7741935483870968\n",
      "[193] loss/acc for train: (0.012, 0.774), valid: (0.012, 0.774), test: (0.012, 0.774)\n",
      "193 0 0.01150256022810936 0.7741935483870968\n",
      "[194] loss/acc for train: (0.012, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "194 0 0.01149006374180317 0.7741935483870968\n",
      "[195] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "195 0 0.011477687396109104 0.7741935483870968\n",
      "[196] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "196 0 0.011465426534414291 0.7741935483870968\n",
      "[197] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "197 0 0.011453280225396156 0.7741935483870968\n",
      "[198] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "198 0 0.0114412447437644 0.7741935483870968\n",
      "[199] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "199 0 0.011429321952164173 0.7741935483870968\n",
      "[200] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "200 0 0.011417502537369728 0.7741935483870968\n",
      "[201] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "201 0 0.01140578743070364 0.7741935483870968\n",
      "[202] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "202 0 0.011394175700843334 0.7741935483870968\n",
      "[203] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "203 0 0.011382658034563065 0.7741935483870968\n",
      "[204] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "204 0 0.01137123815715313 0.7741935483870968\n",
      "[205] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "205 0 0.011359909549355507 0.7741935483870968\n",
      "[206] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "206 0 0.011348673142492771 0.7741935483870968\n",
      "[207] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "207 0 0.011337523348629475 0.7741935483870968\n",
      "[208] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "208 0 0.011326456442475319 0.7741935483870968\n",
      "[209] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "209 0 0.011315470561385155 0.7741935483870968\n",
      "[210] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "210 0 0.011304565705358982 0.7741935483870968\n",
      "[211] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "211 0 0.01129373349249363 0.7741935483870968\n",
      "[212] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "212 0 0.011282979510724545 0.7741935483870968\n",
      "[213] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "213 0 0.011272292584180832 0.7741935483870968\n",
      "[214] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "214 0 0.01126167457550764 0.7741935483870968\n",
      "[215] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "215 0 0.011251122690737247 0.7741935483870968\n",
      "[216] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "216 0 0.011240634135901928 0.7741935483870968\n",
      "[217] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "217 0 0.011230206117033958 0.7741935483870968\n",
      "[218] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "218 0 0.011219837702810764 0.7741935483870968\n",
      "[219] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "219 0 0.011209525167942047 0.7741935483870968\n",
      "[220] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "220 0 0.011199266649782658 0.7741935483870968\n",
      "[221] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "221 0 0.011189059354364872 0.7741935483870968\n",
      "[222] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "222 0 0.01117890328168869 0.7741935483870968\n",
      "[223] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "223 0 0.011168796569108963 0.7741935483870968\n",
      "[224] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "224 0 0.011158735491335392 0.7741935483870968\n",
      "[225] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "225 0 0.011148717254400253 0.7741935483870968\n",
      "[226] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "226 0 0.011138742789626122 0.7741935483870968\n",
      "[227] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "227 0 0.011128810234367847 0.7741935483870968\n",
      "[228] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "228 0 0.011118915863335133 0.7741935483870968\n",
      "[229] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "229 0 0.011109059676527977 0.7741935483870968\n",
      "[230] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "230 0 0.011099239811301231 0.7741935483870968\n",
      "[231] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "231 0 0.011089452542364597 0.7741935483870968\n",
      "[232] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "232 0 0.011079701595008373 0.7741935483870968\n",
      "[233] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "233 0 0.011069980449974537 0.7741935483870968\n",
      "[234] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "234 0 0.011060292832553387 0.7741935483870968\n",
      "[235] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "235 0 0.0110506322234869 0.7741935483870968\n",
      "[236] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "236 0 0.011041001416742802 0.7741935483870968\n",
      "[237] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "237 0 0.011031396687030792 0.7741935483870968\n",
      "[238] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "238 0 0.011021818965673447 0.7741935483870968\n",
      "[239] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "239 0 0.01101226732134819 0.7741935483870968\n",
      "[240] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "240 0 0.011002739891409874 0.7741935483870968\n",
      "[241] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "241 0 0.010993236675858498 0.7741935483870968\n",
      "[242] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "242 0 0.010983753949403763 0.7741935483870968\n",
      "[243] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "243 0 0.010974293574690819 0.7741935483870968\n",
      "[244] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "244 0 0.010964853689074516 0.7741935483870968\n",
      "[245] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "245 0 0.010955436155200005 0.7741935483870968\n",
      "[246] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "246 0 0.010946035385131836 0.7741935483870968\n",
      "[247] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "247 0 0.010936656966805458 0.7741935483870968\n",
      "[248] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "248 0 0.0109272925183177 0.7741935483870968\n",
      "[249] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "249 0 0.010917947627604008 0.7741935483870968\n",
      "[250] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "250 0 0.010908619500696659 0.7741935483870968\n",
      "[251] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "251 0 0.010899308137595654 0.7741935483870968\n",
      "[252] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "252 0 0.010890012606978416 0.7741935483870968\n",
      "[253] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "253 0 0.010880731046199799 0.7741935483870968\n",
      "[254] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "254 0 0.010871467180550098 0.7741935483870968\n",
      "[255] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "255 0 0.010862214490771294 0.7741935483870968\n",
      "[256] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "256 0 0.010852979496121407 0.7741935483870968\n",
      "[257] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "257 0 0.010843757539987564 0.7741935483870968\n",
      "[258] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "258 0 0.010834545828402042 0.7741935483870968\n",
      "[259] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "259 0 0.01082534994930029 0.7741935483870968\n",
      "[260] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "260 0 0.010816165246069431 0.7741935483870968\n",
      "[261] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "261 0 0.010806994512677193 0.7741935483870968\n",
      "[262] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "262 0 0.010797834023833275 0.7741935483870968\n",
      "[263] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "263 0 0.010788686573505402 0.7741935483870968\n",
      "[264] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "264 0 0.010779548436403275 0.7741935483870968\n",
      "[265] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "265 0 0.010770424269139767 0.7741935483870968\n",
      "[266] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "266 0 0.010761309415102005 0.7741935483870968\n",
      "[267] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "267 0 0.010752206668257713 0.7741935483870968\n",
      "[268] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "268 0 0.010743114165961742 0.7741935483870968\n",
      "[269] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "269 0 0.010734030045568943 0.7741935483870968\n",
      "[270] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "270 0 0.010724957101047039 0.7741935483870968\n",
      "[271] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "271 0 0.010715896263718605 0.7741935483870968\n",
      "[272] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "272 0 0.010706842876970768 0.7741935483870968\n",
      "[273] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "273 0 0.010697799734771252 0.7741935483870968\n",
      "[274] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "274 0 0.010688768699765205 0.7741935483870968\n",
      "[275] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "275 0 0.01067974604666233 0.7741935483870968\n",
      "[276] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "276 0 0.010670732706785202 0.7741935483870968\n",
      "[277] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "277 0 0.01066172681748867 0.7741935483870968\n",
      "[278] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "278 0 0.010652732104063034 0.7741935483870968\n",
      "[279] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "279 0 0.01064374577254057 0.7741935483870968\n",
      "[280] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "280 0 0.01063476875424385 0.7741935483870968\n",
      "[281] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "281 0 0.010625801980495453 0.7741935483870968\n",
      "[282] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "282 0 0.010616843588650227 0.7741935483870968\n",
      "[283] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "283 0 0.010607894510030746 0.7741935483870968\n",
      "[284] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "284 0 0.010598953813314438 0.7741935483870968\n",
      "[285] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "285 0 0.0105900214985013 0.7741935483870968\n",
      "[286] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "286 0 0.01058110035955906 0.7741935483870968\n",
      "[287] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "287 0 0.010572186671197414 0.7741935483870968\n",
      "[288] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "288 0 0.010563280433416367 0.7741935483870968\n",
      "[289] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "289 0 0.010554385371506214 0.7741935483870968\n",
      "[290] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "290 0 0.010545499622821808 0.7741935483870968\n",
      "[291] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "291 0 0.010536622256040573 0.7741935483870968\n",
      "[292] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "292 0 0.010527949780225754 0.7741935483870968\n",
      "[293] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "293 0 0.010520730167627335 0.7741935483870968\n",
      "[294] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "294 0 0.010513104498386383 0.7741935483870968\n",
      "[295] loss/acc for train: (0.011, 0.774), valid: (0.011, 0.774), test: (0.011, 0.774)\n",
      "295 0 0.010505122132599354 0.7741935483870968\n",
      "[296] loss/acc for train: (0.011, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "296 0 0.01049683429300785 0.7741935483870968\n",
      "[297] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "297 0 0.010488280095160007 0.7741935483870968\n",
      "[298] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "298 0 0.010479502379894257 0.7741935483870968\n",
      "[299] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "299 0 0.01047153677791357 0.7741935483870968\n",
      "[300] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "300 0 0.010463966988027096 0.7741935483870968\n",
      "[301] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "301 0 0.010456305928528309 0.7741935483870968\n",
      "[302] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "302 0 0.010448557324707508 0.7741935483870968\n",
      "[303] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "303 0 0.010440729558467865 0.7741935483870968\n",
      "[304] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "304 0 0.010432827286422253 0.7741935483870968\n",
      "[305] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "305 0 0.010424857027828693 0.7741935483870968\n",
      "[306] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "306 0 0.010416826233267784 0.7741935483870968\n",
      "[307] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "307 0 0.010408734902739525 0.7741935483870968\n",
      "[308] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "308 0 0.010400592349469662 0.7741935483870968\n",
      "[309] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "309 0 0.010393436998128891 0.7741935483870968\n",
      "[310] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "310 0 0.010386143811047077 0.7741935483870968\n",
      "[311] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "311 0 0.010378560051321983 0.7741935483870968\n",
      "[312] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "312 0 0.010370722971856594 0.7741935483870968\n",
      "[313] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "313 0 0.01036266889423132 0.7741935483870968\n",
      "[314] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "314 0 0.010354826226830482 0.7741935483870968\n",
      "[315] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "315 0 0.0103475796058774 0.7741935483870968\n",
      "[316] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "316 0 0.010340205393731594 0.7741935483870968\n",
      "[317] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "317 0 0.010332716628909111 0.7741935483870968\n",
      "[318] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "318 0 0.010325120761990547 0.7741935483870968\n",
      "[319] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "319 0 0.010317427106201649 0.7741935483870968\n",
      "[320] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "320 0 0.010309940204024315 0.7741935483870968\n",
      "[321] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "321 0 0.010302728042006493 0.7741935483870968\n",
      "[322] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "322 0 0.010295274667441845 0.7741935483870968\n",
      "[323] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "323 0 0.010287698358297348 0.7741935483870968\n",
      "[324] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "324 0 0.010280617512762547 0.7741935483870968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[325] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "325 0 0.010273393243551254 0.7741935483870968\n",
      "[326] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "326 0 0.010266036726534367 0.7741935483870968\n",
      "[327] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "327 0 0.010258556343615055 0.7741935483870968\n",
      "[328] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "328 0 0.010251619853079319 0.7741935483870968\n",
      "[329] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "329 0 0.010244559496641159 0.7741935483870968\n",
      "[330] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "330 0 0.010237271897494793 0.7741935483870968\n",
      "[331] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "331 0 0.010229784995317459 0.7741935483870968\n",
      "[332] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "332 0 0.010222896002233028 0.7741935483870968\n",
      "[333] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "333 0 0.010216005146503448 0.7741935483870968\n",
      "[334] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "334 0 0.010208946652710438 0.7741935483870968\n",
      "[335] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "335 0 0.010201734490692616 0.7741935483870968\n",
      "[336] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "336 0 0.010194383561611176 0.7741935483870968\n",
      "[337] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "337 0 0.01018733624368906 0.7741935483870968\n",
      "[338] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "338 0 0.01018051989376545 0.7741935483870968\n",
      "[339] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "339 0 0.01017348188906908 0.7741935483870968\n",
      "[340] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "340 0 0.010166248306632042 0.7741935483870968\n",
      "[341] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "341 0 0.010159369558095932 0.7741935483870968\n",
      "[342] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "342 0 0.010152602568268776 0.7741935483870968\n",
      "[343] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "343 0 0.01014565210789442 0.7741935483870968\n",
      "[344] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "344 0 0.010138536803424358 0.7741935483870968\n",
      "[345] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "345 0 0.010131575167179108 0.7741935483870968\n",
      "[346] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "346 0 0.010124832391738892 0.7741935483870968\n",
      "[347] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "347 0 0.010117883794009686 0.7741935483870968\n",
      "[348] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "348 0 0.010110910050570965 0.7741935483870968\n",
      "[349] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "349 0 0.010104138404130936 0.7741935483870968\n",
      "[350] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "350 0 0.010097246617078781 0.7741935483870968\n",
      "[351] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "351 0 0.010090538300573826 0.7741935483870968\n",
      "[352] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "352 0 0.010083671659231186 0.7741935483870968\n",
      "[353] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "353 0 0.010077090002596378 0.7741935483870968\n",
      "[354] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "354 0 0.010070397518575191 0.7741935483870968\n",
      "[355] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "355 0 0.01006351225078106 0.7741935483870968\n",
      "[356] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "356 0 0.010056878440082073 0.7741935483870968\n",
      "[357] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "357 0 0.010050280950963497 0.7741935483870968\n",
      "[358] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "358 0 0.010043492540717125 0.7741935483870968\n",
      "[359] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "359 0 0.010036710649728775 0.7741935483870968\n",
      "[360] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "360 0 0.01003012154251337 0.7741935483870968\n",
      "[361] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "361 0 0.010023384355008602 0.7741935483870968\n",
      "[362] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "362 0 0.0100168501958251 0.7741935483870968\n",
      "[363] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "363 0 0.010010170750319958 0.7741935483870968\n",
      "[364] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "364 0 0.01000371016561985 0.7741935483870968\n",
      "[365] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "365 0 0.00999716017395258 0.7741935483870968\n",
      "[366] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "366 0 0.009990422986447811 0.7741935483870968\n",
      "[367] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "367 0 0.009983953088521957 0.7741935483870968\n",
      "[368] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "368 0 0.009977377019822598 0.7741935483870968\n",
      "[369] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "369 0 0.009970900602638721 0.7741935483870968\n",
      "[370] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "370 0 0.00996439065784216 0.7741935483870968\n",
      "[371] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "371 0 0.009957842528820038 0.7741935483870968\n",
      "[372] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "372 0 0.009951360523700714 0.7741935483870968\n",
      "[373] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "373 0 0.009944934397935867 0.7741935483870968\n",
      "[374] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "374 0 0.009938442148268223 0.7741935483870968\n",
      "[375] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "375 0 0.00993208959698677 0.7741935483870968\n",
      "[376] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "376 0 0.009925691410899162 0.7741935483870968\n",
      "[377] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "377 0 0.009919140487909317 0.7741935483870968\n",
      "[378] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "378 0 0.009912800043821335 0.7741935483870968\n",
      "[379] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "379 0 0.009906359948217869 0.7741935483870968\n",
      "[380] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "380 0 0.00990001205354929 0.7741935483870968\n",
      "[381] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "381 0 0.009893625043332577 0.7741935483870968\n",
      "[382] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "382 0 0.009887325577437878 0.7741935483870968\n",
      "[383] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "383 0 0.009880933910608292 0.7741935483870968\n",
      "[384] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "384 0 0.009874747134745121 0.7741935483870968\n",
      "[385] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "385 0 0.009868379682302475 0.7741935483870968\n",
      "[386] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "386 0 0.009862061589956284 0.7741935483870968\n",
      "[387] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "387 0 0.00985577329993248 0.7741935483870968\n",
      "[388] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "388 0 0.009849503636360168 0.7741935483870968\n",
      "[389] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "389 0 0.0098432507365942 0.7741935483870968\n",
      "[390] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "390 0 0.009836939163506031 0.7741935483870968\n",
      "[391] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "391 0 0.009830859489738941 0.7741935483870968\n",
      "[392] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "392 0 0.00982452929019928 0.7741935483870968\n",
      "[393] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "393 0 0.00981839094310999 0.7741935483870968\n",
      "[394] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "394 0 0.00981227122247219 0.7741935483870968\n",
      "[395] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "395 0 0.009805974550545216 0.7741935483870968\n",
      "[396] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "396 0 0.00979976449161768 0.7741935483870968\n",
      "[397] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "397 0 0.009793641977012157 0.7741935483870968\n",
      "[398] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "398 0 0.009787368588149548 0.7741935483870968\n",
      "[399] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "399 0 0.009781386703252792 0.7741935483870968\n",
      "[400] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "400 0 0.00977523997426033 0.7741935483870968\n",
      "[401] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "401 0 0.00976897869259119 0.7741935483870968\n",
      "[402] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "402 0 0.009762986563146114 0.7741935483870968\n",
      "[403] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "403 0 0.009756796061992645 0.7741935483870968\n",
      "[404] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "404 0 0.009750839322805405 0.7741935483870968\n",
      "[405] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "405 0 0.009744839742779732 0.7741935483870968\n",
      "[406] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "406 0 0.00973866693675518 0.7741935483870968\n",
      "[407] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "407 0 0.009732555598020554 0.7741935483870968\n",
      "[408] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "408 0 0.009726555086672306 0.7741935483870968\n",
      "[409] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "409 0 0.009720420464873314 0.7741935483870968\n",
      "[410] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "410 0 0.009714401327073574 0.7741935483870968\n",
      "[411] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "411 0 0.009708392433822155 0.7741935483870968\n",
      "[412] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "412 0 0.009702478535473347 0.7741935483870968\n",
      "[413] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "413 0 0.009696420282125473 0.7741935483870968\n",
      "[414] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "414 0 0.00969043280929327 0.7741935483870968\n",
      "[415] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "415 0 0.009684535674750805 0.7741935483870968\n",
      "[416] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "416 0 0.009678509086370468 0.7741935483870968\n",
      "[417] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "417 0 0.00967256911098957 0.7741935483870968\n",
      "[418] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "418 0 0.009666644968092442 0.7741935483870968\n",
      "[419] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "419 0 0.00966076459735632 0.7741935483870968\n",
      "[420] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "420 0 0.00965484045445919 0.7741935483870968\n",
      "[421] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "421 0 0.009648903273046017 0.7741935483870968\n",
      "[422] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "422 0 0.009642986580729485 0.7741935483870968\n",
      "[423] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "423 0 0.009637091308832169 0.7741935483870968\n",
      "[424] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "424 0 0.00963129848241806 0.7741935483870968\n",
      "[425] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "425 0 0.00962485745549202 0.7741935483870968\n",
      "[426] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "426 0 0.009618324227631092 0.7741935483870968\n",
      "[427] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "427 0 0.009611726738512516 0.7741935483870968\n",
      "[428] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "428 0 0.009605072438716888 0.7741935483870968\n",
      "[429] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "429 0 0.009598320350050926 0.7741935483870968\n",
      "[430] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "430 0 0.00959151890128851 0.7741935483870968\n",
      "[431] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "431 0 0.009584648534655571 0.7741935483870968\n",
      "[432] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "432 0 0.009577762335538864 0.7741935483870968\n",
      "[433] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "433 0 0.009570925496518612 0.7741935483870968\n",
      "[434] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "434 0 0.009563911706209183 0.7741935483870968\n",
      "[435] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "435 0 0.00955695565789938 0.7741935483870968\n",
      "[436] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "436 0 0.009549995884299278 0.7741935483870968\n",
      "[437] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "437 0 0.009543010964989662 0.7741935483870968\n",
      "[438] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "438 0 0.00953598041087389 0.7741935483870968\n",
      "[439] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "439 0 0.009528972208499908 0.7741935483870968\n",
      "[440] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "440 0 0.009521887637674809 0.7741935483870968\n",
      "[441] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "441 0 0.009514836594462395 0.7741935483870968\n",
      "[442] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "442 0 0.009507820941507816 0.7741935483870968\n",
      "[443] loss/acc for train: (0.010, 0.774), valid: (0.010, 0.774), test: (0.010, 0.774)\n",
      "443 0 0.00950073916465044 0.7741935483870968\n",
      "[444] loss/acc for train: (0.010, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "444 0 0.009493744932115078 0.7741935483870968\n",
      "[445] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "445 0 0.009486624971032143 0.7741935483870968\n",
      "[446] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "446 0 0.009479710832238197 0.7741935483870968\n",
      "[447] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "447 0 0.009472607634961605 0.7741935483870968\n",
      "[448] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "448 0 0.009465519338846207 0.7741935483870968\n",
      "[449] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "449 0 0.009458462707698345 0.7741935483870968\n",
      "[450] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "450 0 0.009451483376324177 0.7741935483870968\n",
      "[451] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "451 0 0.009444468654692173 0.7741935483870968\n",
      "[452] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "452 0 0.009437333792448044 0.7741935483870968\n",
      "[453] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "453 0 0.009430422447621822 0.7741935483870968\n",
      "[454] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "454 0 0.009423299692571163 0.7741935483870968\n",
      "[455] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "455 0 0.009416282176971436 0.7741935483870968\n",
      "[456] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "456 0 0.009409366175532341 0.7741935483870968\n",
      "[457] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "457 0 0.009402282536029816 0.7741935483870968\n",
      "[458] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "458 0 0.009395299479365349 0.7741935483870968\n",
      "[459] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "459 0 0.009388353675603867 0.7741935483870968\n",
      "[460] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "460 0 0.009381355717778206 0.7741935483870968\n",
      "[461] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "461 0 0.009374373592436314 0.7741935483870968\n",
      "[462] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "462 0 0.009367415681481361 0.7741935483870968\n",
      "[463] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "463 0 0.00936046615242958 0.7741935483870968\n",
      "[464] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "464 0 0.009353522211313248 0.7741935483870968\n",
      "[465] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "465 0 0.009346583858132362 0.7741935483870968\n",
      "[466] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "466 0 0.009339653886854649 0.7741935483870968\n",
      "[467] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "467 0 0.009332730434834957 0.7741935483870968\n",
      "[468] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "468 0 0.009325835853815079 0.7741935483870968\n",
      "[469] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "469 0 0.009318946860730648 0.7741935483870968\n",
      "[470] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "470 0 0.009312015026807785 0.7741935483870968\n",
      "[471] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "471 0 0.009305121377110481 0.7741935483870968\n",
      "[472] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "472 0 0.009298291057348251 0.7741935483870968\n",
      "[473] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "473 0 0.009291364811360836 0.7741935483870968\n",
      "[474] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "474 0 0.009284603409469128 0.7741935483870968\n",
      "[475] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "475 0 0.009277638047933578 0.7741935483870968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[476] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "476 0 0.009270780719816685 0.7741935483870968\n",
      "[477] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "477 0 0.009264039807021618 0.7741935483870968\n",
      "[478] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "478 0 0.009257097728550434 0.7741935483870968\n",
      "[479] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "479 0 0.009252505376935005 0.7741935483870968\n",
      "[480] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "480 0 0.009248215705156326 0.7741935483870968\n",
      "[481] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "481 0 0.00924370065331459 0.7741935483870968\n",
      "[482] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "482 0 0.009239313192665577 0.7741935483870968\n",
      "[483] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "483 0 0.009234750643372536 0.7741935483870968\n",
      "[484] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "484 0 0.00923023372888565 0.7741935483870968\n",
      "[485] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "485 0 0.009225723333656788 0.7741935483870968\n",
      "[486] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "486 0 0.009221151471138 0.7741935483870968\n",
      "[487] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "487 0 0.00921656284481287 0.7741935483870968\n",
      "[488] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "488 0 0.00921198632568121 0.7741935483870968\n",
      "[489] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "489 0 0.009207401424646378 0.7741935483870968\n",
      "[490] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "490 0 0.009202814660966396 0.7741935483870968\n",
      "[491] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "491 0 0.009198225103318691 0.7741935483870968\n",
      "[492] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "492 0 0.009193637408316135 0.7741935483870968\n",
      "[493] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "493 0 0.009189051575958729 0.7741935483870968\n",
      "[494] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "494 0 0.009184523485600948 0.7741935483870968\n",
      "[495] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "495 0 0.009179922752082348 0.7741935483870968\n",
      "[496] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "496 0 0.00917547196149826 0.7741935483870968\n",
      "[497] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "497 0 0.009170826524496078 0.7741935483870968\n",
      "[498] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "498 0 0.009166392497718334 0.7741935483870968\n",
      "[499] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "499 0 0.009161830879747868 0.7741935483870968\n",
      "[500] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "500 0 0.009157367050647736 0.7741935483870968\n",
      "[501] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "501 0 0.009152832441031933 0.7741935483870968\n",
      "[502] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "502 0 0.00914848130196333 0.7741935483870968\n",
      "[503] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "503 0 0.009144103154540062 0.7741935483870968\n",
      "[504] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "504 0 0.009139562025666237 0.7741935483870968\n",
      "[505] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "505 0 0.00913514569401741 0.7741935483870968\n",
      "[506] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "506 0 0.009130753576755524 0.7741935483870968\n",
      "[507] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "507 0 0.009126358665525913 0.7741935483870968\n",
      "[508] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "508 0 0.009122053161263466 0.7741935483870968\n",
      "[509] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "509 0 0.00911760050803423 0.7741935483870968\n",
      "[510] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "510 0 0.009113496169447899 0.7741935483870968\n",
      "[511] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "511 0 0.009109178557991982 0.7741935483870968\n",
      "[512] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "512 0 0.009104695171117783 0.7741935483870968\n",
      "[513] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "513 0 0.009100498631596565 0.7741935483870968\n",
      "[514] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "514 0 0.00909616332501173 0.7741935483870968\n",
      "[515] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "515 0 0.009092127904295921 0.7741935483870968\n",
      "[516] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "516 0 0.009087840095162392 0.7741935483870968\n",
      "[517] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "517 0 0.009083603508770466 0.7741935483870968\n",
      "[518] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "518 0 0.009079520590603352 0.7741935483870968\n",
      "[519] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "519 0 0.009075305424630642 0.7741935483870968\n",
      "[520] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "520 0 0.009070983156561852 0.7741935483870968\n",
      "[521] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "521 0 0.009066876955330372 0.7741935483870968\n",
      "[522] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "522 0 0.00906280055642128 0.7741935483870968\n",
      "[523] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "523 0 0.009058644063770771 0.7741935483870968\n",
      "[524] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "524 0 0.00905459001660347 0.7741935483870968\n",
      "[525] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "525 0 0.009050420485436916 0.7741935483870968\n",
      "[526] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "526 0 0.00904642790555954 0.7741935483870968\n",
      "[527] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "527 0 0.009042266756296158 0.7741935483870968\n",
      "[528] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "528 0 0.009038192220032215 0.7741935483870968\n",
      "[529] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "529 0 0.009034126065671444 0.7741935483870968\n",
      "[530] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "530 0 0.009030161425471306 0.7741935483870968\n",
      "[531] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "531 0 0.009026051498949528 0.7741935483870968\n",
      "[532] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "532 0 0.009022179991006851 0.7741935483870968\n",
      "[533] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "533 0 0.00901819858700037 0.7741935483870968\n",
      "[534] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "534 0 0.009014113806188107 0.7741935483870968\n",
      "[535] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "535 0 0.009010068140923977 0.7741935483870968\n",
      "[536] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "536 0 0.00900626927614212 0.7741935483870968\n",
      "[537] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "537 0 0.009002086706459522 0.7741935483870968\n",
      "[538] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "538 0 0.008998222649097443 0.7741935483870968\n",
      "[539] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "539 0 0.008994314819574356 0.7741935483870968\n",
      "[540] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "540 0 0.008990309201180935 0.7741935483870968\n",
      "[541] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "541 0 0.008986217901110649 0.7741935483870968\n",
      "[542] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "542 0 0.00898231565952301 0.7741935483870968\n",
      "[543] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "543 0 0.008978373371064663 0.7741935483870968\n",
      "[544] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "544 0 0.00897439569234848 0.7741935483870968\n",
      "[545] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "545 0 0.008970586583018303 0.7741935483870968\n",
      "[546] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "546 0 0.008966675028204918 0.7741935483870968\n",
      "[547] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "547 0 0.008962670341134071 0.7741935483870968\n",
      "[548] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "548 0 0.008958826772868633 0.7741935483870968\n",
      "[549] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "549 0 0.008954829536378384 0.7741935483870968\n",
      "[550] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "550 0 0.008950966410338879 0.7741935483870968\n",
      "[551] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "551 0 0.00894708652049303 0.7741935483870968\n",
      "[552] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "552 0 0.008943116292357445 0.7741935483870968\n",
      "[553] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "553 0 0.008939344435930252 0.7741935483870968\n",
      "[554] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "554 0 0.008935339748859406 0.7741935483870968\n",
      "[555] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "555 0 0.008931511081755161 0.7741935483870968\n",
      "[556] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "556 0 0.00892766285687685 0.7741935483870968\n",
      "[557] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "557 0 0.008923723362386227 0.7741935483870968\n",
      "[558] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "558 0 0.008919832296669483 0.7741935483870968\n",
      "[559] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "559 0 0.008916066959500313 0.7741935483870968\n",
      "[560] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "560 0 0.008912068791687489 0.7741935483870968\n",
      "[561] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "561 0 0.008908262476325035 0.7741935483870968\n",
      "[562] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "562 0 0.008904366753995419 0.7741935483870968\n",
      "[563] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "563 0 0.008900468237698078 0.7741935483870968\n",
      "[564] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "564 0 0.008896632120013237 0.7741935483870968\n",
      "[565] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "565 0 0.008892741985619068 0.7741935483870968\n",
      "[566] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "566 0 0.008888909593224525 0.7741935483870968\n",
      "[567] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "567 0 0.008885056711733341 0.7741935483870968\n",
      "[568] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "568 0 0.008881141431629658 0.7741935483870968\n",
      "[569] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "569 0 0.008877287618815899 0.7741935483870968\n",
      "[570] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "570 0 0.0088734719902277 0.7741935483870968\n",
      "[571] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "571 0 0.008869592100381851 0.7741935483870968\n",
      "[572] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "572 0 0.008865775540471077 0.7741935483870968\n",
      "[573] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "573 0 0.008861960843205452 0.7741935483870968\n",
      "[574] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "574 0 0.008858103305101395 0.7741935483870968\n",
      "[575] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "575 0 0.00885434914380312 0.7741935483870968\n",
      "[576] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "576 0 0.008850502781569958 0.7741935483870968\n",
      "[577] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "577 0 0.008846571668982506 0.7741935483870968\n",
      "[578] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "578 0 0.008842662908136845 0.7741935483870968\n",
      "[579] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "579 0 0.008838927373290062 0.7741935483870968\n",
      "[580] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "580 0 0.008834965527057648 0.7741935483870968\n",
      "[581] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "581 0 0.00883118063211441 0.7741935483870968\n",
      "[582] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "582 0 0.00882730819284916 0.7741935483870968\n",
      "[583] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "583 0 0.008823443204164505 0.7741935483870968\n",
      "[584] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "584 0 0.008819625712931156 0.7741935483870968\n",
      "[585] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "585 0 0.008815745823085308 0.7741935483870968\n",
      "[586] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "586 0 0.008811958134174347 0.7741935483870968\n",
      "[587] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "587 0 0.008808132261037827 0.7741935483870968\n",
      "[588] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "588 0 0.008804221637547016 0.7741935483870968\n",
      "[589] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "589 0 0.008800484240055084 0.7741935483870968\n",
      "[590] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "590 0 0.008796527981758118 0.7741935483870968\n",
      "[591] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "591 0 0.008792806416749954 0.7741935483870968\n",
      "[592] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "592 0 0.00878902431577444 0.7741935483870968\n",
      "[593] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "593 0 0.00878515187650919 0.7741935483870968\n",
      "[594] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "594 0 0.008781198412179947 0.7741935483870968\n",
      "[595] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "595 0 0.008777511306107044 0.7741935483870968\n",
      "[596] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "596 0 0.008773546665906906 0.7741935483870968\n",
      "[597] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "597 0 0.008769679814577103 0.7741935483870968\n",
      "[598] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "598 0 0.008765870705246925 0.7741935483870968\n",
      "[599] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "599 0 0.00876197312027216 0.7741935483870968\n",
      "[600] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "600 0 0.00875828880816698 0.7741935483870968\n",
      "[601] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "601 0 0.008754309266805649 0.7741935483870968\n",
      "[602] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "602 0 0.00875059049576521 0.7741935483870968\n",
      "[603] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "603 0 0.008746815845370293 0.7741935483870968\n",
      "[604] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "604 0 0.008742948062717915 0.7741935483870968\n",
      "[605] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "605 0 0.00873899832367897 0.7741935483870968\n",
      "[606] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "606 0 0.00873526744544506 0.7741935483870968\n",
      "[607] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "607 0 0.008731326088309288 0.7741935483870968\n",
      "[608] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "608 0 0.008727489039301872 0.7741935483870968\n",
      "[609] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "609 0 0.00872367899864912 0.7741935483870968\n",
      "[610] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "610 0 0.008719779551029205 0.7741935483870968\n",
      "[611] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "611 0 0.008716066367924213 0.7741935483870968\n",
      "[612] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "612 0 0.008712105453014374 0.7741935483870968\n",
      "[613] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "613 0 0.008708390407264233 0.7741935483870968\n",
      "[614] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "614 0 0.008704612962901592 0.7741935483870968\n",
      "[615] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "615 0 0.008700739592313766 0.7741935483870968\n",
      "[616] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "616 0 0.008696780540049076 0.7741935483870968\n",
      "[617] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "617 0 0.008693138137459755 0.7741935483870968\n",
      "[618] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "618 0 0.00868916418403387 0.7741935483870968\n",
      "[619] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "619 0 0.008685409091413021 0.7741935483870968\n",
      "[620] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "620 0 0.008681738749146461 0.7741935483870968\n",
      "[621] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "621 0 0.008677960373461246 0.7741935483870968\n",
      "[622] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "622 0 0.008674084208905697 0.7741935483870968\n",
      "[623] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "623 0 0.00867011770606041 0.7741935483870968\n",
      "[624] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "624 0 0.00866607204079628 0.7741935483870968\n",
      "[625] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "625 0 0.008662750944495201 0.7741935483870968\n",
      "[626] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "626 0 0.00865896139293909 0.7741935483870968\n",
      "[627] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "627 0 0.008654625155031681 0.7741935483870968\n",
      "[628] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "628 0 0.008650929667055607 0.7741935483870968\n",
      "[629] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "629 0 0.008647247217595577 0.7741935483870968\n",
      "[630] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "630 0 0.008643453940749168 0.7741935483870968\n",
      "[631] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "631 0 0.008639560081064701 0.7741935483870968\n",
      "[632] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "632 0 0.008635574020445347 0.7741935483870968\n",
      "[633] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "633 0 0.008631609380245209 0.7741935483870968\n",
      "[634] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "634 0 0.008628031238913536 0.7741935483870968\n",
      "[635] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "635 0 0.008623958565294743 0.7741935483870968\n",
      "[636] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "636 0 0.008620155043900013 0.7741935483870968\n",
      "[637] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "637 0 0.008616381324827671 0.7741935483870968\n",
      "[638] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "638 0 0.008612500503659248 0.7741935483870968\n",
      "[639] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "639 0 0.00860857218503952 0.7741935483870968\n",
      "[640] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "640 0 0.008604773320257664 0.7741935483870968\n",
      "[641] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "641 0 0.008600916713476181 0.7741935483870968\n",
      "[642] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "642 0 0.008597072213888168 0.7741935483870968\n",
      "[643] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "643 0 0.008593213744461536 0.7741935483870968\n",
      "[644] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "644 0 0.008589424192905426 0.7741935483870968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[645] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "645 0 0.008585639297962189 0.7741935483870968\n",
      "[646] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "646 0 0.008581753820180893 0.7741935483870968\n",
      "[647] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "647 0 0.008578003384172916 0.7741935483870968\n",
      "[648] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "648 0 0.008574139326810837 0.7741935483870968\n",
      "[649] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "649 0 0.0085701709613204 0.7741935483870968\n",
      "[650] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "650 0 0.008566582575440407 0.7741935483870968\n",
      "[651] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "651 0 0.008562625385820866 0.7741935483870968\n",
      "[652] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "652 0 0.008558772504329681 0.7741935483870968\n",
      "[653] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "653 0 0.00855509378015995 0.7741935483870968\n",
      "[654] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "654 0 0.008551287464797497 0.7741935483870968\n",
      "[655] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "655 0 0.008547368459403515 0.7741935483870968\n",
      "[656] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "656 0 0.008543344214558601 0.7741935483870968\n",
      "[657] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "657 0 0.008539709262549877 0.7741935483870968\n",
      "[658] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "658 0 0.00853586196899414 0.7741935483870968\n",
      "[659] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "659 0 0.008531810715794563 0.7741935483870968\n",
      "[660] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "660 0 0.008528091013431549 0.7741935483870968\n",
      "[661] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "661 0 0.008524246513843536 0.7741935483870968\n",
      "[662] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "662 0 0.008520286530256271 0.7741935483870968\n",
      "[663] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "663 0 0.00851662177592516 0.7741935483870968\n",
      "[664] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "664 0 0.008512666448950768 0.7741935483870968\n",
      "[665] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "665 0 0.008508908562362194 0.7741935483870968\n",
      "[666] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "666 0 0.008505230769515038 0.7741935483870968\n",
      "[667] loss/acc for train: (0.009, 0.774), valid: (0.009, 0.774), test: (0.009, 0.774)\n",
      "667 0 0.008501417934894562 0.7741935483870968\n",
      "[668] loss/acc for train: (0.009, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "668 0 0.008497482165694237 0.7741935483870968\n",
      "[669] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "669 0 0.008493435569107533 0.7741935483870968\n",
      "[670] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "670 0 0.00848994217813015 0.7741935483870968\n",
      "[671] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "671 0 0.008486148901283741 0.7741935483870968\n",
      "[672] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "672 0 0.008481922559440136 0.7741935483870968\n",
      "[673] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "673 0 0.008478295058012009 0.7741935483870968\n",
      "[674] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "674 0 0.008474594913423061 0.7741935483870968\n",
      "[675] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "675 0 0.008470757864415646 0.7741935483870968\n",
      "[676] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "676 0 0.008466794155538082 0.7741935483870968\n",
      "[677] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "677 0 0.008462723344564438 0.7741935483870968\n",
      "[678] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "678 0 0.008459004573523998 0.7741935483870968\n",
      "[679] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "679 0 0.00845506601035595 0.7741935483870968\n",
      "[680] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "680 0 0.008451366797089577 0.7741935483870968\n",
      "[681] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "681 0 0.008447567000985146 0.7741935483870968\n",
      "[682] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "682 0 0.008443630300462246 0.7741935483870968\n",
      "[683] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "683 0 0.008439774625003338 0.7741935483870968\n",
      "[684] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "684 0 0.008436198346316814 0.7741935483870968\n",
      "[685] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "685 0 0.00843209307640791 0.7741935483870968\n",
      "[686] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "686 0 0.008428281173110008 0.7741935483870968\n",
      "[687] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "687 0 0.008424491621553898 0.7741935483870968\n",
      "[688] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "688 0 0.008420560508966446 0.7741935483870968\n",
      "[689] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "689 0 0.008416843600571156 0.7741935483870968\n",
      "[690] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "690 0 0.008412906900048256 0.7741935483870968\n",
      "[691] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "691 0 0.008409028872847557 0.7741935483870968\n",
      "[692] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "692 0 0.008405182510614395 0.7741935483870968\n",
      "[693] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "693 0 0.008401376195251942 0.7741935483870968\n",
      "[694] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "694 0 0.008397532626986504 0.7741935483870968\n",
      "[695] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "695 0 0.008393705822527409 0.7741935483870968\n",
      "[696] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "696 0 0.008389848284423351 0.7741935483870968\n",
      "[697] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "697 0 0.008386041037738323 0.7741935483870968\n",
      "[698] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "698 0 0.008382149040699005 0.7741935483870968\n",
      "[699] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "699 0 0.008378453552722931 0.7741935483870968\n",
      "[700] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "700 0 0.00837450660765171 0.7741935483870968\n",
      "[701] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "701 0 0.008370691910386086 0.7741935483870968\n",
      "[702] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "702 0 0.008366845548152924 0.7741935483870968\n",
      "[703] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "703 0 0.00836299266666174 0.7741935483870968\n",
      "[704] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "704 0 0.00835923757404089 0.7741935483870968\n",
      "[705] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "705 0 0.008355291560292244 0.7741935483870968\n",
      "[706] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "706 0 0.008351486176252365 0.7741935483870968\n",
      "[707] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "707 0 0.00834762491285801 0.7741935483870968\n",
      "[708] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "708 0 0.00834380742162466 0.7741935483870968\n",
      "[709] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "709 0 0.00833995919674635 0.7741935483870968\n",
      "[710] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "710 0 0.008336089551448822 0.7741935483870968\n",
      "[711] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "711 0 0.008332330733537674 0.7741935483870968\n",
      "[712] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "712 0 0.008328446187078953 0.7741935483870968\n",
      "[713] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "713 0 0.008324610069394112 0.7741935483870968\n",
      "[714] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "714 0 0.008320971392095089 0.7741935483870968\n",
      "[715] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "715 0 0.008316908963024616 0.7741935483870968\n",
      "[716] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "716 0 0.008313157595694065 0.7741935483870968\n",
      "[717] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "717 0 0.008309348486363888 0.7741935483870968\n",
      "[718] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "718 0 0.008305368945002556 0.7741935483870968\n",
      "[719] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "719 0 0.008301780559122562 0.7741935483870968\n",
      "[720] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "720 0 0.008297908119857311 0.7741935483870968\n",
      "[721] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "721 0 0.008293883875012398 0.7741935483870968\n",
      "[722] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "722 0 0.008290151134133339 0.7741935483870968\n",
      "[723] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "723 0 0.008286233991384506 0.7741935483870968\n",
      "[724] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "724 0 0.008282428607344627 0.7741935483870968\n",
      "[725] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "725 0 0.008278544060885906 0.7741935483870968\n",
      "[726] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "726 0 0.008274673484265804 0.7741935483870968\n",
      "[727] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "727 0 0.008270989172160625 0.7741935483870968\n",
      "[728] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "728 0 0.008267119526863098 0.7741935483870968\n",
      "[729] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "729 0 0.008263200521469116 0.7741935483870968\n",
      "[730] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "730 0 0.008259497582912445 0.7741935483870968\n",
      "[731] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "731 0 0.008255526423454285 0.7741935483870968\n",
      "[732] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "732 0 0.00825180672109127 0.7741935483870968\n",
      "[733] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "733 0 0.008247973397374153 0.7741935483870968\n",
      "[734] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "734 0 0.008244026452302933 0.7741935483870968\n",
      "[735] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "735 0 0.008240233175456524 0.7741935483870968\n",
      "[736] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "736 0 0.008236360736191273 0.7741935483870968\n",
      "[737] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "737 0 0.008232523687183857 0.7741935483870968\n",
      "[738] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "738 0 0.008228708989918232 0.7741935483870968\n",
      "[739] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "739 0 0.008224899880588055 0.7741935483870968\n",
      "[740] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "740 0 0.008221182972192764 0.7741935483870968\n",
      "[741] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "741 0 0.008217214606702328 0.7741935483870968\n",
      "[742] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "742 0 0.008213573135435581 0.7741935483870968\n",
      "[743] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "743 0 0.00820975936949253 0.7741935483870968\n",
      "[744] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "744 0 0.008205744437873363 0.7741935483870968\n",
      "[745] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "745 0 0.00820219423621893 0.7741935483870968\n",
      "[746] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "746 0 0.008198424242436886 0.7741935483870968\n",
      "[747] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "747 0 0.008194281719624996 0.7741935483870968\n",
      "[748] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "748 0 0.008190587162971497 0.7741935483870968\n",
      "[749] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "749 0 0.008186815306544304 0.7741935483870968\n",
      "[750] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "750 0 0.008182832971215248 0.7741935483870968\n",
      "[751] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "751 0 0.0081791952252388 0.7741935483870968\n",
      "[752] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "752 0 0.008175409398972988 0.7741935483870968\n",
      "[753] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "753 0 0.008171348832547665 0.7741935483870968\n",
      "[754] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "754 0 0.008167749270796776 0.7741935483870968\n",
      "[755] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "755 0 0.00816398486495018 0.7741935483870968\n",
      "[756] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "756 0 0.008159998804330826 0.7741935483870968\n",
      "[757] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "757 0 0.008156216703355312 0.7741935483870968\n",
      "[758] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "758 0 0.008152453228831291 0.7741935483870968\n",
      "[759] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "759 0 0.008148462511599064 0.7741935483870968\n",
      "[760] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "760 0 0.008144889958202839 0.7741935483870968\n",
      "[761] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "761 0 0.008141111582517624 0.7741935483870968\n",
      "[762] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "762 0 0.008137107826769352 0.7741935483870968\n",
      "[763] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "763 0 0.008133433759212494 0.7741935483870968\n",
      "[764] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "764 0 0.00812971219420433 0.7741935483870968\n",
      "[765] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "765 0 0.008125639520585537 0.7741935483870968\n",
      "[766] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "766 0 0.008121917024254799 0.7741935483870968\n",
      "[767] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "767 0 0.008118115365505219 0.7741935483870968\n",
      "[768] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "768 0 0.008114228025078773 0.7741935483870968\n",
      "[769] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "769 0 0.008110573515295982 0.7741935483870968\n",
      "[770] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "770 0 0.008106634020805359 0.7741935483870968\n",
      "[771] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "771 0 0.008102813735604286 0.7741935483870968\n",
      "[772] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "772 0 0.008099027909338474 0.7741935483870968\n",
      "[773] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "773 0 0.008095236495137215 0.7741935483870968\n",
      "[774] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "774 0 0.008091442286968231 0.7741935483870968\n",
      "[775] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "775 0 0.008087641559541225 0.7741935483870968\n",
      "[776] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "776 0 0.00808383896946907 0.7741935483870968\n",
      "[777] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "777 0 0.00808003544807434 0.7741935483870968\n",
      "[778] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "778 0 0.008076307363808155 0.7741935483870968\n",
      "[779] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "779 0 0.008072453550994396 0.7741935483870968\n",
      "[780] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "780 0 0.008068684488534927 0.7741935483870968\n",
      "[781] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "781 0 0.008064860478043556 0.7741935483870968\n",
      "[782] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "782 0 0.008061242289841175 0.7741935483870968\n",
      "[783] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "783 0 0.008057380095124245 0.7741935483870968\n",
      "[784] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "784 0 0.008053520694375038 0.7741935483870968\n",
      "[785] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "785 0 0.008049720898270607 0.7741935483870968\n",
      "[786] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "786 0 0.008045930415391922 0.7741935483870968\n",
      "[787] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "787 0 0.008042139932513237 0.7741935483870968\n",
      "[788] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "788 0 0.008038504980504513 0.7741935483870968\n",
      "[789] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "789 0 0.008034713566303253 0.7741935483870968\n",
      "[790] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "790 0 0.008030900731682777 0.7741935483870968\n",
      "[791] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "791 0 0.008027289062738419 0.7741935483870968\n",
      "[792] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "792 0 0.008023452945053577 0.7741935483870968\n",
      "[793] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "793 0 0.008019736036658287 0.7741935483870968\n",
      "[794] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "794 0 0.008015994913876057 0.7741935483870968\n",
      "[795] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "795 0 0.008012267760932446 0.7741935483870968\n",
      "[796] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "796 0 0.008008617907762527 0.7741935483870968\n",
      "[797] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "797 0 0.008004793897271156 0.7741935483870968\n",
      "[798] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "798 0 0.00800120085477829 0.7741935483870968\n",
      "[799] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "799 0 0.007997366599738598 0.7741935483870968\n",
      "[800] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "800 0 0.007993772625923157 0.7741935483870968\n",
      "[801] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "801 0 0.007990103214979172 0.7741935483870968\n",
      "[802] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "802 0 0.007986185140907764 0.7741935483870968\n",
      "[803] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "803 0 0.007982644252479076 0.7741935483870968\n",
      "[804] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "804 0 0.007978870533406734 0.7741935483870968\n",
      "[805] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "805 0 0.007975188083946705 0.7741935483870968\n",
      "[806] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "806 0 0.007971527054905891 0.7741935483870968\n",
      "[807] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "807 0 0.007967724464833736 0.7741935483870968\n",
      "[808] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "808 0 0.007964186370372772 0.7741935483870968\n",
      "[809] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "809 0 0.007960405200719833 0.7741935483870968\n",
      "[810] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "810 0 0.007956797257065773 0.7741935483870968\n",
      "[811] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "811 0 0.007953235879540443 0.7741935483870968\n",
      "[812] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "812 0 0.0079493448138237 0.7741935483870968\n",
      "[813] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "813 0 0.007945715449750423 0.7741935483870968\n",
      "[814] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "814 0 0.007942250929772854 0.7741935483870968\n",
      "[815] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "815 0 0.007938440889120102 0.7741935483870968\n",
      "[816] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "816 0 0.007934781722724438 0.7741935483870968\n",
      "[817] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "817 0 0.007931246422231197 0.7741935483870968\n",
      "[818] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "818 0 0.007927468046545982 0.7741935483870968\n",
      "[819] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "819 0 0.007923989556729794 0.7741935483870968\n",
      "[820] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "820 0 0.007920379750430584 0.7741935483870968\n",
      "[821] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "821 0 0.007916547358036041 0.7741935483870968\n",
      "[822] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "822 0 0.007913056761026382 0.7741935483870968\n",
      "[823] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "823 0 0.007909433916211128 0.7741935483870968\n",
      "[824] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "824 0 0.00790567696094513 0.7741935483870968\n",
      "[825] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "825 0 0.00790218822658062 0.7741935483870968\n",
      "[826] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "826 0 0.007898474112153053 0.7741935483870968\n",
      "[827] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "827 0 0.007894838228821754 0.7741935483870968\n",
      "[828] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "828 0 0.007891319692134857 0.7741935483870968\n",
      "[829] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "829 0 0.007887661457061768 0.7741935483870968\n",
      "[830] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "830 0 0.007884080521762371 0.7741935483870968\n",
      "[831] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "831 0 0.00788048468530178 0.7741935483870968\n",
      "[832] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "832 0 0.007876874879002571 0.7741935483870968\n",
      "[833] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "833 0 0.007873293943703175 0.7741935483870968\n",
      "[834] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "834 0 0.00786973349750042 0.7741935483870968\n",
      "[835] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "835 0 0.007866140455007553 0.7741935483870968\n",
      "[836] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "836 0 0.007862639613449574 0.7741935483870968\n",
      "[837] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "837 0 0.007858994416892529 0.7741935483870968\n",
      "[838] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "838 0 0.007855601608753204 0.7741935483870968\n",
      "[839] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "839 0 0.007852082140743732 0.7741935483870968\n",
      "[840] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "840 0 0.007848362438380718 0.7741935483870968\n",
      "[841] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "841 0 0.007844819687306881 0.7741935483870968\n",
      "[842] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "842 0 0.007841232232749462 0.7741935483870968\n",
      "[843] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "843 0 0.007837780751287937 0.7741935483870968\n",
      "[844] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "844 0 0.007834210991859436 0.7741935483870968\n",
      "[845] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "845 0 0.007830641232430935 0.7741935483870968\n",
      "[846] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "846 0 0.00782739743590355 0.7741935483870968\n",
      "[847] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "847 0 0.007823689840734005 0.7741935483870968\n",
      "[848] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "848 0 0.007820301689207554 0.7741935483870968\n",
      "[849] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "849 0 0.007816951721906662 0.7741935483870968\n",
      "[850] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "850 0 0.007813378237187862 0.7741935483870968\n",
      "[851] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "851 0 0.007809713948518038 0.7741935483870968\n",
      "[852] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "852 0 0.007806185632944107 0.7741935483870968\n",
      "[853] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "853 0 0.007802842650562525 0.7741935483870968\n",
      "[854] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "854 0 0.007799168117344379 0.7741935483870968\n",
      "[855] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.774), test: (0.008, 0.774)\n",
      "855 0 0.0077958786860108376 0.7741935483870968\n",
      "[856] loss/acc for train: (0.008, 0.774), valid: (0.008, 0.806), test: (0.008, 0.806)\n",
      "856 0 0.007792456075549126 0.8064516129032258\n",
      "[857] loss/acc for train: (0.008, 0.806), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "857 0 0.007788835559040308 0.8387096774193549\n",
      "[858] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "858 0 0.007785244379192591 0.8387096774193549\n",
      "[859] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "859 0 0.007782041560858488 0.8387096774193549\n",
      "[860] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "860 0 0.007778440602123737 0.8387096774193549\n",
      "[861] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "861 0 0.007774942088872194 0.8387096774193549\n",
      "[862] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "862 0 0.00777165312319994 0.8387096774193549\n",
      "[863] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "863 0 0.0077682118862867355 0.8387096774193549\n",
      "[864] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "864 0 0.007764588110148907 0.8387096774193549\n",
      "[865] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "865 0 0.007761138491332531 0.8387096774193549\n",
      "[866] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "866 0 0.007757795974612236 0.8387096774193549\n",
      "[867] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "867 0 0.007754223886877298 0.8387096774193549\n",
      "[868] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "868 0 0.007750962860882282 0.8387096774193549\n",
      "[869] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "869 0 0.007747516501694918 0.8387096774193549\n",
      "[870] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "870 0 0.007744118571281433 0.8387096774193549\n",
      "[871] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "871 0 0.007740919478237629 0.8387096774193549\n",
      "[872] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "872 0 0.007737262640148401 0.8387096774193549\n",
      "[873] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "873 0 0.007733834441751242 0.8387096774193549\n",
      "[874] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "874 0 0.007730547804385424 0.8387096774193549\n",
      "[875] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "875 0 0.007726999931037426 0.8387096774193549\n",
      "[876] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "876 0 0.007723621558398008 0.8387096774193549\n",
      "[877] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "877 0 0.007720253895968199 0.8387096774193549\n",
      "[878] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "878 0 0.0077169607393443584 0.8387096774193549\n",
      "[879] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "879 0 0.0077135078608989716 0.8387096774193549\n",
      "[880] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "880 0 0.0077102649956941605 0.8387096774193549\n",
      "[881] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "881 0 0.007707016542553902 0.8387096774193549\n",
      "[882] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "882 0 0.007703498471528292 0.8387096774193549\n",
      "[883] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "883 0 0.0077003114856779575 0.8387096774193549\n",
      "[884] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "884 0 0.00769704720005393 0.8387096774193549\n",
      "[885] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "885 0 0.007693620398640633 0.8387096774193549\n",
      "[886] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "886 0 0.007690084166824818 0.8387096774193549\n",
      "[887] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "887 0 0.0076868291944265366 0.8387096774193549\n",
      "[888] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "888 0 0.007683628238737583 0.8387096774193549\n",
      "[889] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "889 0 0.007680131588131189 0.8387096774193549\n",
      "[890] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "890 0 0.007676873356103897 0.8387096774193549\n",
      "[891] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "891 0 0.00767360208556056 0.8387096774193549\n",
      "[892] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "892 0 0.0076703582890331745 0.8387096774193549\n",
      "[893] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "893 0 0.007667074911296368 0.8387096774193549\n",
      "[894] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "894 0 0.007663695607334375 0.8387096774193549\n",
      "[895] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "895 0 0.007660410366952419 0.8387096774193549\n",
      "[896] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "896 0 0.007657220587134361 0.8387096774193549\n",
      "[897] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "897 0 0.00765384454280138 0.8387096774193549\n",
      "[898] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "898 0 0.0076505271717906 0.8387096774193549\n",
      "[899] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "899 0 0.007647312246263027 0.8387096774193549\n",
      "[900] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "900 0 0.007644014898687601 0.8387096774193549\n",
      "[901] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "901 0 0.007640862371772528 0.8387096774193549\n",
      "[902] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "902 0 0.007637588307261467 0.8387096774193549\n",
      "[903] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "903 0 0.007634178269654512 0.8387096774193549\n",
      "[904] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "904 0 0.007631090935319662 0.8387096774193549\n",
      "[905] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "905 0 0.00762793468311429 0.8387096774193549\n",
      "[906] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "906 0 0.007624393794685602 0.8387096774193549\n",
      "[907] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "907 0 0.00762144336476922 0.8387096774193549\n",
      "[908] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "908 0 0.007618342526257038 0.8387096774193549\n",
      "[909] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "909 0 0.0076150959357619286 0.8387096774193549\n",
      "[910] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "910 0 0.0076117198914289474 0.8387096774193549\n",
      "[911] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "911 0 0.00760827399790287 0.8387096774193549\n",
      "[912] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "912 0 0.007605452090501785 0.8387096774193549\n",
      "[913] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "913 0 0.007602155674248934 0.8387096774193549\n",
      "[914] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "914 0 0.007598667871206999 0.8387096774193549\n",
      "[915] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "915 0 0.007595587521791458 0.8387096774193549\n",
      "[916] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "916 0 0.007592442445456982 0.8387096774193549\n",
      "[917] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "917 0 0.007589201908558607 0.8387096774193549\n",
      "[918] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "918 0 0.0075859022326767445 0.8387096774193549\n",
      "[919] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "919 0 0.007582766469568014 0.8387096774193549\n",
      "[920] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "920 0 0.007579577621072531 0.8387096774193549\n",
      "[921] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "921 0 0.007576380856335163 0.8387096774193549\n",
      "[922] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "922 0 0.007573217619210482 0.8387096774193549\n",
      "[923] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "923 0 0.0075700669549405575 0.8387096774193549\n",
      "[924] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "924 0 0.007566897198557854 0.8387096774193549\n",
      "[925] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "925 0 0.007563771679997444 0.8387096774193549\n",
      "[926] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "926 0 0.00756062613800168 0.8387096774193549\n",
      "[927] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "927 0 0.007557441480457783 0.8387096774193549\n",
      "[928] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "928 0 0.007554275449365377 0.8387096774193549\n",
      "[929] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "929 0 0.007550966925919056 0.8387096774193549\n",
      "[930] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "930 0 0.007547397166490555 0.8387096774193549\n",
      "[931] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "931 0 0.007543961517512798 0.8387096774193549\n",
      "[932] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "932 0 0.007540414109826088 0.8387096774193549\n",
      "[933] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "933 0 0.00753690954297781 0.8387096774193549\n",
      "[934] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "934 0 0.0075333560816943645 0.8387096774193549\n",
      "[935] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "935 0 0.007529722526669502 0.8387096774193549\n",
      "[936] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "936 0 0.007526099681854248 0.8387096774193549\n",
      "[937] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "937 0 0.007522533647716045 0.8387096774193549\n",
      "[938] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "938 0 0.007518776226788759 0.8387096774193549\n",
      "[939] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "939 0 0.00751519575715065 0.8387096774193549\n",
      "[940] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "940 0 0.007511553820222616 0.8387096774193549\n",
      "[941] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "941 0 0.007507837377488613 0.8387096774193549\n",
      "[942] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "942 0 0.0075040552765131 0.8387096774193549\n",
      "[943] loss/acc for train: (0.008, 0.839), valid: (0.008, 0.839), test: (0.008, 0.839)\n",
      "943 0 0.007500339765101671 0.8387096774193549\n",
      "[944] loss/acc for train: (0.008, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "944 0 0.007496593985706568 0.8387096774193549\n",
      "[945] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "945 0 0.007492839824408293 0.8387096774193549\n",
      "[946] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "946 0 0.0074891322292387486 0.8387096774193549\n",
      "[947] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "947 0 0.007485387846827507 0.8387096774193549\n",
      "[948] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "948 0 0.0074816010892391205 0.8387096774193549\n",
      "[949] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "949 0 0.00747785996645689 0.8387096774193549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[950] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "950 0 0.007474098354578018 0.8387096774193549\n",
      "[951] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "951 0 0.00747050391510129 0.8387096774193549\n",
      "[952] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "952 0 0.007466938346624374 0.8387096774193549\n",
      "[953] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "953 0 0.007463076151907444 0.8387096774193549\n",
      "[954] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "954 0 0.007459250278770924 0.8387096774193549\n",
      "[955] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "955 0 0.007455599959939718 0.8387096774193549\n",
      "[956] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "956 0 0.007452643476426601 0.8387096774193549\n",
      "[957] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "957 0 0.0074491677805781364 0.8387096774193549\n",
      "[958] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "958 0 0.007445182651281357 0.8387096774193549\n",
      "[959] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "959 0 0.007442389149218798 0.8387096774193549\n",
      "[960] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "960 0 0.007439301814883947 0.8387096774193549\n",
      "[961] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "961 0 0.007435939274728298 0.8387096774193549\n",
      "[962] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "962 0 0.00743302283808589 0.8387096774193549\n",
      "[963] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "963 0 0.0074304030276834965 0.8387096774193549\n",
      "[964] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "964 0 0.007427426986396313 0.8387096774193549\n",
      "[965] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "965 0 0.007424204144626856 0.8387096774193549\n",
      "[966] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "966 0 0.007421321701258421 0.8387096774193549\n",
      "[967] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "967 0 0.007418526336550713 0.8387096774193549\n",
      "[968] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "968 0 0.007415939588099718 0.8387096774193549\n",
      "[969] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "969 0 0.007412782870233059 0.8387096774193549\n",
      "[970] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "970 0 0.007409809157252312 0.8387096774193549\n",
      "[971] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "971 0 0.0074068838730454445 0.8387096774193549\n",
      "[972] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "972 0 0.007403919473290443 0.8387096774193549\n",
      "[973] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "973 0 0.007400918751955032 0.8387096774193549\n",
      "[974] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "974 0 0.0073979515582323074 0.8387096774193549\n",
      "[975] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "975 0 0.007395127322524786 0.8387096774193549\n",
      "[976] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "976 0 0.007392094936221838 0.8387096774193549\n",
      "[977] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "977 0 0.007389106322079897 0.8387096774193549\n",
      "[978] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "978 0 0.007386158220469952 0.8387096774193549\n",
      "[979] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "979 0 0.007383135613054037 0.8387096774193549\n",
      "[980] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "980 0 0.007380321621894836 0.8387096774193549\n",
      "[981] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "981 0 0.007377421949058771 0.8387096774193549\n",
      "[982] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "982 0 0.007374298758804798 0.8387096774193549\n",
      "[983] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "983 0 0.007371372077614069 0.8387096774193549\n",
      "[984] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "984 0 0.007368611637502909 0.8387096774193549\n",
      "[985] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "985 0 0.007365745957940817 0.8387096774193549\n",
      "[986] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "986 0 0.007362631615251303 0.8387096774193549\n",
      "[987] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "987 0 0.007359709125012159 0.8387096774193549\n",
      "[988] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "988 0 0.007357088383287191 0.8387096774193549\n",
      "[989] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "989 0 0.007353795692324638 0.8387096774193549\n",
      "[990] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "990 0 0.007351083215326071 0.8387096774193549\n",
      "[991] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "991 0 0.0073481337167322636 0.8387096774193549\n",
      "[992] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "992 0 0.007345345802605152 0.8387096774193549\n",
      "[993] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "993 0 0.00734260119497776 0.8387096774193549\n",
      "[994] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "994 0 0.0073397415690124035 0.8387096774193549\n",
      "[995] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "995 0 0.0073372614569962025 0.8387096774193549\n",
      "[996] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "996 0 0.007334168069064617 0.8387096774193549\n",
      "[997] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "997 0 0.007331714499741793 0.8387096774193549\n",
      "[998] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "998 0 0.007328975014388561 0.8387096774193549\n",
      "[999] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "999 0 0.007325828541070223 0.8387096774193549\n",
      "[1000] loss/acc for train: (0.007, 0.839), valid: (0.007, 0.839), test: (0.007, 0.839)\n",
      "Done 1.2911932468414307\n",
      "test accuracy 0.839\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = df_combined[['MAG','MAG10yr','Count_L','Count_S']]\n",
    "labels = df_combined[['MAG5yr']]\n",
    "labels = labels['MAG5yr'].astype(int)\n",
    "\n",
    "batch_size = 35\n",
    "test_loader, val_loader, train_loader, train_dataset, val_dataset, test_dataset, num_classes = split_data(data, labels, batch_size)\n",
    "\n",
    "#print_dataset2(train_dataset, \"Training Dataset\")\n",
    "#print_dataset2(val_dataset  , \"Validation Dataset\")\n",
    "#print_dataset2(test_dataset , \"Testing Dataset\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "epochs = 1\n",
    "input_dim = 256\n",
    "\n",
    "# Instantiate model and define loss function and optimizer\n",
    "print(num_classes)\n",
    "model = NeuralNetwork(input_variables=4,num_classes=2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "epochs=1000\n",
    "train_metrics, val_metrics, test_metrics = train_test_model_epochs(model,num_epochs=epochs)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_results( pd.DataFrame(train_metrics)\n",
    "            , pd.DataFrame(val_metrics)\n",
    "            , pd.DataFrame(test_metrics)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ca85f718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot: title={'center': 'MAG10yr'}>]], dtype=object)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(y_train).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "95fc7d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Dataset\n",
      "                0               1               2               3\n",
      "0      tensor(0.)      tensor(0.)      tensor(0.)  tensor(0.2174)\n",
      "1  tensor(0.8512)      tensor(1.)  tensor(0.2000)  tensor(0.0056)\n",
      "2  tensor(0.3256)  tensor(0.4414)      tensor(0.)  tensor(0.2752)\n",
      "3  tensor(0.8605)  tensor(0.8759)  tensor(0.2000)  tensor(0.1017)\n",
      "4  tensor(0.4605)  tensor(0.8759)      tensor(0.)  tensor(0.1045)\n",
      "5  tensor(0.8140)      tensor(1.)  tensor(0.2000)  tensor(0.0024)\n",
      "6  tensor(0.8512)      tensor(1.)  tensor(0.2000)  tensor(0.0041)\n",
      "7  tensor(0.8605)      tensor(1.)      tensor(1.)  tensor(0.0205)\n",
      "8  tensor(0.6233)  tensor(0.4414)      tensor(0.)  tensor(0.5410)\n",
      "   0\n",
      "0  0\n",
      "1  0\n",
      "2  0\n",
      "3  0\n",
      "4  0\n",
      "5  1\n",
      "6  0\n",
      "7  1\n",
      "8  0\n"
     ]
    }
   ],
   "source": [
    "print_dataset2(test_dataset , \"Testing Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3e21a96d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "accuracy_score(y_test, y_test)\n",
    "f1_score(y_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
